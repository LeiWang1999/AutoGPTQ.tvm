2023-05-01 16:00:02 [INFO] [task_scheduler.cc:160] Initializing Task #0: "main"
2023-05-01 16:00:02 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 8192), "int8"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # with T.block("root"):
        B_decompress = T.alloc_buffer((16384, 16384), "float16")
        for i, j in T.grid(16384, 16384):
            with T.block("B_decompress"):
                vi, vj = T.axis.remap("SS", [i, j])
                T.reads(B[vi, vj // 2:vj // 2 + 2])
                T.writes(B_decompress[vi, vj])
                B_decompress[vi, vj] = T.Select(vj % 32 * 4 % 8 <= 5, T.Cast("float16", T.bitwise_and(T.shift_right(T.Cast("int32", B[vi, vj // 32 * 16 + vj % 32 * 4 // 8]), vj % 32 * 4 % 8), 15)), T.Cast("float16", T.bitwise_or(T.Cast("int8", T.bitwise_and(T.shift_right(T.Cast("int32", B[vi, vj // 32 * 16 + vj % 32 * 4 // 8]), vj % 32 * 4 % 8), T.shift_left(1, 8 - vj % 32 * 4 % 8) - 1)), T.Cast("int8", T.bitwise_and(T.bitwise_and(T.shift_left(T.Cast("int32", B[vi, vj // 32 * 16 + vj % 32 * 4 // 8 + 1]), 8 - vj % 32 * 4 % 8), T.shift_left(15, 8 - vj % 32 * 4 % 8)), 15)))))
        for i, j, k in T.grid(16384, 16384, 16384):
            with T.block("B"):
                vi, vj, vk = T.axis.remap("SSR", [i, j, k])
                T.reads(A[vi, vk], B_decompress[vj, vk])
                T.writes(C[vi, vj])
                with T.init():
                    C[vi, vj] = T.float16(0)
                C[vi, vj] = C[vi, vj] + A[vi, vk] * B_decompress[vj, vk]
2023-05-01 16:00:02 [INFO] [multi_level_tiling_tensor_core.cc:212] Sketch 0: tensorizing with wmma_sync_16x16x16_f16f16f16_trans
2023-05-01 16:00:02 [INFO] [multi_level_tiling_tensor_core.cc:212] Sketch 1: tensorizing with wmma_sync_16x16x16_f16f16f16
2023-05-01 16:00:02 [INFO] [task_scheduler.cc:164] Total 2 design space(s) generated
2023-05-01 16:00:03 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 8192), "int8"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 64})
            C_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            C_reindex_shared_dyn_wmma_accumulator = T.alloc_buffer((16384, 16384), "float16", scope="wmma.accumulator")
            A_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            B_decompress_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            A_reindex_shared_dyn_wmma_matrix_a = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_a")
            B_decompress_reindex_shared_dyn_wmma_matrix_b = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_b")
            for ax0_0_0_ax1_0_0_fused in T.thread_binding(256, thread="blockIdx.y"):
                for ax0_0_1_ax1_0_1_fused in T.thread_binding(8, thread="blockIdx.x"):
                    for ax0_0_2_ax1_0_2_fused in T.thread_binding(2, thread="threadIdx.y"):
                        for ax2_0_0 in range(256):
                            for ax0_ax1_fused in range(65536):
                                with T.block("A_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused // 64 * 4096 + ax0_0_1_ax1_0_1_fused // 2 * 1024 + ax0_ax1_fused // 64)
                                    v1 = T.axis.spatial(16384, ax2_0_0 * 64 + ax0_ax1_fused % 64)
                                    T.reads(A[v0, v1])
                                    T.writes(A_reindex_shared_dyn[v0, v1])
                                    T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]], "meta_schedule.cooperative_fetch": 8})
                                    A_reindex_shared_dyn[v0, v1] = A[v0, v1]
                            for ax0_ax1_fused in range(8192):
                                with T.block("B_decompress_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(16384, ax2_0_0 * 64 + ax0_ax1_fused // 128)
                                    v1 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused % 64 * 256 + ax0_0_1_ax1_0_1_fused % 2 * 128 + ax0_ax1_fused % 128)
                                    T.reads(B[v1, v0 // 2:v0 // 2 + 2])
                                    T.writes(B_decompress_reindex_shared_dyn[v0, v1])
                                    T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]], "meta_schedule.cooperative_fetch": 2})
                                    B_decompress_reindex_shared_dyn[v0, v1] = T.Select(v0 % 32 * 4 % 8 <= 5, T.Cast("float16", T.bitwise_and(T.shift_right(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8]), v0 % 32 * 4 % 8), 15)), T.Cast("float16", T.bitwise_or(T.Cast("int8", T.bitwise_and(T.shift_right(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8]), v0 % 32 * 4 % 8), T.shift_left(1, 8 - v0 % 32 * 4 % 8) - 1)), T.Cast("int8", T.bitwise_and(T.bitwise_and(T.shift_left(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8 + 1]), 8 - v0 % 32 * 4 % 8), T.shift_left(15, 8 - v0 % 32 * 4 % 8)), 15)))))
                            for ax2_0_1 in range(1):
                                for ax0_0, ax1_0 in T.grid(64, 4):
                                    with T.block("A_reindex_shared.dyn_wmma.matrix_a_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 64 * 256 + ax0_0_1_ax1_0_1_fused // 2 * 64 + ax0_0)
                                        v1_o = T.axis.spatial(1024, ax2_0_0 * 4 + ax1_0)
                                        T.reads(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_load_16x16x16_f16_a_shared_dyn"})
                                        for ax0_1, ax1_1 in T.grid(16, 16):
                                            with T.block("A_reindex_shared.dyn_wmma.matrix_a"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(A_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = A_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                                for ax0_0, ax1_0 in T.grid(4, 4):
                                    with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b_o"):
                                        v0_o = T.axis.spatial(1024, ax2_0_0 * 4 + ax0_0)
                                        v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 64 * 16 + ax0_0_1_ax1_0_1_fused % 2 * 8 + ax0_0_2_ax1_0_2_fused * 4 + ax1_0)
                                        T.reads(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_load_16x16x16_f16_b_shared_dyn"})
                                        for ax0_1, ax1_1 in T.grid(16, 16):
                                            with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(B_decompress_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = B_decompress_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                                for ax0_0_3, ax1_0_3, ax2_0_2, ax0_0_4, ax1_0_4 in T.grid(32, 2, 4, 2, 2):
                                    with T.block("B_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 64 * 256 + ax0_0_1_ax1_0_1_fused // 2 * 64 + ax0_0_3 * 2 + ax0_0_4)
                                        v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 64 * 16 + ax0_0_1_ax1_0_1_fused % 2 * 8 + ax0_0_2_ax1_0_2_fused * 4 + ax1_0_3 * 2 + ax1_0_4)
                                        v2_o = T.axis.reduce(1024, ax2_0_0 * 4 + ax2_0_1 * 4 + ax2_0_2)
                                        T.reads(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], B_decompress_reindex_shared_dyn_wmma_matrix_b[v2_o * 16:v2_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_sync_16x16x16_f16f16f16", "meta_schedule.auto_tensorize_init": "wmma_fill_16x16x16_f16", "meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                                        with T.init():
                                            for ax0_1, ax1_1 in T.grid(16, 16):
                                                with T.block("B_init"):
                                                    v0_i_init, v1_i_init = T.axis.remap("SS", [ax0_1, ax1_1])
                                                    T.reads()
                                                    T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o * 16 + v0_i_init, v1_o * 16 + v1_i_init])
                                                    C_reindex_shared_dyn_wmma_accumulator[v0_o * 16 + v0_i_init, v1_o * 16 + v1_i_init] = T.float16(0)
                                        for ax0_1, ax1_1, ax2_1 in T.grid(16, 16, 16):
                                            with T.block("B"):
                                                v0_i, v1_i, v2_i = T.axis.remap("SSR", [ax0_1, ax1_1, ax2_1])
                                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o * 16 + v0_i, v1_o * 16 + v1_i], A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v2_o * 16 + v2_i], B_decompress_reindex_shared_dyn_wmma_matrix_b[v2_o * 16 + v2_i, v1_o * 16 + v1_i])
                                                T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.block_attr({"meta_schedule.tiling_structure": "SSSRRSRS"})
                                                C_reindex_shared_dyn_wmma_accumulator[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = C_reindex_shared_dyn_wmma_accumulator[v0_o * 16 + v0_i, v1_o * 16 + v1_i] + A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v2_o * 16 + v2_i] * B_decompress_reindex_shared_dyn_wmma_matrix_b[v2_o * 16 + v2_i, v1_o * 16 + v1_i]
                        for ax0_0, ax1_0 in T.grid(64, 4):
                            with T.block("C_reindex_shared.dyn_wmma.accumulator_o"):
                                v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 64 * 256 + ax0_0_1_ax1_0_1_fused // 2 * 64 + ax0_0)
                                v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 64 * 16 + ax0_0_1_ax1_0_1_fused % 2 * 8 + ax0_0_2_ax1_0_2_fused * 4 + ax1_0)
                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                T.writes(C_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                T.block_attr({"meta_schedule.auto_tensorize": "wmma_store_16x16x16_f16_shared_dyn"})
                                for ax0_1, ax1_1 in T.grid(16, 16):
                                    with T.block("C_reindex_shared.dyn_wmma.accumulator"):
                                        v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                        T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                        T.writes(C_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                        C_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = C_reindex_shared_dyn_wmma_accumulator[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                    for ax0_ax1_fused in range(131072):
                        with T.block("C_reindex_shared.dyn"):
                            v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused // 64 * 4096 + ax0_0_1_ax1_0_1_fused // 2 * 1024 + ax0_ax1_fused // 128)
                            v1 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused % 64 * 256 + ax0_0_1_ax1_0_1_fused % 2 * 128 + ax0_ax1_fused % 128)
                            T.reads(C_reindex_shared_dyn[v0, v1])
                            T.writes(C[v0, v1])
                            T.block_attr({"meta_schedule.cooperative_fetch": 2})
                            C[v0, v1] = C_reindex_shared_dyn[v0, v1]

2023-05-01 16:01:19 [INFO] [task_scheduler.cc:160] Initializing Task #0: "main"
2023-05-01 16:01:19 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 16384), "float16"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # with T.block("root"):
        for i, j, k in T.grid(16384, 16384, 16384):
            with T.block("B"):
                vi, vj, vk = T.axis.remap("SSR", [i, j, k])
                T.reads(A[vi, vk], B[vj, vk])
                T.writes(C[vi, vj])
                with T.init():
                    C[vi, vj] = T.float16(0)
                C[vi, vj] = C[vi, vj] + A[vi, vk] * B[vj, vk]
2023-05-01 16:01:19 [INFO] [multi_level_tiling_tensor_core.cc:212] Sketch 0: tensorizing with wmma_sync_16x16x16_f16f16f16_trans
2023-05-01 16:01:19 [INFO] [multi_level_tiling_tensor_core.cc:212] Sketch 1: tensorizing with wmma_sync_16x16x16_f16f16f16
2023-05-01 16:01:19 [INFO] [task_scheduler.cc:164] Total 2 design space(s) generated
2023-05-01 16:01:19 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 16384), "float16"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 1024})
            C_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            C_reindex_shared_dyn_wmma_accumulator = T.alloc_buffer((16384, 16384), "float16", scope="wmma.accumulator")
            A_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            B_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            A_reindex_shared_dyn_wmma_matrix_a = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_a")
            B_reindex_shared_dyn_wmma_matrix_b = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_b")
            for ax0_0_0_ax1_0_0_fused in T.thread_binding(64, thread="blockIdx.y"):
                for ax0_0_1_ax1_0_1_fused in T.thread_binding(64, thread="blockIdx.x"):
                    for ax0_0_2_ax1_0_2_fused in T.thread_binding(8, thread="threadIdx.y"):
                        for ax2_0_0 in range(2):
                            for ax0_ax1_fused in range(8388608):
                                with T.block("A_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused // 16 * 4096 + ax0_0_1_ax1_0_1_fused // 16 * 1024 + ax0_ax1_fused // 8192)
                                    v1 = T.axis.spatial(16384, ax2_0_0 * 8192 + ax0_ax1_fused % 8192)
                                    T.reads(A[v0, v1])
                                    T.writes(A_reindex_shared_dyn[v0, v1])
                                    T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]], "meta_schedule.cooperative_fetch": 4})
                                    A_reindex_shared_dyn[v0, v1] = A[v0, v1]
                            for ax0_ax1_fused in range(524288):
                                with T.block("B_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(16384, ax2_0_0 * 8192 + ax0_ax1_fused // 64)
                                    v1 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused % 16 * 1024 + ax0_0_1_ax1_0_1_fused % 16 * 64 + ax0_ax1_fused % 64)
                                    T.reads(B[v1, v0])
                                    T.writes(B_reindex_shared_dyn[v0, v1])
                                    T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]], "meta_schedule.cooperative_fetch": 1})
                                    B_reindex_shared_dyn[v0, v1] = B[v1, v0]
                            for ax2_0_1 in range(512):
                                for ax0_0, ax1_0 in T.grid(32, 1):
                                    with T.block("A_reindex_shared.dyn_wmma.matrix_a_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 16 * 256 + ax0_0_1_ax1_0_1_fused // 16 * 64 + ax0_0_2_ax1_0_2_fused // 4 * 32 + ax0_0)
                                        v1_o = T.axis.spatial(1024, ax2_0_0 * 512 + ax2_0_1 + ax1_0)
                                        T.reads(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_load_16x16x16_f16_a_shared_dyn"})
                                        for ax0_1, ax1_1 in T.grid(16, 16):
                                            with T.block("A_reindex_shared.dyn_wmma.matrix_a"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(A_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = A_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                                for ax0_0, ax1_0 in T.grid(1, 1):
                                    with T.block("B_reindex_shared.dyn_wmma.matrix_b_o"):
                                        v0_o = T.axis.spatial(1024, ax2_0_0 * 512 + ax2_0_1 + ax0_0)
                                        v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 16 * 64 + ax0_0_1_ax1_0_1_fused % 16 * 4 + ax0_0_2_ax1_0_2_fused % 4 + ax1_0)
                                        T.reads(B_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(B_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_load_16x16x16_f16_b_shared_dyn"})
                                        for ax0_1, ax1_1 in T.grid(16, 16):
                                            with T.block("B_reindex_shared.dyn_wmma.matrix_b"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(B_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.writes(B_reindex_shared_dyn_wmma_matrix_b[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                B_reindex_shared_dyn_wmma_matrix_b[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = B_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                                for ax0_0_3, ax1_0_3, ax2_0_2, ax0_0_4, ax1_0_4 in T.grid(8, 1, 1, 4, 1):
                                    with T.block("B_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 16 * 256 + ax0_0_1_ax1_0_1_fused // 16 * 64 + ax0_0_2_ax1_0_2_fused // 4 * 32 + ax0_0_3 * 4 + ax0_0_4)
                                        v1_o = T.axis.spatial(1024, ax1_0_4 + ax0_0_0_ax1_0_0_fused % 16 * 64 + ax0_0_1_ax1_0_1_fused % 16 * 4 + ax0_0_2_ax1_0_2_fused % 4 + ax1_0_3)
                                        v2_o = T.axis.reduce(1024, ax2_0_0 * 512 + ax2_0_1 + ax2_0_2)
                                        T.reads(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], B_reindex_shared_dyn_wmma_matrix_b[v2_o * 16:v2_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_sync_16x16x16_f16f16f16", "meta_schedule.auto_tensorize_init": "wmma_fill_16x16x16_f16", "meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                                        with T.init():
                                            for ax0_1, ax1_1 in T.grid(16, 16):
                                                with T.block("B_init"):
                                                    v0_i_init, v1_i_init = T.axis.remap("SS", [ax0_1, ax1_1])
                                                    T.reads()
                                                    T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o * 16 + v0_i_init, v1_o * 16 + v1_i_init])
                                                    C_reindex_shared_dyn_wmma_accumulator[v0_o * 16 + v0_i_init, v1_o * 16 + v1_i_init] = T.float16(0)
                                        for ax0_1, ax1_1, ax2_1 in T.grid(16, 16, 16):
                                            with T.block("B"):
                                                v0_i, v1_i, v2_i = T.axis.remap("SSR", [ax0_1, ax1_1, ax2_1])
                                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o * 16 + v0_i, v1_o * 16 + v1_i], A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v2_o * 16 + v2_i], B_reindex_shared_dyn_wmma_matrix_b[v2_o * 16 + v2_i, v1_o * 16 + v1_i])
                                                T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.block_attr({"meta_schedule.tiling_structure": "SSSRRSRS"})
                                                C_reindex_shared_dyn_wmma_accumulator[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = C_reindex_shared_dyn_wmma_accumulator[v0_o * 16 + v0_i, v1_o * 16 + v1_i] + A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v2_o * 16 + v2_i] * B_reindex_shared_dyn_wmma_matrix_b[v2_o * 16 + v2_i, v1_o * 16 + v1_i]
                        for ax0_0, ax1_0 in T.grid(32, 1):
                            with T.block("C_reindex_shared.dyn_wmma.accumulator_o"):
                                v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 16 * 256 + ax0_0_1_ax1_0_1_fused // 16 * 64 + ax0_0_2_ax1_0_2_fused // 4 * 32 + ax0_0)
                                v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 16 * 64 + ax0_0_1_ax1_0_1_fused % 16 * 4 + ax0_0_2_ax1_0_2_fused % 4 + ax1_0)
                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                T.writes(C_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                T.block_attr({"meta_schedule.auto_tensorize": "wmma_store_16x16x16_f16_shared_dyn"})
                                for ax0_1, ax1_1 in T.grid(16, 16):
                                    with T.block("C_reindex_shared.dyn_wmma.accumulator"):
                                        v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                        T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                        T.writes(C_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                        C_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = C_reindex_shared_dyn_wmma_accumulator[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                    for ax0_ax1_fused in range(65536):
                        with T.block("C_reindex_shared.dyn"):
                            v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused // 16 * 4096 + ax0_0_1_ax1_0_1_fused // 16 * 1024 + ax0_ax1_fused // 64)
                            v1 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused % 16 * 1024 + ax0_0_1_ax1_0_1_fused % 16 * 64 + ax0_ax1_fused % 64)
                            T.reads(C_reindex_shared_dyn[v0, v1])
                            T.writes(C[v0, v1])
                            T.block_attr({"meta_schedule.cooperative_fetch": 8})
                            C[v0, v1] = C_reindex_shared_dyn[v0, v1]

2023-05-01 16:01:41 [INFO] [task_scheduler.cc:160] Initializing Task #0: "main"
2023-05-01 16:01:41 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 16384), "float16"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # with T.block("root"):
        for i, j, k in T.grid(16384, 16384, 16384):
            with T.block("B"):
                vi, vj, vk = T.axis.remap("SSR", [i, j, k])
                T.reads(A[vi, vk], B[vj, vk])
                T.writes(C[vi, vj])
                with T.init():
                    C[vi, vj] = T.float16(0)
                C[vi, vj] = C[vi, vj] + A[vi, vk] * B[vj, vk]
2023-05-01 16:01:41 [INFO] [multi_level_tiling_tensor_core.cc:212] Sketch 0: tensorizing with wmma_sync_16x16x16_f16f16f16_trans
2023-05-01 16:01:41 [INFO] [multi_level_tiling_tensor_core.cc:212] Sketch 1: tensorizing with wmma_sync_16x16x16_f16f16f16
2023-05-01 16:01:41 [INFO] [task_scheduler.cc:164] Total 2 design space(s) generated
2023-05-01 16:01:41 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 16384), "float16"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 16})
            C_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            C_reindex_shared_dyn_wmma_accumulator = T.alloc_buffer((16384, 16384), "float16", scope="wmma.accumulator")
            A_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            B_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            A_reindex_shared_dyn_wmma_matrix_a = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_a")
            B_reindex_shared_dyn_wmma_matrix_b = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_b")
            for ax0_0_0_ax1_0_0_fused in T.thread_binding(32, thread="blockIdx.y"):
                for ax0_0_1_ax1_0_1_fused in T.thread_binding(2, thread="blockIdx.x"):
                    for ax0_0_2_ax1_0_2_fused in T.thread_binding(1024, thread="threadIdx.y"):
                        for ax2_0_0 in range(16):
                            for ax0_ax1_fused in range(1048576):
                                with T.block("A_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused // 2 * 1024 + ax0_ax1_fused // 1024)
                                    v1 = T.axis.spatial(16384, ax2_0_0 * 1024 + ax0_ax1_fused % 1024)
                                    T.reads(A[v0, v1])
                                    T.writes(A_reindex_shared_dyn[v0, v1])
                                    T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]], "meta_schedule.cooperative_fetch": 1})
                                    A_reindex_shared_dyn[v0, v1] = A[v0, v1]
                            for ax0_ax1_fused in range(4194304):
                                with T.block("B_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(16384, ax2_0_0 * 1024 + ax0_ax1_fused // 4096)
                                    v1 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused % 2 * 8192 + ax0_0_1_ax1_0_1_fused * 4096 + ax0_ax1_fused % 4096)
                                    T.reads(B[v1, v0])
                                    T.writes(B_reindex_shared_dyn[v0, v1])
                                    T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]], "meta_schedule.cooperative_fetch": 8})
                                    B_reindex_shared_dyn[v0, v1] = B[v1, v0]
                            for ax2_0_1 in range(64):
                                for ax0_0, ax1_0 in T.grid(4, 1):
                                    with T.block("A_reindex_shared.dyn_wmma.matrix_a_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 2 * 64 + ax0_0_2_ax1_0_2_fused // 64 * 4 + ax0_0)
                                        v1_o = T.axis.spatial(1024, ax2_0_0 * 64 + ax2_0_1 + ax1_0)
                                        T.reads(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_load_16x16x16_f16_a_shared_dyn"})
                                        for ax0_1, ax1_1 in T.grid(16, 16):
                                            with T.block("A_reindex_shared.dyn_wmma.matrix_a"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(A_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = A_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                                for ax0_0, ax1_0 in T.grid(1, 4):
                                    with T.block("B_reindex_shared.dyn_wmma.matrix_b_o"):
                                        v0_o = T.axis.spatial(1024, ax2_0_0 * 64 + ax2_0_1 + ax0_0)
                                        v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 2 * 512 + ax0_0_1_ax1_0_1_fused * 256 + ax0_0_2_ax1_0_2_fused % 64 * 4 + ax1_0)
                                        T.reads(B_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(B_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_load_16x16x16_f16_b_shared_dyn"})
                                        for ax0_1, ax1_1 in T.grid(16, 16):
                                            with T.block("B_reindex_shared.dyn_wmma.matrix_b"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(B_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.writes(B_reindex_shared_dyn_wmma_matrix_b[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                B_reindex_shared_dyn_wmma_matrix_b[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = B_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                                for ax0_0_3, ax1_0_3, ax2_0_2, ax0_0_4, ax1_0_4 in T.grid(1, 4, 1, 4, 1):
                                    with T.block("B_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 2 * 64 + ax0_0_2_ax1_0_2_fused // 64 * 4 + ax0_0_3 * 4 + ax0_0_4)
                                        v1_o = T.axis.spatial(1024, ax1_0_4 + ax0_0_0_ax1_0_0_fused % 2 * 512 + ax0_0_1_ax1_0_1_fused * 256 + ax0_0_2_ax1_0_2_fused % 64 * 4 + ax1_0_3)
                                        v2_o = T.axis.reduce(1024, ax2_0_0 * 64 + ax2_0_1 + ax2_0_2)
                                        T.reads(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], B_reindex_shared_dyn_wmma_matrix_b[v2_o * 16:v2_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_sync_16x16x16_f16f16f16", "meta_schedule.auto_tensorize_init": "wmma_fill_16x16x16_f16", "meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                                        with T.init():
                                            for ax0_1, ax1_1 in T.grid(16, 16):
                                                with T.block("B_init"):
                                                    v0_i_init, v1_i_init = T.axis.remap("SS", [ax0_1, ax1_1])
                                                    T.reads()
                                                    T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o * 16 + v0_i_init, v1_o * 16 + v1_i_init])
                                                    C_reindex_shared_dyn_wmma_accumulator[v0_o * 16 + v0_i_init, v1_o * 16 + v1_i_init] = T.float16(0)
                                        for ax0_1, ax1_1, ax2_1 in T.grid(16, 16, 16):
                                            with T.block("B"):
                                                v0_i, v1_i, v2_i = T.axis.remap("SSR", [ax0_1, ax1_1, ax2_1])
                                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o * 16 + v0_i, v1_o * 16 + v1_i], A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v2_o * 16 + v2_i], B_reindex_shared_dyn_wmma_matrix_b[v2_o * 16 + v2_i, v1_o * 16 + v1_i])
                                                T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.block_attr({"meta_schedule.tiling_structure": "SSSRRSRS"})
                                                C_reindex_shared_dyn_wmma_accumulator[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = C_reindex_shared_dyn_wmma_accumulator[v0_o * 16 + v0_i, v1_o * 16 + v1_i] + A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v2_o * 16 + v2_i] * B_reindex_shared_dyn_wmma_matrix_b[v2_o * 16 + v2_i, v1_o * 16 + v1_i]
                        for ax0_0, ax1_0 in T.grid(4, 4):
                            with T.block("C_reindex_shared.dyn_wmma.accumulator_o"):
                                v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 2 * 64 + ax0_0_2_ax1_0_2_fused // 64 * 4 + ax0_0)
                                v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 2 * 512 + ax0_0_1_ax1_0_1_fused * 256 + ax0_0_2_ax1_0_2_fused % 64 * 4 + ax1_0)
                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                T.writes(C_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                T.block_attr({"meta_schedule.auto_tensorize": "wmma_store_16x16x16_f16_shared_dyn"})
                                for ax0_1, ax1_1 in T.grid(16, 16):
                                    with T.block("C_reindex_shared.dyn_wmma.accumulator"):
                                        v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                        T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                        T.writes(C_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                        C_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = C_reindex_shared_dyn_wmma_accumulator[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                    for ax0_ax1_fused in range(4194304):
                        with T.block("C_reindex_shared.dyn"):
                            v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused // 2 * 1024 + ax0_ax1_fused // 4096)
                            v1 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused % 2 * 8192 + ax0_0_1_ax1_0_1_fused * 4096 + ax0_ax1_fused % 4096)
                            T.reads(C_reindex_shared_dyn[v0, v1])
                            T.writes(C[v0, v1])
                            T.block_attr({"meta_schedule.cooperative_fetch": 4})
                            C[v0, v1] = C_reindex_shared_dyn[v0, v1]

2023-05-01 16:03:04 [INFO] [task_scheduler.cc:160] Initializing Task #0: "main"
2023-05-01 16:03:04 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 16384), "float16"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i, j, k in T.grid(16384, 16384, 16384):
            with T.block("B"):
                vi, vj, vk = T.axis.remap("SSR", [i, j, k])
                T.reads(A[vi, vk], B[vj, vk])
                T.writes(C[vi, vj])
                with T.init():
                    C[vi, vj] = T.float16(0)
                C[vi, vj] = C[vi, vj] + A[vi, vk] * B[vj, vk]
2023-05-01 16:03:04 [INFO] [multi_level_tiling_tensor_core.cc:216] Sketch 0: tensorizing with wmma_sync_16x16x16_f16f16f16_trans
2023-05-01 16:03:04 [INFO] [multi_level_tiling_tensor_core.cc:216] Sketch 1: tensorizing with wmma_sync_16x16x16_f16f16f16
2023-05-01 16:03:04 [INFO] [task_scheduler.cc:164] Total 2 design space(s) generated
2023-05-01 16:03:04 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 16384), "float16"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 0})
            C_reindex_shared_dyn = T.alloc_buffer((128, 64, 8, 16, 16, 16), "float16", scope="shared.dyn")
            C_reindex_shared_dyn_wmma_accumulator = T.alloc_buffer((128, 64, 8, 16, 16, 16), "float16", scope="wmma.accumulator")
            A_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            B_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            A_reindex_shared_dyn_wmma_matrix_a = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_a")
            B_reindex_shared_dyn_wmma_matrix_b = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_b")
            for ax0_0_0_ax1_0_0_fused in T.thread_binding(32, thread="blockIdx.y"):
                for ax0_0_1_ax1_0_1_fused in T.thread_binding(64, thread="blockIdx.x"):
                    for ax0_0_2_ax1_0_2_fused in T.thread_binding(4, thread="threadIdx.y"):
                        for ax2_0_0 in range(32):
                            for ax0_ax1_fused in range(131072):
                                with T.block("A_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused // 16 * 8192 + ax0_0_1_ax1_0_1_fused // 2 * 256 + ax0_ax1_fused // 512)
                                    v1 = T.axis.spatial(16384, ax2_0_0 * 512 + ax0_ax1_fused % 512)
                                    T.reads(A[v0, v1])
                                    T.writes(A_reindex_shared_dyn[v0, v1])
                                    T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]], "meta_schedule.cooperative_fetch": 8})
                                    A_reindex_shared_dyn[v0, v1] = A[v0, v1]
                            for ax0_ax1_fused in range(262144):
                                with T.block("B_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(16384, ax2_0_0 * 512 + ax0_ax1_fused // 512)
                                    v1 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused % 16 * 1024 + ax0_0_1_ax1_0_1_fused % 2 * 512 + ax0_ax1_fused % 512)
                                    T.reads(B[v1, v0])
                                    T.writes(B_reindex_shared_dyn[v0, v1])
                                    T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]], "meta_schedule.cooperative_fetch": 4})
                                    B_reindex_shared_dyn[v0, v1] = B[v1, v0]
                            for ax2_0_1 in range(8):
                                for ax0_0, ax1_0 in T.grid(8, 4):
                                    with T.block("A_reindex_shared.dyn_wmma.matrix_a_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 16 * 512 + ax0_0_1_ax1_0_1_fused // 2 * 16 + ax0_0_2_ax1_0_2_fused // 2 * 8 + ax0_0)
                                        v1_o = T.axis.spatial(1024, ax2_0_0 * 32 + ax2_0_1 * 4 + ax1_0)
                                        T.reads(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_load_16x16x16_f16_a_shared_dyn"})
                                        for ax0_1, ax1_1 in T.grid(16, 16):
                                            with T.block("A_reindex_shared.dyn_wmma.matrix_a"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(A_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = A_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                                for ax0_0, ax1_0 in T.grid(4, 16):
                                    with T.block("B_reindex_shared.dyn_wmma.matrix_b_o"):
                                        v0_o = T.axis.spatial(1024, ax2_0_0 * 32 + ax2_0_1 * 4 + ax0_0)
                                        v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 16 * 64 + ax0_0_1_ax1_0_1_fused % 2 * 32 + ax0_0_2_ax1_0_2_fused % 2 * 16 + ax1_0)
                                        T.reads(B_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(B_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_load_16x16x16_f16_b_shared_dyn"})
                                        for ax0_1, ax1_1 in T.grid(16, 16):
                                            with T.block("B_reindex_shared.dyn_wmma.matrix_b"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(B_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.writes(B_reindex_shared_dyn_wmma_matrix_b[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                B_reindex_shared_dyn_wmma_matrix_b[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = B_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                                for ax0_0_3, ax1_0_3, ax2_0_2, ax0_0_4, ax1_0_4 in T.grid(4, 16, 4, 2, 1):
                                    with T.block("B_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 16 * 512 + ax0_0_1_ax1_0_1_fused // 2 * 16 + ax0_0_2_ax1_0_2_fused // 2 * 8 + ax0_0_3 * 2 + ax0_0_4)
                                        v1_o = T.axis.spatial(1024, ax1_0_4 + ax0_0_0_ax1_0_0_fused % 16 * 64 + ax0_0_1_ax1_0_1_fused % 2 * 32 + ax0_0_2_ax1_0_2_fused % 2 * 16 + ax1_0_3)
                                        v2_o = T.axis.reduce(1024, ax2_0_0 * 32 + ax2_0_1 * 4 + ax2_0_2)
                                        T.reads(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], B_reindex_shared_dyn_wmma_matrix_b[v2_o * 16:v2_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 8, v1_o // 16, v0_o % 8, v1_o % 16, 0:16, 0:16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_sync_16x16x16_f16f16f16", "meta_schedule.auto_tensorize_init": "wmma_fill_16x16x16_f16", "meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                                        with T.init():
                                            for ax0_1, ax1_1 in T.grid(16, 16):
                                                with T.block("B_init"):
                                                    v0_i_init, v1_i_init = T.axis.remap("SS", [ax0_1, ax1_1])
                                                    T.reads()
                                                    T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 8, v1_o // 16, v0_o % 8, v1_o % 16, v0_i_init, v1_i_init])
                                                    C_reindex_shared_dyn_wmma_accumulator[v0_o // 8, v1_o // 16, v0_o % 8, v1_o % 16, v0_i_init, v1_i_init] = T.float16(0)
                                        for ax0_1, ax1_1, ax2_1 in T.grid(16, 16, 16):
                                            with T.block("B"):
                                                v0_i, v1_i, v2_i = T.axis.remap("SSR", [ax0_1, ax1_1, ax2_1])
                                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o // 8, v1_o // 16, v0_o % 8, v1_o % 16, v0_i, v1_i], A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v2_o * 16 + v2_i], B_reindex_shared_dyn_wmma_matrix_b[v2_o * 16 + v2_i, v1_o * 16 + v1_i])
                                                T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 8, v1_o // 16, v0_o % 8, v1_o % 16, v0_i, v1_i])
                                                T.block_attr({"meta_schedule.tiling_structure": "SSSRRSRS"})
                                                C_reindex_shared_dyn_wmma_accumulator[v0_o // 8, v1_o // 16, v0_o % 8, v1_o % 16, v0_i, v1_i] = C_reindex_shared_dyn_wmma_accumulator[v0_o // 8, v1_o // 16, v0_o % 8, v1_o % 16, v0_i, v1_i] + A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v2_o * 16 + v2_i] * B_reindex_shared_dyn_wmma_matrix_b[v2_o * 16 + v2_i, v1_o * 16 + v1_i]
                    for ax2 in range(8):
                        for ax0_ax1_fused in T.thread_binding(4, thread="threadIdx.y"):
                            for ax2_1, ax3 in T.grid(1, 16):
                                with T.block("C_reindex_shared.dyn_wmma.accumulator_o"):
                                    v0 = T.axis.spatial(128, ax0_0_0_ax1_0_0_fused // 16 * 64 + ax0_0_1_ax1_0_1_fused // 2 * 2 + ax0_ax1_fused // 2)
                                    v1 = T.axis.spatial(64, ax0_0_0_ax1_0_0_fused % 16 * 4 + ax0_0_1_ax1_0_1_fused % 2 * 2 + ax0_ax1_fused % 2)
                                    v2 = T.axis.spatial(8, ax2 + ax2_1)
                                    v3 = T.axis.spatial(16, ax3)
                                    v4_o = T.axis.spatial(1, 0)
                                    v5_o = T.axis.spatial(1, 0)
                                    T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16])
                                    T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16])
                                    T.block_attr({"meta_schedule.auto_tensorize": "wmma_store_16x16x16_f16_shared_dyn"})
                                    for ax4, ax5 in T.grid(16, 16):
                                        with T.block("C_reindex_shared.dyn_wmma.accumulator"):
                                            v4_i, v5_i = T.axis.remap("SS", [ax4, ax5])
                                            T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, v4_i, v5_i])
                                            T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, v4_i, v5_i])
                                            C_reindex_shared_dyn[v0, v1, v2, v3, v4_i, v5_i] = C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, v4_i, v5_i]
                        for ax0_ax1_ax3_ax4_ax5_fused in range(16384):
                            with T.block("C_reindex_shared.dyn"):
                                v0 = T.axis.spatial(128, ax0_0_0_ax1_0_0_fused // 16 * 64 + ax0_0_1_ax1_0_1_fused // 2 * 2 + ax0_ax1_ax3_ax4_ax5_fused // 8192)
                                v1 = T.axis.spatial(64, ax0_0_0_ax1_0_0_fused % 16 * 4 + ax0_0_1_ax1_0_1_fused % 2 * 2 + ax0_ax1_ax3_ax4_ax5_fused % 8192 // 4096)
                                v2 = T.axis.spatial(8, ax2)
                                v3 = T.axis.spatial(16, ax0_ax1_ax3_ax4_ax5_fused % 4096 // 256)
                                v4 = T.axis.spatial(16, ax0_ax1_ax3_ax4_ax5_fused % 256 // 16)
                                v5 = T.axis.spatial(16, ax0_ax1_ax3_ax4_ax5_fused % 16)
                                T.reads(C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5])
                                T.writes(C[v4 + v2 * 16 + v0 * 128, v5 + v3 * 16 + v1 * 256])
                                T.block_attr({"meta_schedule.cooperative_fetch": 8})
                                C[v4 + v2 * 16 + v0 * 128, v5 + v3 * 16 + v1 * 256] = C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5]
b0 = sch.get_block(name="B", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
b2 = sch.reindex(block=b0, buffer=("write", 0))
b3 = sch.reindex(block=b0, buffer=("read", 0))
b4 = sch.reindex(block=b0, buffer=("read", 1))
sch.transform_layout(block=b0, buffer=("read", 0), index_map=lambda vi, vk: (vi, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b0, buffer=("read", 1), index_map=lambda vj, vk: (vk, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b0, buffer=("write", 0), index_map=lambda vi, vj: (vi, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_block_layout(block=b2, index_map=lambda vi, vj: (vi, vj,))
sch.transform_block_layout(block=b3, index_map=lambda vi, vk: (vi, vk,))
sch.transform_block_layout(block=b4, index_map=lambda vj, vk: (vk, vj,))
sch.transform_block_layout(block=b0, index_map=lambda vi, vj, vk: (vi, vj, vk,))
l5, l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, 16], preserve_unit_iters=True)
l10, l11 = sch.split(loop=l6, factors=[None, 16], preserve_unit_iters=True)
l12, l13 = sch.split(loop=l5, factors=[None, 16], preserve_unit_iters=True)
l14, l15, l16, l17, l18, l19 = sch.get_loops(block=b0)
sch.reorder(l16, l18, l13, l11, l9)
b20 = sch.blockize(loop=l13, preserve_unit_iters=True)
sch.annotate(block_or_loop=b20, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_sync_16x16x16_f16f16f16")
sch.annotate(block_or_loop=b20, ann_key="meta_schedule.auto_tensorize_init", ann_val="wmma_fill_16x16x16_f16")
sch.annotate(block_or_loop=b20, ann_key="warp_execution", ann_val=1)
l21, l22, l23 = sch.get_loops(block=b20)
v24, v25, v26, v27, v28 = sch.sample_perfect_tile(loop=l21, n=5, max_innermost_factor=4, decision=[2, 32, 2, 4, 2])
l29, l30, l31, l32, l33 = sch.split(loop=l21, factors=[v24, v25, v26, v27, v28], preserve_unit_iters=True)
v34, v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l22, n=5, max_innermost_factor=4, decision=[16, 2, 2, 16, 1])
l39, l40, l41, l42, l43 = sch.split(loop=l22, factors=[v34, v35, v36, v37, v38], preserve_unit_iters=True)
v44, v45, v46 = sch.sample_perfect_tile(loop=l23, n=3, max_innermost_factor=4, decision=[32, 8, 4])
l47, l48, l49 = sch.split(loop=l23, factors=[v44, v45, v46], preserve_unit_iters=True)
sch.reorder(l29, l39, l30, l40, l31, l41, l47, l48, l32, l42, l49, l33, l43)
l50 = sch.fuse(l29, l39, preserve_unit_iters=True)
sch.bind(loop=l50, thread_axis="blockIdx.y")
l51 = sch.fuse(l30, l40, preserve_unit_iters=True)
sch.bind(loop=l51, thread_axis="blockIdx.x")
l52 = sch.fuse(l31, l41, preserve_unit_iters=True)
sch.bind(loop=l52, thread_axis="threadIdx.y")
sch.annotate(block_or_loop=b20, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b20, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
sch.transform_layout(block=b20, buffer=("write", 0), index_map=lambda i0, i1: (i0 // 16 // (v27 * v28), i1 // 16 // (v37 * v38), i0 // 16 % (v27 * v28), i1 // 16 % (v37 * v38), i0 % 16, i1 % 16,), pad_value=None, assume_injective_transform=True)
b53 = sch.cache_write(block=b20, write_buffer_index=0, storage_scope="shared.dyn")
sch.reverse_compute_at(block=b53, loop=l51, preserve_unit_loops=True, index=-1)
b54 = sch.cache_write(block=b20, write_buffer_index=0, storage_scope="wmma.accumulator")
l55, l56, l57, l58, l59, l60, l61, l62 = sch.get_loops(block=b53)
sch.reorder(l59, l57, l58, l60)
sch.compute_at(block=b54, loop=l59, preserve_unit_loops=True, index=-1)
l63, l64, l65, l66, l67, l68, l69, l70, l71 = sch.get_loops(block=b54)
l72 = sch.fuse(l66, l67, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.y")
sch.reverse_compute_inline(block=b2)
l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b54)
b81 = sch.blockize(loop=l79, preserve_unit_iters=True)
sch.annotate(block_or_loop=b81, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_store_16x16x16_f16_shared_dyn")
l82, l83, l84, l85, l86, l87, l88, l89 = sch.get_loops(block=b53)
l90 = sch.fuse(l85, l86, l87, l88, l89, preserve_unit_iters=True)
v91 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b53, ann_key="meta_schedule.cooperative_fetch", ann_val=v91)
b92 = sch.cache_read(block=b20, read_buffer_index=0, storage_scope="shared.dyn", consumer_blocks=[b20])
sch.compute_at(block=b92, loop=l47, preserve_unit_loops=True, index=-1)
l93, l94, l95, l96, l97, l98 = sch.get_loops(block=b92)
l99 = sch.fuse(l97, l98, preserve_unit_iters=True)
v100 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b92, ann_key="meta_schedule.cooperative_fetch", ann_val=v100)
b101 = sch.cache_read(block=b20, read_buffer_index=1, storage_scope="shared.dyn", consumer_blocks=[b20])
sch.compute_at(block=b101, loop=l47, preserve_unit_loops=True, index=-1)
l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b101)
l108 = sch.fuse(l106, l107, preserve_unit_iters=True)
v109 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b101, ann_key="meta_schedule.cooperative_fetch", ann_val=v109)
b110 = sch.cache_read(block=b20, read_buffer_index=0, storage_scope="wmma.matrix_a")
sch.compute_at(block=b110, loop=l48, preserve_unit_loops=True, index=-1)
l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b110)
l118, l119 = sch.split(loop=l117, factors=[None, 16], preserve_unit_iters=True)
l120, l121 = sch.split(loop=l116, factors=[None, 16], preserve_unit_iters=True)
l122, l123, l124, l125, l126, l127, l128, l129, l130 = sch.get_loops(block=b110)
sch.reorder(l129, l121, l119)
b131 = sch.blockize(loop=l121, preserve_unit_iters=True)
sch.annotate(block_or_loop=b131, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_a_shared_dyn")
b132 = sch.cache_read(block=b20, read_buffer_index=1, storage_scope="wmma.matrix_b")
sch.compute_at(block=b132, loop=l48, preserve_unit_loops=True, index=-1)
l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b132)
l140, l141 = sch.split(loop=l139, factors=[None, 16], preserve_unit_iters=True)
l142, l143 = sch.split(loop=l138, factors=[None, 16], preserve_unit_iters=True)
l144, l145, l146, l147, l148, l149, l150, l151, l152 = sch.get_loops(block=b132)
sch.reorder(l151, l143, l141)
b153 = sch.blockize(loop=l143, preserve_unit_iters=True)
sch.annotate(block_or_loop=b153, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_b_shared_dyn")
sch.compute_inline(block=b3)
sch.compute_inline(block=b4)
sch.storage_align(block=b92, buffer_index=0, axis=-2, factor=32, offset=8)
sch.storage_align(block=b101, buffer_index=0, axis=-2, factor=32, offset=8)
v154 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v154)
2023-05-01 16:03:04 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 16384), "float16"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 64})
            C_reindex_shared_dyn = T.alloc_buffer((256, 32, 4, 32, 16, 16), "float16", scope="shared.dyn")
            C_reindex_shared_dyn_wmma_accumulator = T.alloc_buffer((256, 32, 4, 32, 16, 16), "float16", scope="wmma.accumulator")
            A_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            B_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            A_reindex_shared_dyn_wmma_matrix_a = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_a")
            B_reindex_shared_dyn_wmma_matrix_b = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_b")
            for ax0_0_0_ax1_0_0_fused in T.thread_binding(32, thread="blockIdx.y"):
                for ax0_0_1_ax1_0_1_fused in T.thread_binding(4, thread="blockIdx.x"):
                    for ax0_0_2_ax1_0_2_fused in T.thread_binding(64, thread="threadIdx.y"):
                        for ax2_0_0 in range(8):
                            for ax0_ax1_fused in range(1048576):
                                with T.block("A_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused // 4 * 2048 + ax0_0_1_ax1_0_1_fused * 512 + ax0_ax1_fused // 2048)
                                    v1 = T.axis.spatial(16384, ax2_0_0 * 2048 + ax0_ax1_fused % 2048)
                                    T.reads(A[v0, v1])
                                    T.writes(A_reindex_shared_dyn[v0, v1])
                                    T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]], "meta_schedule.cooperative_fetch": 8})
                                    A_reindex_shared_dyn[v0, v1] = A[v0, v1]
                            for ax0_ax1_fused in range(8388608):
                                with T.block("B_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused % 4 * 4096 + ax0_ax1_fused // 2048)
                                    v1 = T.axis.spatial(16384, ax2_0_0 * 2048 + ax0_ax1_fused % 2048)
                                    T.reads(B[v0, v1])
                                    T.writes(B_reindex_shared_dyn[v0, v1])
                                    T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]], "meta_schedule.cooperative_fetch": 4})
                                    B_reindex_shared_dyn[v0, v1] = B[v0, v1]
                            for ax2_0_1 in range(128):
                                for ax0_0, ax1_0 in T.grid(4, 1):
                                    with T.block("A_reindex_shared.dyn_wmma.matrix_a_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 4 * 128 + ax0_0_1_ax1_0_1_fused * 32 + ax0_0_2_ax1_0_2_fused // 8 * 4 + ax0_0)
                                        v1_o = T.axis.spatial(1024, ax2_0_0 * 128 + ax2_0_1 + ax1_0)
                                        T.reads(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_load_16x16x16_f16_a_shared_dyn"})
                                        for ax0_1, ax1_1 in T.grid(16, 16):
                                            with T.block("A_reindex_shared.dyn_wmma.matrix_a"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(A_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = A_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                                for ax0_0, ax1_0 in T.grid(32, 1):
                                    with T.block("B_reindex_shared.dyn_wmma.matrix_b_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 4 * 256 + ax0_0_2_ax1_0_2_fused % 8 * 32 + ax0_0)
                                        v1_o = T.axis.spatial(1024, ax2_0_0 * 128 + ax2_0_1 + ax1_0)
                                        T.reads(B_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(B_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_load_16x16x16_f16_b_trans_shared_dyn"})
                                        for ax0_1, ax1_1 in T.grid(16, 16):
                                            with T.block("B_reindex_shared.dyn_wmma.matrix_b"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(B_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.writes(B_reindex_shared_dyn_wmma_matrix_b[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                B_reindex_shared_dyn_wmma_matrix_b[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = B_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                                for ax0_0_3, ax1_0_3, ax2_0_2, ax0_0_4, ax1_0_4 in T.grid(4, 8, 1, 1, 4):
                                    with T.block("B_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 4 * 128 + ax0_0_1_ax1_0_1_fused * 32 + ax0_0_2_ax1_0_2_fused // 8 * 4 + ax0_0_3 + ax0_0_4)
                                        v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 4 * 256 + ax0_0_2_ax1_0_2_fused % 8 * 32 + ax1_0_3 * 4 + ax1_0_4)
                                        v2_o = T.axis.reduce(1024, ax2_0_0 * 128 + ax2_0_1 + ax2_0_2)
                                        T.reads(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], B_reindex_shared_dyn_wmma_matrix_b[v1_o * 16:v1_o * 16 + 16, v2_o * 16:v2_o * 16 + 16])
                                        T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 4, v1_o // 32, v0_o % 4, v1_o % 32, 0:16, 0:16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_sync_16x16x16_f16f16f16_trans", "meta_schedule.auto_tensorize_init": "wmma_fill_16x16x16_f16", "meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                                        with T.init():
                                            for ax0_1, ax1_1 in T.grid(16, 16):
                                                with T.block("B_init"):
                                                    v0_i_init, v1_i_init = T.axis.remap("SS", [ax0_1, ax1_1])
                                                    T.reads()
                                                    T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 4, v1_o // 32, v0_o % 4, v1_o % 32, v0_i_init, v1_i_init])
                                                    C_reindex_shared_dyn_wmma_accumulator[v0_o // 4, v1_o // 32, v0_o % 4, v1_o % 32, v0_i_init, v1_i_init] = T.float16(0)
                                        for ax0_1, ax1_1, ax2_1 in T.grid(16, 16, 16):
                                            with T.block("B"):
                                                v0_i, v1_i, v2_i = T.axis.remap("SSR", [ax0_1, ax1_1, ax2_1])
                                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o // 4, v1_o // 32, v0_o % 4, v1_o % 32, v0_i, v1_i], A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v2_o * 16 + v2_i], B_reindex_shared_dyn_wmma_matrix_b[v1_o * 16 + v1_i, v2_o * 16 + v2_i])
                                                T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 4, v1_o // 32, v0_o % 4, v1_o % 32, v0_i, v1_i])
                                                T.block_attr({"meta_schedule.tiling_structure": "SSSRRSRS"})
                                                C_reindex_shared_dyn_wmma_accumulator[v0_o // 4, v1_o // 32, v0_o % 4, v1_o % 32, v0_i, v1_i] = C_reindex_shared_dyn_wmma_accumulator[v0_o // 4, v1_o // 32, v0_o % 4, v1_o % 32, v0_i, v1_i] + A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v2_o * 16 + v2_i] * B_reindex_shared_dyn_wmma_matrix_b[v1_o * 16 + v1_i, v2_o * 16 + v2_i]
                    for ax2 in range(4):
                        for ax0_ax1_fused in T.thread_binding(64, thread="threadIdx.y"):
                            for ax2_1, ax3 in T.grid(1, 32):
                                with T.block("C_reindex_shared.dyn_wmma.accumulator_o"):
                                    v0 = T.axis.spatial(256, ax0_0_0_ax1_0_0_fused // 4 * 32 + ax0_0_1_ax1_0_1_fused * 8 + ax0_ax1_fused // 8)
                                    v1 = T.axis.spatial(32, ax0_0_0_ax1_0_0_fused % 4 * 8 + ax0_ax1_fused % 8)
                                    v2 = T.axis.spatial(4, ax2 + ax2_1)
                                    v3 = T.axis.spatial(32, ax3)
                                    v4_o = T.axis.spatial(1, 0)
                                    v5_o = T.axis.spatial(1, 0)
                                    T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16])
                                    T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16])
                                    T.block_attr({"meta_schedule.auto_tensorize": "wmma_store_16x16x16_f16_shared_dyn"})
                                    for ax4, ax5 in T.grid(16, 16):
                                        with T.block("C_reindex_shared.dyn_wmma.accumulator"):
                                            v4_i, v5_i = T.axis.remap("SS", [ax4, ax5])
                                            T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, v4_i, v5_i])
                                            T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, v4_i, v5_i])
                                            C_reindex_shared_dyn[v0, v1, v2, v3, v4_i, v5_i] = C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, v4_i, v5_i]
                        for ax0_ax1_ax3_ax4_ax5_fused in range(524288):
                            with T.block("C_reindex_shared.dyn"):
                                v0 = T.axis.spatial(256, ax0_0_0_ax1_0_0_fused // 4 * 32 + ax0_0_1_ax1_0_1_fused * 8 + ax0_ax1_ax3_ax4_ax5_fused // 65536)
                                v1 = T.axis.spatial(32, ax0_0_0_ax1_0_0_fused % 4 * 8 + ax0_ax1_ax3_ax4_ax5_fused % 65536 // 8192)
                                v2 = T.axis.spatial(4, ax2)
                                v3 = T.axis.spatial(32, ax0_ax1_ax3_ax4_ax5_fused % 8192 // 256)
                                v4 = T.axis.spatial(16, ax0_ax1_ax3_ax4_ax5_fused % 256 // 16)
                                v5 = T.axis.spatial(16, ax0_ax1_ax3_ax4_ax5_fused % 16)
                                T.reads(C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5])
                                T.writes(C[v4 + v2 * 16 + v0 * 64, v5 + v3 * 16 + v1 * 512])
                                T.block_attr({"meta_schedule.cooperative_fetch": 8})
                                C[v4 + v2 * 16 + v0 * 64, v5 + v3 * 16 + v1 * 512] = C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5]
b0 = sch.get_block(name="B", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
b2 = sch.reindex(block=b0, buffer=("write", 0))
b3 = sch.reindex(block=b0, buffer=("read", 0))
b4 = sch.reindex(block=b0, buffer=("read", 1))
sch.transform_layout(block=b0, buffer=("read", 0), index_map=lambda vi, vk: (vi, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b0, buffer=("read", 1), index_map=lambda vj, vk: (vj, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b0, buffer=("write", 0), index_map=lambda vi, vj: (vi, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_block_layout(block=b2, index_map=lambda vi, vj: (vi, vj,))
sch.transform_block_layout(block=b3, index_map=lambda vi, vk: (vi, vk,))
sch.transform_block_layout(block=b4, index_map=lambda vj, vk: (vj, vk,))
sch.transform_block_layout(block=b0, index_map=lambda vi, vj, vk: (vi, vj, vk,))
l5, l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, 16], preserve_unit_iters=True)
l10, l11 = sch.split(loop=l6, factors=[None, 16], preserve_unit_iters=True)
l12, l13 = sch.split(loop=l5, factors=[None, 16], preserve_unit_iters=True)
l14, l15, l16, l17, l18, l19 = sch.get_loops(block=b0)
sch.reorder(l16, l18, l13, l11, l9)
b20 = sch.blockize(loop=l13, preserve_unit_iters=True)
sch.annotate(block_or_loop=b20, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_sync_16x16x16_f16f16f16_trans")
sch.annotate(block_or_loop=b20, ann_key="meta_schedule.auto_tensorize_init", ann_val="wmma_fill_16x16x16_f16")
sch.annotate(block_or_loop=b20, ann_key="warp_execution", ann_val=1)
l21, l22, l23 = sch.get_loops(block=b20)
v24, v25, v26, v27, v28 = sch.sample_perfect_tile(loop=l21, n=5, max_innermost_factor=4, decision=[8, 4, 8, 4, 1])
l29, l30, l31, l32, l33 = sch.split(loop=l21, factors=[v24, v25, v26, v27, v28], preserve_unit_iters=True)
v34, v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l22, n=5, max_innermost_factor=4, decision=[4, 1, 8, 8, 4])
l39, l40, l41, l42, l43 = sch.split(loop=l22, factors=[v34, v35, v36, v37, v38], preserve_unit_iters=True)
v44, v45, v46 = sch.sample_perfect_tile(loop=l23, n=3, max_innermost_factor=4, decision=[8, 128, 1])
l47, l48, l49 = sch.split(loop=l23, factors=[v44, v45, v46], preserve_unit_iters=True)
sch.reorder(l29, l39, l30, l40, l31, l41, l47, l48, l32, l42, l49, l33, l43)
l50 = sch.fuse(l29, l39, preserve_unit_iters=True)
sch.bind(loop=l50, thread_axis="blockIdx.y")
l51 = sch.fuse(l30, l40, preserve_unit_iters=True)
sch.bind(loop=l51, thread_axis="blockIdx.x")
l52 = sch.fuse(l31, l41, preserve_unit_iters=True)
sch.bind(loop=l52, thread_axis="threadIdx.y")
sch.annotate(block_or_loop=b20, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b20, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
sch.transform_layout(block=b20, buffer=("write", 0), index_map=lambda i0, i1: (i0 // 16 // (v27 * v28), i1 // 16 // (v37 * v38), i0 // 16 % (v27 * v28), i1 // 16 % (v37 * v38), i0 % 16, i1 % 16,), pad_value=None, assume_injective_transform=True)
b53 = sch.cache_write(block=b20, write_buffer_index=0, storage_scope="shared.dyn")
sch.reverse_compute_at(block=b53, loop=l51, preserve_unit_loops=True, index=-1)
b54 = sch.cache_write(block=b20, write_buffer_index=0, storage_scope="wmma.accumulator")
l55, l56, l57, l58, l59, l60, l61, l62 = sch.get_loops(block=b53)
sch.reorder(l59, l57, l58, l60)
sch.compute_at(block=b54, loop=l59, preserve_unit_loops=True, index=-1)
l63, l64, l65, l66, l67, l68, l69, l70, l71 = sch.get_loops(block=b54)
l72 = sch.fuse(l66, l67, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.y")
sch.reverse_compute_inline(block=b2)
l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b54)
b81 = sch.blockize(loop=l79, preserve_unit_iters=True)
sch.annotate(block_or_loop=b81, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_store_16x16x16_f16_shared_dyn")
l82, l83, l84, l85, l86, l87, l88, l89 = sch.get_loops(block=b53)
l90 = sch.fuse(l85, l86, l87, l88, l89, preserve_unit_iters=True)
v91 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b53, ann_key="meta_schedule.cooperative_fetch", ann_val=v91)
b92 = sch.cache_read(block=b20, read_buffer_index=0, storage_scope="shared.dyn", consumer_blocks=[b20])
sch.compute_at(block=b92, loop=l47, preserve_unit_loops=True, index=-1)
l93, l94, l95, l96, l97, l98 = sch.get_loops(block=b92)
l99 = sch.fuse(l97, l98, preserve_unit_iters=True)
v100 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b92, ann_key="meta_schedule.cooperative_fetch", ann_val=v100)
b101 = sch.cache_read(block=b20, read_buffer_index=1, storage_scope="shared.dyn", consumer_blocks=[b20])
sch.compute_at(block=b101, loop=l47, preserve_unit_loops=True, index=-1)
l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b101)
l108 = sch.fuse(l106, l107, preserve_unit_iters=True)
v109 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b101, ann_key="meta_schedule.cooperative_fetch", ann_val=v109)
b110 = sch.cache_read(block=b20, read_buffer_index=0, storage_scope="wmma.matrix_a")
sch.compute_at(block=b110, loop=l48, preserve_unit_loops=True, index=-1)
l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b110)
l118, l119 = sch.split(loop=l117, factors=[None, 16], preserve_unit_iters=True)
l120, l121 = sch.split(loop=l116, factors=[None, 16], preserve_unit_iters=True)
l122, l123, l124, l125, l126, l127, l128, l129, l130 = sch.get_loops(block=b110)
sch.reorder(l129, l121, l119)
b131 = sch.blockize(loop=l121, preserve_unit_iters=True)
sch.annotate(block_or_loop=b131, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_a_shared_dyn")
b132 = sch.cache_read(block=b20, read_buffer_index=1, storage_scope="wmma.matrix_b")
sch.compute_at(block=b132, loop=l48, preserve_unit_loops=True, index=-1)
l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b132)
l140, l141 = sch.split(loop=l139, factors=[None, 16], preserve_unit_iters=True)
l142, l143 = sch.split(loop=l138, factors=[None, 16], preserve_unit_iters=True)
l144, l145, l146, l147, l148, l149, l150, l151, l152 = sch.get_loops(block=b132)
sch.reorder(l151, l143, l141)
b153 = sch.blockize(loop=l143, preserve_unit_iters=True)
sch.annotate(block_or_loop=b153, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_b_trans_shared_dyn")
sch.compute_inline(block=b3)
sch.compute_inline(block=b4)
sch.storage_align(block=b92, buffer_index=0, axis=-2, factor=32, offset=8)
sch.storage_align(block=b101, buffer_index=0, axis=-2, factor=32, offset=8)
v154 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v154)
2023-05-01 16:03:04 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 16:03:04 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2023-05-01 16:03:08 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x1ec6718)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1e39ca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1f5a7f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x1efb0e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1eea748)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1e38888)]: 497 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1e54338)]: 0 failure(s)
2023-05-01 16:03:13 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x1ec6718)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1e39ca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1f5a7f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x1efb0e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1eea748)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1e38888)]: 996 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1e54338)]: 0 failure(s)
2023-05-01 16:03:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x1ec6718)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1e39ca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1f5a7f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x1efb0e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1eea748)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1e38888)]: 1489 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1e54338)]: 0 failure(s)
2023-05-01 16:03:21 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x1ec6718)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1e39ca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1f5a7f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x1efb0e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1eea748)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1e38888)]: 1985 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1e54338)]: 0 failure(s)
2023-05-01 16:03:21 [INFO] [evolutionary_search.cc:723] Sampled 63 candidate(s)
2023-05-01 16:03:32 [INFO] [task_scheduler.cc:160] Initializing Task #0: "main"
2023-05-01 16:03:32 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 8192), "int8"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        B_decompress = T.alloc_buffer((16384, 16384), "float16")
        for i, j in T.grid(16384, 16384):
            with T.block("B_decompress"):
                vi, vj = T.axis.remap("SS", [i, j])
                T.reads(B[vi, vj // 2:vj // 2 + 2])
                T.writes(B_decompress[vi, vj])
                B_decompress[vi, vj] = T.Select(vj % 32 * 4 % 8 <= 5, T.Cast("float16", T.bitwise_and(T.shift_right(T.Cast("int32", B[vi, vj // 32 * 16 + vj % 32 * 4 // 8]), vj % 32 * 4 % 8), 15)), T.Cast("float16", T.bitwise_or(T.Cast("int8", T.bitwise_and(T.shift_right(T.Cast("int32", B[vi, vj // 32 * 16 + vj % 32 * 4 // 8]), vj % 32 * 4 % 8), T.shift_left(1, 8 - vj % 32 * 4 % 8) - 1)), T.Cast("int8", T.bitwise_and(T.bitwise_and(T.shift_left(T.Cast("int32", B[vi, vj // 32 * 16 + vj % 32 * 4 // 8 + 1]), 8 - vj % 32 * 4 % 8), T.shift_left(15, 8 - vj % 32 * 4 % 8)), 15)))))
        for i, j, k in T.grid(16384, 16384, 16384):
            with T.block("B"):
                vi, vj, vk = T.axis.remap("SSR", [i, j, k])
                T.reads(A[vi, vk], B_decompress[vj, vk])
                T.writes(C[vi, vj])
                with T.init():
                    C[vi, vj] = T.float16(0)
                C[vi, vj] = C[vi, vj] + A[vi, vk] * B_decompress[vj, vk]
2023-05-01 16:03:32 [INFO] [multi_level_tiling_tensor_core.cc:216] Sketch 0: tensorizing with wmma_sync_16x16x16_f16f16f16_trans
2023-05-01 16:03:32 [INFO] [multi_level_tiling_tensor_core.cc:216] Sketch 1: tensorizing with wmma_sync_16x16x16_f16f16f16
2023-05-01 16:03:32 [INFO] [task_scheduler.cc:164] Total 2 design space(s) generated
2023-05-01 16:03:32 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 8192), "int8"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 512})
            C_reindex_shared_dyn = T.alloc_buffer((16, 8, 64, 128, 16, 16), "float16", scope="shared.dyn")
            C_reindex_shared_dyn_wmma_accumulator = T.alloc_buffer((16, 8, 64, 128, 16, 16), "float16", scope="wmma.accumulator")
            A_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            B_decompress_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            A_reindex_shared_dyn_wmma_matrix_a = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_a")
            B_decompress_reindex_shared_dyn_wmma_matrix_b = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_b")
            for ax0_0_0_ax1_0_0_fused in T.thread_binding(16, thread="blockIdx.y"):
                for ax0_0_1_ax1_0_1_fused in T.thread_binding(2, thread="blockIdx.x"):
                    for ax0_0_2_ax1_0_2_fused in T.thread_binding(4, thread="threadIdx.y"):
                        for ax2_0_0 in range(64):
                            for ax0_ax1_fused in range(1048576):
                                with T.block("A_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused // 4 * 4096 + ax0_ax1_fused // 256)
                                    v1 = T.axis.spatial(16384, ax2_0_0 * 256 + ax0_ax1_fused % 256)
                                    T.reads(A[v0, v1])
                                    T.writes(A_reindex_shared_dyn[v0, v1])
                                    T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]], "meta_schedule.cooperative_fetch": 4})
                                    A_reindex_shared_dyn[v0, v1] = A[v0, v1]
                            for ax0_ax1_fused in range(524288):
                                with T.block("B_decompress_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(16384, ax2_0_0 * 256 + ax0_ax1_fused // 2048)
                                    v1 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused % 4 * 4096 + ax0_0_1_ax1_0_1_fused * 2048 + ax0_ax1_fused % 2048)
                                    T.reads(B[v1, v0 // 2:v0 // 2 + 2])
                                    T.writes(B_decompress_reindex_shared_dyn[v0, v1])
                                    T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]], "meta_schedule.cooperative_fetch": 8})
                                    B_decompress_reindex_shared_dyn[v0, v1] = T.Select(v0 % 32 * 4 % 8 <= 5, T.Cast("float16", T.bitwise_and(T.shift_right(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8]), v0 % 32 * 4 % 8), 15)), T.Cast("float16", T.bitwise_or(T.Cast("int8", T.bitwise_and(T.shift_right(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8]), v0 % 32 * 4 % 8), T.shift_left(1, 8 - v0 % 32 * 4 % 8) - 1)), T.Cast("int8", T.bitwise_and(T.bitwise_and(T.shift_left(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8 + 1]), 8 - v0 % 32 * 4 % 8), T.shift_left(15, 8 - v0 % 32 * 4 % 8)), 15)))))
                            for ax2_0_1 in range(8):
                                for ax0_0, ax1_0 in T.grid(64, 2):
                                    with T.block("A_reindex_shared.dyn_wmma.matrix_a_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 4 * 256 + ax0_0_2_ax1_0_2_fused * 64 + ax0_0)
                                        v1_o = T.axis.spatial(1024, ax2_0_0 * 16 + ax2_0_1 * 2 + ax1_0)
                                        T.reads(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_load_16x16x16_f16_a_shared_dyn"})
                                        for ax0_1, ax1_1 in T.grid(16, 16):
                                            with T.block("A_reindex_shared.dyn_wmma.matrix_a"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(A_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = A_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                                for ax0_0, ax1_0 in T.grid(2, 128):
                                    with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b_o"):
                                        v0_o = T.axis.spatial(1024, ax2_0_0 * 16 + ax2_0_1 * 2 + ax0_0)
                                        v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 4 * 256 + ax0_0_1_ax1_0_1_fused * 128 + ax1_0)
                                        T.reads(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_load_16x16x16_f16_b_shared_dyn"})
                                        for ax0_1, ax1_1 in T.grid(16, 16):
                                            with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(B_decompress_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = B_decompress_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                                for ax0_0_3, ax1_0_3, ax2_0_2, ax0_0_4, ax1_0_4 in T.grid(32, 128, 2, 2, 1):
                                    with T.block("B_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 4 * 256 + ax0_0_2_ax1_0_2_fused * 64 + ax0_0_3 * 2 + ax0_0_4)
                                        v1_o = T.axis.spatial(1024, ax1_0_4 + ax0_0_0_ax1_0_0_fused % 4 * 256 + ax0_0_1_ax1_0_1_fused * 128 + ax1_0_3)
                                        v2_o = T.axis.reduce(1024, ax2_0_0 * 16 + ax2_0_1 * 2 + ax2_0_2)
                                        T.reads(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], B_decompress_reindex_shared_dyn_wmma_matrix_b[v2_o * 16:v2_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 64, v1_o // 128, v0_o % 64, v1_o % 128, 0:16, 0:16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_sync_16x16x16_f16f16f16", "meta_schedule.auto_tensorize_init": "wmma_fill_16x16x16_f16", "meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                                        with T.init():
                                            for ax0_1, ax1_1 in T.grid(16, 16):
                                                with T.block("B_init"):
                                                    v0_i_init, v1_i_init = T.axis.remap("SS", [ax0_1, ax1_1])
                                                    T.reads()
                                                    T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 64, v1_o // 128, v0_o % 64, v1_o % 128, v0_i_init, v1_i_init])
                                                    C_reindex_shared_dyn_wmma_accumulator[v0_o // 64, v1_o // 128, v0_o % 64, v1_o % 128, v0_i_init, v1_i_init] = T.float16(0)
                                        for ax0_1, ax1_1, ax2_1 in T.grid(16, 16, 16):
                                            with T.block("B"):
                                                v0_i, v1_i, v2_i = T.axis.remap("SSR", [ax0_1, ax1_1, ax2_1])
                                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o // 64, v1_o // 128, v0_o % 64, v1_o % 128, v0_i, v1_i], A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v2_o * 16 + v2_i], B_decompress_reindex_shared_dyn_wmma_matrix_b[v2_o * 16 + v2_i, v1_o * 16 + v1_i])
                                                T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 64, v1_o // 128, v0_o % 64, v1_o % 128, v0_i, v1_i])
                                                T.block_attr({"meta_schedule.tiling_structure": "SSSRRSRS"})
                                                C_reindex_shared_dyn_wmma_accumulator[v0_o // 64, v1_o // 128, v0_o % 64, v1_o % 128, v0_i, v1_i] = C_reindex_shared_dyn_wmma_accumulator[v0_o // 64, v1_o // 128, v0_o % 64, v1_o % 128, v0_i, v1_i] + A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v2_o * 16 + v2_i] * B_decompress_reindex_shared_dyn_wmma_matrix_b[v2_o * 16 + v2_i, v1_o * 16 + v1_i]
                    for ax2 in range(64):
                        for ax0_ax1_fused in T.thread_binding(4, thread="threadIdx.y"):
                            for ax2_1, ax3 in T.grid(1, 128):
                                with T.block("C_reindex_shared.dyn_wmma.accumulator_o"):
                                    v0 = T.axis.spatial(16, ax0_0_0_ax1_0_0_fused // 4 * 4 + ax0_ax1_fused)
                                    v1 = T.axis.spatial(8, ax0_0_0_ax1_0_0_fused % 4 * 2 + ax0_0_1_ax1_0_1_fused)
                                    v2 = T.axis.spatial(64, ax2 + ax2_1)
                                    v3 = T.axis.spatial(128, ax3)
                                    v4_o = T.axis.spatial(1, 0)
                                    v5_o = T.axis.spatial(1, 0)
                                    T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16])
                                    T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16])
                                    T.block_attr({"meta_schedule.auto_tensorize": "wmma_store_16x16x16_f16_shared_dyn"})
                                    for ax4, ax5 in T.grid(16, 16):
                                        with T.block("C_reindex_shared.dyn_wmma.accumulator"):
                                            v4_i, v5_i = T.axis.remap("SS", [ax4, ax5])
                                            T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, v4_i, v5_i])
                                            T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, v4_i, v5_i])
                                            C_reindex_shared_dyn[v0, v1, v2, v3, v4_i, v5_i] = C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, v4_i, v5_i]
                        for ax0_ax1_ax3_ax4_ax5_fused in range(131072):
                            with T.block("C_reindex_shared.dyn"):
                                v0 = T.axis.spatial(16, ax0_0_0_ax1_0_0_fused // 4 * 4 + ax0_ax1_ax3_ax4_ax5_fused // 32768)
                                v1 = T.axis.spatial(8, ax0_0_0_ax1_0_0_fused % 4 * 2 + ax0_0_1_ax1_0_1_fused)
                                v2 = T.axis.spatial(64, ax2)
                                v3 = T.axis.spatial(128, ax0_ax1_ax3_ax4_ax5_fused % 32768 // 256)
                                v4 = T.axis.spatial(16, ax0_ax1_ax3_ax4_ax5_fused % 256 // 16)
                                v5 = T.axis.spatial(16, ax0_ax1_ax3_ax4_ax5_fused % 16)
                                T.reads(C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5])
                                T.writes(C[v4 + v2 * 16 + v0 * 1024, v5 + v3 * 16 + v1 * 2048])
                                T.block_attr({"meta_schedule.cooperative_fetch": 4})
                                C[v4 + v2 * 16 + v0 * 1024, v5 + v3 * 16 + v1 * 2048] = C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5]
b0 = sch.get_block(name="B_decompress", func_name="main")
b1 = sch.get_block(name="B", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
b3 = sch.reindex(block=b1, buffer=("write", 0))
b4 = sch.reindex(block=b1, buffer=("read", 0))
b5 = sch.reindex(block=b1, buffer=("read", 1))
sch.transform_layout(block=b1, buffer=("read", 0), index_map=lambda vi, vk: (vi, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("read", 1), index_map=lambda vj, vk: (vk, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("write", 0), index_map=lambda vi, vj: (vi, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_block_layout(block=b3, index_map=lambda vi, vj: (vi, vj,))
sch.transform_block_layout(block=b4, index_map=lambda vi, vk: (vi, vk,))
sch.transform_block_layout(block=b5, index_map=lambda vj, vk: (vk, vj,))
sch.transform_block_layout(block=b1, index_map=lambda vi, vj, vk: (vi, vj, vk,))
l6, l7, l8 = sch.get_loops(block=b1)
l9, l10 = sch.split(loop=l8, factors=[None, 16], preserve_unit_iters=True)
l11, l12 = sch.split(loop=l7, factors=[None, 16], preserve_unit_iters=True)
l13, l14 = sch.split(loop=l6, factors=[None, 16], preserve_unit_iters=True)
l15, l16, l17, l18, l19, l20 = sch.get_loops(block=b1)
sch.reorder(l17, l19, l14, l12, l10)
b21 = sch.blockize(loop=l14, preserve_unit_iters=True)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_sync_16x16x16_f16f16f16")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize_init", ann_val="wmma_fill_16x16x16_f16")
sch.annotate(block_or_loop=b21, ann_key="warp_execution", ann_val=1)
l22, l23, l24 = sch.get_loops(block=b21)
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l22, n=5, max_innermost_factor=4, decision=[4, 1, 4, 32, 2])
l30, l31, l32, l33, l34 = sch.split(loop=l22, factors=[v25, v26, v27, v28, v29], preserve_unit_iters=True)
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l23, n=5, max_innermost_factor=4, decision=[4, 2, 1, 128, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l23, factors=[v35, v36, v37, v38, v39], preserve_unit_iters=True)
v45, v46, v47 = sch.sample_perfect_tile(loop=l24, n=3, max_innermost_factor=4, decision=[64, 8, 2])
l48, l49, l50 = sch.split(loop=l24, factors=[v45, v46, v47], preserve_unit_iters=True)
sch.reorder(l30, l40, l31, l41, l32, l42, l48, l49, l33, l43, l50, l34, l44)
l51 = sch.fuse(l30, l40, preserve_unit_iters=True)
sch.bind(loop=l51, thread_axis="blockIdx.y")
l52 = sch.fuse(l31, l41, preserve_unit_iters=True)
sch.bind(loop=l52, thread_axis="blockIdx.x")
l53 = sch.fuse(l32, l42, preserve_unit_iters=True)
sch.bind(loop=l53, thread_axis="threadIdx.y")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
sch.transform_layout(block=b21, buffer=("write", 0), index_map=lambda i0, i1: (i0 // 16 // (v28 * v29), i1 // 16 // (v38 * v39), i0 // 16 % (v28 * v29), i1 // 16 % (v38 * v39), i0 % 16, i1 % 16,), pad_value=None, assume_injective_transform=True)
b54 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="shared.dyn")
sch.reverse_compute_at(block=b54, loop=l52, preserve_unit_loops=True, index=-1)
b55 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="wmma.accumulator")
l56, l57, l58, l59, l60, l61, l62, l63 = sch.get_loops(block=b54)
sch.reorder(l60, l58, l59, l61)
sch.compute_at(block=b55, loop=l60, preserve_unit_loops=True, index=-1)
l64, l65, l66, l67, l68, l69, l70, l71, l72 = sch.get_loops(block=b55)
l73 = sch.fuse(l67, l68, preserve_unit_iters=True)
sch.bind(loop=l73, thread_axis="threadIdx.y")
sch.reverse_compute_inline(block=b3)
l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b55)
b82 = sch.blockize(loop=l80, preserve_unit_iters=True)
sch.annotate(block_or_loop=b82, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_store_16x16x16_f16_shared_dyn")
l83, l84, l85, l86, l87, l88, l89, l90 = sch.get_loops(block=b54)
l91 = sch.fuse(l86, l87, l88, l89, l90, preserve_unit_iters=True)
v92 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch", ann_val=v92)
b93 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b93, loop=l48, preserve_unit_loops=True, index=-1)
l94, l95, l96, l97, l98, l99 = sch.get_loops(block=b93)
l100 = sch.fuse(l98, l99, preserve_unit_iters=True)
v101 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch", ann_val=v101)
b102 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b102, loop=l48, preserve_unit_loops=True, index=-1)
l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b102)
l109 = sch.fuse(l107, l108, preserve_unit_iters=True)
v110 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch", ann_val=v110)
b111 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="wmma.matrix_a")
sch.compute_at(block=b111, loop=l49, preserve_unit_loops=True, index=-1)
l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b111)
l119, l120 = sch.split(loop=l118, factors=[None, 16], preserve_unit_iters=True)
l121, l122 = sch.split(loop=l117, factors=[None, 16], preserve_unit_iters=True)
l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b111)
sch.reorder(l130, l122, l120)
b132 = sch.blockize(loop=l122, preserve_unit_iters=True)
sch.annotate(block_or_loop=b132, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_a_shared_dyn")
b133 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="wmma.matrix_b")
sch.compute_at(block=b133, loop=l49, preserve_unit_loops=True, index=-1)
l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b133)
l141, l142 = sch.split(loop=l140, factors=[None, 16], preserve_unit_iters=True)
l143, l144 = sch.split(loop=l139, factors=[None, 16], preserve_unit_iters=True)
l145, l146, l147, l148, l149, l150, l151, l152, l153 = sch.get_loops(block=b133)
sch.reorder(l152, l144, l142)
b154 = sch.blockize(loop=l144, preserve_unit_iters=True)
sch.annotate(block_or_loop=b154, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_b_shared_dyn")
sch.compute_inline(block=b4)
sch.compute_inline(block=b5)
sch.storage_align(block=b93, buffer_index=0, axis=-2, factor=32, offset=8)
sch.storage_align(block=b102, buffer_index=0, axis=-2, factor=32, offset=8)
sch.compute_inline(block=b0)
v155 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v155)
2023-05-01 16:03:32 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 8192), "int8"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 16})
            C_reindex_shared_dyn = T.alloc_buffer((256, 64, 4, 16, 16, 16), "float16", scope="shared.dyn")
            C_reindex_shared_dyn_wmma_accumulator = T.alloc_buffer((256, 64, 4, 16, 16, 16), "float16", scope="wmma.accumulator")
            A_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            B_decompress_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            A_reindex_shared_dyn_wmma_matrix_a = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_a")
            B_decompress_reindex_shared_dyn_wmma_matrix_b = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_b")
            for ax0_0_0_ax1_0_0_fused in T.thread_binding(512, thread="blockIdx.y"):
                for ax0_0_1_ax1_0_1_fused in T.thread_binding(32, thread="blockIdx.x"):
                    for ax0_0_2_ax1_0_2_fused in T.thread_binding(1, thread="threadIdx.y"):
                        for ax2_0_0 in range(8):
                            for ax0_ax1_fused in range(131072):
                                with T.block("A_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused // 16 * 512 + ax0_0_1_ax1_0_1_fused // 4 * 64 + ax0_ax1_fused // 2048)
                                    v1 = T.axis.spatial(16384, ax2_0_0 * 2048 + ax0_ax1_fused % 2048)
                                    T.reads(A[v0, v1])
                                    T.writes(A_reindex_shared_dyn[v0, v1])
                                    T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]], "meta_schedule.cooperative_fetch": 8})
                                    A_reindex_shared_dyn[v0, v1] = A[v0, v1]
                            for ax0_ax1_fused in range(524288):
                                with T.block("B_decompress_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused % 16 * 1024 + ax0_0_1_ax1_0_1_fused % 4 * 256 + ax0_ax1_fused // 2048)
                                    v1 = T.axis.spatial(16384, ax2_0_0 * 2048 + ax0_ax1_fused % 2048)
                                    T.reads(B[v0, v1 // 2:v1 // 2 + 2])
                                    T.writes(B_decompress_reindex_shared_dyn[v0, v1])
                                    T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]], "meta_schedule.cooperative_fetch": 1})
                                    B_decompress_reindex_shared_dyn[v0, v1] = T.Select(v1 % 32 * 4 % 8 <= 5, T.Cast("float16", T.bitwise_and(T.shift_right(T.Cast("int32", B[v0, v1 // 32 * 16 + v1 % 32 * 4 // 8]), v1 % 32 * 4 % 8), 15)), T.Cast("float16", T.bitwise_or(T.Cast("int8", T.bitwise_and(T.shift_right(T.Cast("int32", B[v0, v1 // 32 * 16 + v1 % 32 * 4 // 8]), v1 % 32 * 4 % 8), T.shift_left(1, 8 - v1 % 32 * 4 % 8) - 1)), T.Cast("int8", T.bitwise_and(T.bitwise_and(T.shift_left(T.Cast("int32", B[v0, v1 // 32 * 16 + v1 % 32 * 4 // 8 + 1]), 8 - v1 % 32 * 4 % 8), T.shift_left(15, 8 - v1 % 32 * 4 % 8)), 15)))))
                            for ax2_0_1 in range(32):
                                for ax0_0, ax1_0 in T.grid(4, 4):
                                    with T.block("A_reindex_shared.dyn_wmma.matrix_a_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 16 * 32 + ax0_0_1_ax1_0_1_fused // 4 * 4 + ax0_0)
                                        v1_o = T.axis.spatial(1024, ax2_0_0 * 128 + ax2_0_1 * 4 + ax1_0)
                                        T.reads(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_load_16x16x16_f16_a_shared_dyn"})
                                        for ax0_1, ax1_1 in T.grid(16, 16):
                                            with T.block("A_reindex_shared.dyn_wmma.matrix_a"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(A_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = A_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                                for ax0_0, ax1_0 in T.grid(16, 4):
                                    with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 16 * 64 + ax0_0_1_ax1_0_1_fused % 4 * 16 + ax0_0)
                                        v1_o = T.axis.spatial(1024, ax2_0_0 * 128 + ax2_0_1 * 4 + ax1_0)
                                        T.reads(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_load_16x16x16_f16_b_trans_shared_dyn"})
                                        for ax0_1, ax1_1 in T.grid(16, 16):
                                            with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(B_decompress_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = B_decompress_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                                for ax0_0_3, ax1_0_3, ax2_0_2, ax0_0_4, ax1_0_4 in T.grid(1, 16, 4, 4, 1):
                                    with T.block("B_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 16 * 32 + ax0_0_1_ax1_0_1_fused // 4 * 4 + ax0_0_3 * 4 + ax0_0_4)
                                        v1_o = T.axis.spatial(1024, ax1_0_4 + ax0_0_0_ax1_0_0_fused % 16 * 64 + ax0_0_1_ax1_0_1_fused % 4 * 16 + ax1_0_3)
                                        v2_o = T.axis.reduce(1024, ax2_0_0 * 128 + ax2_0_1 * 4 + ax2_0_2)
                                        T.reads(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], B_decompress_reindex_shared_dyn_wmma_matrix_b[v1_o * 16:v1_o * 16 + 16, v2_o * 16:v2_o * 16 + 16])
                                        T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 4, v1_o // 16, v0_o % 4, v1_o % 16, 0:16, 0:16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_sync_16x16x16_f16f16f16_trans", "meta_schedule.auto_tensorize_init": "wmma_fill_16x16x16_f16", "meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                                        with T.init():
                                            for ax0_1, ax1_1 in T.grid(16, 16):
                                                with T.block("B_init"):
                                                    v0_i_init, v1_i_init = T.axis.remap("SS", [ax0_1, ax1_1])
                                                    T.reads()
                                                    T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 4, v1_o // 16, v0_o % 4, v1_o % 16, v0_i_init, v1_i_init])
                                                    C_reindex_shared_dyn_wmma_accumulator[v0_o // 4, v1_o // 16, v0_o % 4, v1_o % 16, v0_i_init, v1_i_init] = T.float16(0)
                                        for ax0_1, ax1_1, ax2_1 in T.grid(16, 16, 16):
                                            with T.block("B"):
                                                v0_i, v1_i, v2_i = T.axis.remap("SSR", [ax0_1, ax1_1, ax2_1])
                                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o // 4, v1_o // 16, v0_o % 4, v1_o % 16, v0_i, v1_i], A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v2_o * 16 + v2_i], B_decompress_reindex_shared_dyn_wmma_matrix_b[v1_o * 16 + v1_i, v2_o * 16 + v2_i])
                                                T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 4, v1_o // 16, v0_o % 4, v1_o % 16, v0_i, v1_i])
                                                T.block_attr({"meta_schedule.tiling_structure": "SSSRRSRS"})
                                                C_reindex_shared_dyn_wmma_accumulator[v0_o // 4, v1_o // 16, v0_o % 4, v1_o % 16, v0_i, v1_i] = C_reindex_shared_dyn_wmma_accumulator[v0_o // 4, v1_o // 16, v0_o % 4, v1_o % 16, v0_i, v1_i] + A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v2_o * 16 + v2_i] * B_decompress_reindex_shared_dyn_wmma_matrix_b[v1_o * 16 + v1_i, v2_o * 16 + v2_i]
                    for ax2 in range(4):
                        for ax0_ax1_fused in T.thread_binding(1, thread="threadIdx.y"):
                            for ax2_1, ax3 in T.grid(1, 16):
                                with T.block("C_reindex_shared.dyn_wmma.accumulator_o"):
                                    v0 = T.axis.spatial(256, ax0_0_0_ax1_0_0_fused // 16 * 8 + ax0_0_1_ax1_0_1_fused // 4)
                                    v1 = T.axis.spatial(64, ax0_0_0_ax1_0_0_fused % 16 * 4 + ax0_0_1_ax1_0_1_fused % 4)
                                    v2 = T.axis.spatial(4, ax2 + ax2_1)
                                    v3 = T.axis.spatial(16, ax3)
                                    v4_o = T.axis.spatial(1, 0)
                                    v5_o = T.axis.spatial(1, 0)
                                    T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16])
                                    T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16])
                                    T.block_attr({"meta_schedule.auto_tensorize": "wmma_store_16x16x16_f16_shared_dyn"})
                                    for ax4, ax5 in T.grid(16, 16):
                                        with T.block("C_reindex_shared.dyn_wmma.accumulator"):
                                            v4_i, v5_i = T.axis.remap("SS", [ax4, ax5])
                                            T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, v4_i, v5_i])
                                            T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, v4_i, v5_i])
                                            C_reindex_shared_dyn[v0, v1, v2, v3, v4_i, v5_i] = C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, v4_i, v5_i]
                        for ax0_ax1_ax3_ax4_ax5_fused in range(4096):
                            with T.block("C_reindex_shared.dyn"):
                                v0 = T.axis.spatial(256, ax0_0_0_ax1_0_0_fused // 16 * 8 + ax0_0_1_ax1_0_1_fused // 4)
                                v1 = T.axis.spatial(64, ax0_0_0_ax1_0_0_fused % 16 * 4 + ax0_0_1_ax1_0_1_fused % 4)
                                v2 = T.axis.spatial(4, ax2)
                                v3 = T.axis.spatial(16, ax0_ax1_ax3_ax4_ax5_fused // 256)
                                v4 = T.axis.spatial(16, ax0_ax1_ax3_ax4_ax5_fused % 256 // 16)
                                v5 = T.axis.spatial(16, ax0_ax1_ax3_ax4_ax5_fused % 16)
                                T.reads(C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5])
                                T.writes(C[v4 + v2 * 16 + v0 * 64, v5 + v3 * 16 + v1 * 256])
                                T.block_attr({"meta_schedule.cooperative_fetch": 2})
                                C[v4 + v2 * 16 + v0 * 64, v5 + v3 * 16 + v1 * 256] = C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5]
b0 = sch.get_block(name="B_decompress", func_name="main")
b1 = sch.get_block(name="B", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
b3 = sch.reindex(block=b1, buffer=("write", 0))
b4 = sch.reindex(block=b1, buffer=("read", 0))
b5 = sch.reindex(block=b1, buffer=("read", 1))
sch.transform_layout(block=b1, buffer=("read", 0), index_map=lambda vi, vk: (vi, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("read", 1), index_map=lambda vj, vk: (vj, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("write", 0), index_map=lambda vi, vj: (vi, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_block_layout(block=b3, index_map=lambda vi, vj: (vi, vj,))
sch.transform_block_layout(block=b4, index_map=lambda vi, vk: (vi, vk,))
sch.transform_block_layout(block=b5, index_map=lambda vj, vk: (vj, vk,))
sch.transform_block_layout(block=b1, index_map=lambda vi, vj, vk: (vi, vj, vk,))
l6, l7, l8 = sch.get_loops(block=b1)
l9, l10 = sch.split(loop=l8, factors=[None, 16], preserve_unit_iters=True)
l11, l12 = sch.split(loop=l7, factors=[None, 16], preserve_unit_iters=True)
l13, l14 = sch.split(loop=l6, factors=[None, 16], preserve_unit_iters=True)
l15, l16, l17, l18, l19, l20 = sch.get_loops(block=b1)
sch.reorder(l17, l19, l14, l12, l10)
b21 = sch.blockize(loop=l14, preserve_unit_iters=True)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_sync_16x16x16_f16f16f16_trans")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize_init", ann_val="wmma_fill_16x16x16_f16")
sch.annotate(block_or_loop=b21, ann_key="warp_execution", ann_val=1)
l22, l23, l24 = sch.get_loops(block=b21)
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l22, n=5, max_innermost_factor=4, decision=[32, 8, 1, 1, 4])
l30, l31, l32, l33, l34 = sch.split(loop=l22, factors=[v25, v26, v27, v28, v29], preserve_unit_iters=True)
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l23, n=5, max_innermost_factor=4, decision=[16, 4, 1, 16, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l23, factors=[v35, v36, v37, v38, v39], preserve_unit_iters=True)
v45, v46, v47 = sch.sample_perfect_tile(loop=l24, n=3, max_innermost_factor=4, decision=[8, 32, 4])
l48, l49, l50 = sch.split(loop=l24, factors=[v45, v46, v47], preserve_unit_iters=True)
sch.reorder(l30, l40, l31, l41, l32, l42, l48, l49, l33, l43, l50, l34, l44)
l51 = sch.fuse(l30, l40, preserve_unit_iters=True)
sch.bind(loop=l51, thread_axis="blockIdx.y")
l52 = sch.fuse(l31, l41, preserve_unit_iters=True)
sch.bind(loop=l52, thread_axis="blockIdx.x")
l53 = sch.fuse(l32, l42, preserve_unit_iters=True)
sch.bind(loop=l53, thread_axis="threadIdx.y")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
sch.transform_layout(block=b21, buffer=("write", 0), index_map=lambda i0, i1: (i0 // 16 // (v28 * v29), i1 // 16 // (v38 * v39), i0 // 16 % (v28 * v29), i1 // 16 % (v38 * v39), i0 % 16, i1 % 16,), pad_value=None, assume_injective_transform=True)
b54 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="shared.dyn")
sch.reverse_compute_at(block=b54, loop=l52, preserve_unit_loops=True, index=-1)
b55 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="wmma.accumulator")
l56, l57, l58, l59, l60, l61, l62, l63 = sch.get_loops(block=b54)
sch.reorder(l60, l58, l59, l61)
sch.compute_at(block=b55, loop=l60, preserve_unit_loops=True, index=-1)
l64, l65, l66, l67, l68, l69, l70, l71, l72 = sch.get_loops(block=b55)
l73 = sch.fuse(l67, l68, preserve_unit_iters=True)
sch.bind(loop=l73, thread_axis="threadIdx.y")
sch.reverse_compute_inline(block=b3)
l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b55)
b82 = sch.blockize(loop=l80, preserve_unit_iters=True)
sch.annotate(block_or_loop=b82, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_store_16x16x16_f16_shared_dyn")
l83, l84, l85, l86, l87, l88, l89, l90 = sch.get_loops(block=b54)
l91 = sch.fuse(l86, l87, l88, l89, l90, preserve_unit_iters=True)
v92 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch", ann_val=v92)
b93 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b93, loop=l48, preserve_unit_loops=True, index=-1)
l94, l95, l96, l97, l98, l99 = sch.get_loops(block=b93)
l100 = sch.fuse(l98, l99, preserve_unit_iters=True)
v101 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch", ann_val=v101)
b102 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b102, loop=l48, preserve_unit_loops=True, index=-1)
l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b102)
l109 = sch.fuse(l107, l108, preserve_unit_iters=True)
v110 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch", ann_val=v110)
b111 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="wmma.matrix_a")
sch.compute_at(block=b111, loop=l49, preserve_unit_loops=True, index=-1)
l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b111)
l119, l120 = sch.split(loop=l118, factors=[None, 16], preserve_unit_iters=True)
l121, l122 = sch.split(loop=l117, factors=[None, 16], preserve_unit_iters=True)
l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b111)
sch.reorder(l130, l122, l120)
b132 = sch.blockize(loop=l122, preserve_unit_iters=True)
sch.annotate(block_or_loop=b132, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_a_shared_dyn")
b133 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="wmma.matrix_b")
sch.compute_at(block=b133, loop=l49, preserve_unit_loops=True, index=-1)
l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b133)
l141, l142 = sch.split(loop=l140, factors=[None, 16], preserve_unit_iters=True)
l143, l144 = sch.split(loop=l139, factors=[None, 16], preserve_unit_iters=True)
l145, l146, l147, l148, l149, l150, l151, l152, l153 = sch.get_loops(block=b133)
sch.reorder(l152, l144, l142)
b154 = sch.blockize(loop=l144, preserve_unit_iters=True)
sch.annotate(block_or_loop=b154, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_b_trans_shared_dyn")
sch.compute_inline(block=b4)
sch.compute_inline(block=b5)
sch.storage_align(block=b93, buffer_index=0, axis=-2, factor=32, offset=8)
sch.storage_align(block=b102, buffer_index=0, axis=-2, factor=32, offset=8)
sch.compute_inline(block=b0)
v155 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v155)
2023-05-01 16:03:32 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 16:03:32 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2023-05-01 16:03:36 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 497 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:03:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 998 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:03:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1491 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:03:50 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1990 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:03:50 [INFO] [evolutionary_search.cc:723] Sampled 58 candidate(s)
2023-05-01 16:03:57 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 115 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:04:02 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 82 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:04:09 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 94 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:04:15 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 89 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:04:15 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9999  0.9997  0.9997  0.9996  0.9992  0.9978  0.9977  0.9970  0.9963  0.9960  0.9951  0.9940  0.9933  0.9931  0.9927  0.9922
2023-05-01 16:04:15 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 16:04:15 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 16:11:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #1: GFLOPs: 17308.2264. Time: 508451.1717 us. Best GFLOPs: 17308.2264
2023-05-01 16:11:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #2: GFLOPs: 42782.4588. Time: 205700.8463 us. Best GFLOPs: 42782.4588
2023-05-01 16:11:27 [INFO] [task_scheduler.cc:121] [Task #0: main] Trial #3: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 8192), "int8"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        C_reindex_shared_dyn = T.alloc_buffer((512, 256, 2, 4, 16, 16), "float16", scope="shared.dyn")
        C_reindex_shared_dyn_wmma_accumulator = T.alloc_buffer((512, 256, 2, 4, 16, 16), "float16", scope="wmma.accumulator")
        A_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
        B_decompress_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
        A_reindex_shared_dyn_wmma_matrix_a = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_a")
        B_decompress_reindex_shared_dyn_wmma_matrix_b = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_b")
        for ax0_0_0_ax1_0_0_fused in T.thread_binding(64, thread="blockIdx.y", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0_0_1_ax1_0_1_fused in T.thread_binding(512, thread="blockIdx.x"):
                for ax0_0_2_ax1_0_2_fused in T.thread_binding(4, thread="threadIdx.y"):
                    for ax0_0_3_init, ax1_0_3_init, ax0_0_4_init, ax1_0_4_init in T.grid(2, 1, 1, 4):
                        with T.block("B_o_init"):
                            v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 2 * 32 + ax0_0_1_ax1_0_1_fused // 32 * 2 + ax0_0_3_init + ax0_0_4_init)
                            v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 2 * 512 + ax0_0_1_ax1_0_1_fused % 32 * 16 + ax0_0_2_ax1_0_2_fused * 4 + ax1_0_3_init * 4 + ax1_0_4_init)
                            T.reads()
                            T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 2, v1_o // 4, v0_o % 2, v1_o % 4, 0:16, 0:16])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                            C_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0_o // 2, v1_o // 4, v0_o % 2, v1_o % 4, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.accumulator", offset_factor=16)
                            T.tvm_fill_fragment(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.float32(0))
                    for ax2_0_0 in range(1024):
                        for ax0_ax1_fused_0 in range(1):
                            for ax0_ax1_fused_1 in T.thread_binding(4, thread="threadIdx.y"):
                                for ax0_ax1_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                    for ax0_ax1_fused_3 in T.vectorized(4):
                                        with T.block("A_reindex_shared.dyn"):
                                            v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused // 2 * 512 + ax0_0_1_ax1_0_1_fused // 32 * 32 + (ax0_ax1_fused_0 * 512 + ax0_ax1_fused_1 * 128 + ax0_ax1_fused_2 * 4 + ax0_ax1_fused_3) // 16)
                                            v1 = T.axis.spatial(16384, ax2_0_0 * 16 + (ax0_ax1_fused_0 * 512 + ax0_ax1_fused_1 * 128 + ax0_ax1_fused_2 * 4 + ax0_ax1_fused_3) % 16)
                                            T.reads(A[v0, v1])
                                            T.writes(A_reindex_shared_dyn[v0, v1])
                                            T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]]})
                                            A_reindex_shared_dyn[v0, v1] = A[v0, v1]
                        for ax0_ax1_fused_0 in range(16):
                            for ax0_ax1_fused_1 in T.thread_binding(4, thread="threadIdx.y"):
                                for ax0_ax1_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                    for ax0_ax1_fused_3 in T.vectorized(2):
                                        with T.block("B_decompress_reindex_shared.dyn"):
                                            v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused % 2 * 8192 + ax0_0_1_ax1_0_1_fused % 32 * 256 + (ax0_ax1_fused_0 * 256 + ax0_ax1_fused_1 * 64 + ax0_ax1_fused_2 * 2 + ax0_ax1_fused_3) // 16)
                                            v1 = T.axis.spatial(16384, ax2_0_0 * 16 + (ax0_ax1_fused_0 * 256 + ax0_ax1_fused_1 * 64 + ax0_ax1_fused_2 * 2 + ax0_ax1_fused_3) % 16)
                                            T.reads(B[v0, v1 // 2:v1 // 2 + 2])
                                            T.writes(B_decompress_reindex_shared_dyn[v0, v1])
                                            T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]]})
                                            B_decompress_reindex_shared_dyn[v0, v1] = T.Select(v1 % 32 * 4 % 8 <= 5, T.Cast("float16", T.bitwise_and(T.shift_right(T.Cast("int32", B[v0, v1 // 32 * 16 + v1 % 32 * 4 // 8]), v1 % 32 * 4 % 8), 15)), T.Cast("float16", T.bitwise_or(T.Cast("int8", T.bitwise_and(T.shift_right(T.Cast("int32", B[v0, v1 // 32 * 16 + v1 % 32 * 4 // 8]), v1 % 32 * 4 % 8), T.shift_left(1, 8 - v1 % 32 * 4 % 8) - 1)), T.Cast("int8", T.bitwise_and(T.bitwise_and(T.shift_left(T.Cast("int32", B[v0, v1 // 32 * 16 + v1 % 32 * 4 // 8 + 1]), 8 - v1 % 32 * 4 % 8), T.shift_left(15, 8 - v1 % 32 * 4 % 8)), 15)))))
                        for ax2_0_1 in range(1):
                            for ax0_0, ax1_0 in T.grid(2, 1):
                                with T.block("A_reindex_shared.dyn_wmma.matrix_a_o"):
                                    v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 2 * 32 + ax0_0_1_ax1_0_1_fused // 32 * 2 + ax0_0)
                                    v1_o = T.axis.spatial(1024, ax2_0_0 + ax1_0)
                                    T.reads(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    A_1 = T.match_buffer(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="shared.dyn", offset_factor=16)
                                    C_1 = T.match_buffer(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.matrix_a", offset_factor=16)
                                    T.tvm_load_matrix_sync(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), A_1.data, A_1.elem_offset, A_1.strides[0] * 16, 1), A_1.strides[0], "row_major")
                            for ax0_0, ax1_0 in T.grid(4, 1):
                                with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b_o"):
                                    v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 2 * 512 + ax0_0_1_ax1_0_1_fused % 32 * 16 + ax0_0_2_ax1_0_2_fused * 4 + ax0_0)
                                    v1_o = T.axis.spatial(1024, ax2_0_0 + ax1_0)
                                    T.reads(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    A_1 = T.match_buffer(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="shared.dyn", offset_factor=16)
                                    C_1 = T.match_buffer(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.matrix_b", offset_factor=16)
                                    T.tvm_load_matrix_sync(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), A_1.data, A_1.elem_offset, A_1.strides[0] * 16, 1), A_1.strides[0], "col_major")
                            for ax0_0_3, ax1_0_3, ax2_0_2, ax0_0_4, ax1_0_4 in T.grid(2, 1, 1, 1, 4):
                                with T.block("B_o_update"):
                                    v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 2 * 32 + ax0_0_1_ax1_0_1_fused // 32 * 2 + ax0_0_3 + ax0_0_4)
                                    v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 2 * 512 + ax0_0_1_ax1_0_1_fused % 32 * 16 + ax0_0_2_ax1_0_2_fused * 4 + ax1_0_3 * 4 + ax1_0_4)
                                    v2_o = T.axis.reduce(1024, ax2_0_1 + ax2_0_2 + ax2_0_0)
                                    T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o // 2, v1_o // 4, v0_o % 2, v1_o % 4, 0:16, 0:16], A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], B_decompress_reindex_shared_dyn_wmma_matrix_b[v1_o * 16:v1_o * 16 + 16, v2_o * 16:v2_o * 16 + 16])
                                    T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 2, v1_o // 4, v0_o % 2, v1_o % 4, 0:16, 0:16])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                                    A_1 = T.match_buffer(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="wmma.matrix_a", offset_factor=16)
                                    B_1 = T.match_buffer(B_decompress_reindex_shared_dyn_wmma_matrix_b[v1_o * 16:v1_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], (16, 16), "float16", strides=("B_s0", "B_s1"), scope="wmma.matrix_b", offset_factor=16)
                                    C_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0_o // 2, v1_o // 4, v0_o % 2, v1_o % 4, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.accumulator", offset_factor=16)
                                    T.tvm_mma_sync(C_1.data, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, A_1.data, A_1.elem_offset // A_1.strides[0] // 16 * (A_1.strides[0] // 16) + A_1.elem_offset % A_1.strides[0] // 16, B_1.data, B_1.elem_offset // B_1.strides[0] // 16 * (B_1.strides[0] // 16) + B_1.elem_offset % B_1.strides[0] // 16, C_1.data, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16)
                for ax2 in range(2):
                    for ax0_ax1_fused in T.thread_binding(4, thread="threadIdx.y"):
                        for ax2_1, ax3 in T.grid(1, 4):
                            with T.block("C_reindex_shared.dyn_wmma.accumulator_o"):
                                v0 = T.axis.spatial(512, ax0_0_0_ax1_0_0_fused // 2 * 16 + ax0_0_1_ax1_0_1_fused // 32)
                                v1 = T.axis.spatial(256, ax0_0_0_ax1_0_0_fused % 2 * 128 + ax0_0_1_ax1_0_1_fused % 32 * 4 + ax0_ax1_fused)
                                v2 = T.axis.spatial(2, ax2 + ax2_1)
                                v3 = T.axis.spatial(4, ax3)
                                v4_o = T.axis.spatial(1, 0)
                                v5_o = T.axis.spatial(1, 0)
                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16])
                                T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16])
                                A_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="wmma.accumulator", offset_factor=16)
                                C_1 = T.match_buffer(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="shared.dyn", offset_factor=16)
                                T.tvm_store_matrix_sync(A_1.data, 16, 16, 16, A_1.elem_offset // A_1.strides[0] // 16 * (A_1.strides[0] // 16) + A_1.elem_offset % A_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), C_1.data, C_1.elem_offset, C_1.strides[0] * 16, 2), C_1.strides[0], "row_major")
                    for ax0_ax1_ax3_ax4_ax5_fused_0 in range(8):
                        for ax0_ax1_ax3_ax4_ax5_fused_1 in T.thread_binding(4, thread="threadIdx.y"):
                            for ax0_ax1_ax3_ax4_ax5_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax3_ax4_ax5_fused_3 in T.vectorized(4):
                                    with T.block("C_reindex_shared.dyn"):
                                        v0 = T.axis.spatial(512, ax0_0_0_ax1_0_0_fused // 2 * 16 + ax0_0_1_ax1_0_1_fused // 32)
                                        v1 = T.axis.spatial(256, ax0_0_0_ax1_0_0_fused % 2 * 128 + ax0_0_1_ax1_0_1_fused % 32 * 4 + (ax0_ax1_ax3_ax4_ax5_fused_0 * 512 + ax0_ax1_ax3_ax4_ax5_fused_1 * 128 + ax0_ax1_ax3_ax4_ax5_fused_2 * 4 + ax0_ax1_ax3_ax4_ax5_fused_3) // 1024)
                                        v2 = T.axis.spatial(2, ax2)
                                        v3 = T.axis.spatial(4, (ax0_ax1_ax3_ax4_ax5_fused_0 * 512 + ax0_ax1_ax3_ax4_ax5_fused_1 * 128 + ax0_ax1_ax3_ax4_ax5_fused_2 * 4 + ax0_ax1_ax3_ax4_ax5_fused_3) % 1024 // 256)
                                        v4 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 512 + ax0_ax1_ax3_ax4_ax5_fused_1 * 128 + ax0_ax1_ax3_ax4_ax5_fused_2 * 4 + ax0_ax1_ax3_ax4_ax5_fused_3) % 256 // 16)
                                        v5 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 512 + ax0_ax1_ax3_ax4_ax5_fused_1 * 128 + ax0_ax1_ax3_ax4_ax5_fused_2 * 4 + ax0_ax1_ax3_ax4_ax5_fused_3) % 16)
                                        T.reads(C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5])
                                        T.writes(C[v4 + v2 * 16 + v0 * 32, v5 + v3 * 16 + v1 * 64])
                                        C[v4 + v2 * 16 + v0 * 32, v5 + v3 * 16 + v1 * 64] = C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5]
b0 = sch.get_block(name="B_decompress", func_name="main")
b1 = sch.get_block(name="B", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
b3 = sch.reindex(block=b1, buffer=("write", 0))
b4 = sch.reindex(block=b1, buffer=("read", 0))
b5 = sch.reindex(block=b1, buffer=("read", 1))
sch.transform_layout(block=b1, buffer=("read", 0), index_map=lambda vi, vk: (vi, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("read", 1), index_map=lambda vj, vk: (vj, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("write", 0), index_map=lambda vi, vj: (vi, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_block_layout(block=b3, index_map=lambda vi, vj: (vi, vj,))
sch.transform_block_layout(block=b4, index_map=lambda vi, vk: (vi, vk,))
sch.transform_block_layout(block=b5, index_map=lambda vj, vk: (vj, vk,))
sch.transform_block_layout(block=b1, index_map=lambda vi, vj, vk: (vi, vj, vk,))
l6, l7, l8 = sch.get_loops(block=b1)
l9, l10 = sch.split(loop=l8, factors=[None, 16], preserve_unit_iters=True)
l11, l12 = sch.split(loop=l7, factors=[None, 16], preserve_unit_iters=True)
l13, l14 = sch.split(loop=l6, factors=[None, 16], preserve_unit_iters=True)
l15, l16, l17, l18, l19, l20 = sch.get_loops(block=b1)
sch.reorder(l17, l19, l14, l12, l10)
b21 = sch.blockize(loop=l14, preserve_unit_iters=True)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_sync_16x16x16_f16f16f16_trans")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize_init", ann_val="wmma_fill_16x16x16_f16")
sch.annotate(block_or_loop=b21, ann_key="warp_execution", ann_val=1)
l22, l23, l24 = sch.get_loops(block=b21)
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l22, n=5, max_innermost_factor=4, decision=[32, 16, 1, 2, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l22, factors=[v25, v26, v27, v28, v29], preserve_unit_iters=True)
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l23, n=5, max_innermost_factor=4, decision=[2, 32, 4, 1, 4])
l40, l41, l42, l43, l44 = sch.split(loop=l23, factors=[v35, v36, v37, v38, v39], preserve_unit_iters=True)
v45, v46, v47 = sch.sample_perfect_tile(loop=l24, n=3, max_innermost_factor=4, decision=[1024, 1, 1])
l48, l49, l50 = sch.split(loop=l24, factors=[v45, v46, v47], preserve_unit_iters=True)
sch.reorder(l30, l40, l31, l41, l32, l42, l48, l49, l33, l43, l50, l34, l44)
l51 = sch.fuse(l30, l40, preserve_unit_iters=True)
sch.bind(loop=l51, thread_axis="blockIdx.y")
l52 = sch.fuse(l31, l41, preserve_unit_iters=True)
sch.bind(loop=l52, thread_axis="blockIdx.x")
l53 = sch.fuse(l32, l42, preserve_unit_iters=True)
sch.bind(loop=l53, thread_axis="threadIdx.y")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
sch.transform_layout(block=b21, buffer=("write", 0), index_map=lambda i0, i1: (i0 // 16 // (v28 * v29), i1 // 16 // (v38 * v39), i0 // 16 % (v28 * v29), i1 // 16 % (v38 * v39), i0 % 16, i1 % 16,), pad_value=None, assume_injective_transform=True)
b54 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="shared.dyn")
sch.reverse_compute_at(block=b54, loop=l52, preserve_unit_loops=True, index=-1)
b55 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="wmma.accumulator")
l56, l57, l58, l59, l60, l61, l62, l63 = sch.get_loops(block=b54)
sch.reorder(l60, l58, l59, l61)
sch.compute_at(block=b55, loop=l60, preserve_unit_loops=True, index=-1)
l64, l65, l66, l67, l68, l69, l70, l71, l72 = sch.get_loops(block=b55)
l73 = sch.fuse(l67, l68, preserve_unit_iters=True)
sch.bind(loop=l73, thread_axis="threadIdx.y")
sch.reverse_compute_inline(block=b3)
l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b55)
b82 = sch.blockize(loop=l80, preserve_unit_iters=True)
sch.annotate(block_or_loop=b82, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_store_16x16x16_f16_shared_dyn")
l83, l84, l85, l86, l87, l88, l89, l90 = sch.get_loops(block=b54)
l91 = sch.fuse(l86, l87, l88, l89, l90, preserve_unit_iters=True)
v92 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch", ann_val=v92)
b93 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b93, loop=l48, preserve_unit_loops=True, index=-1)
l94, l95, l96, l97, l98, l99 = sch.get_loops(block=b93)
l100 = sch.fuse(l98, l99, preserve_unit_iters=True)
v101 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch", ann_val=v101)
b102 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b102, loop=l48, preserve_unit_loops=True, index=-1)
l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b102)
l109 = sch.fuse(l107, l108, preserve_unit_iters=True)
v110 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch", ann_val=v110)
b111 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="wmma.matrix_a")
sch.compute_at(block=b111, loop=l49, preserve_unit_loops=True, index=-1)
l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b111)
l119, l120 = sch.split(loop=l118, factors=[None, 16], preserve_unit_iters=True)
l121, l122 = sch.split(loop=l117, factors=[None, 16], preserve_unit_iters=True)
l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b111)
sch.reorder(l130, l122, l120)
b132 = sch.blockize(loop=l122, preserve_unit_iters=True)
sch.annotate(block_or_loop=b132, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_a_shared_dyn")
b133 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="wmma.matrix_b")
sch.compute_at(block=b133, loop=l49, preserve_unit_loops=True, index=-1)
l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b133)
l141, l142 = sch.split(loop=l140, factors=[None, 16], preserve_unit_iters=True)
l143, l144 = sch.split(loop=l139, factors=[None, 16], preserve_unit_iters=True)
l145, l146, l147, l148, l149, l150, l151, l152, l153 = sch.get_loops(block=b133)
sch.reorder(l152, l144, l142)
b154 = sch.blockize(loop=l144, preserve_unit_iters=True)
sch.annotate(block_or_loop=b154, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_b_trans_shared_dyn")
sch.compute_inline(block=b4)
sch.compute_inline(block=b5)
sch.storage_align(block=b93, buffer_index=0, axis=-2, factor=32, offset=8)
sch.storage_align(block=b102, buffer_index=0, axis=-2, factor=32, offset=8)
sch.compute_inline(block=b0)
v155 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v155)
sch.enter_postproc()
sch.unannotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch")
l156, l157, l158, l159 = sch.get_loops(block=b54)
l160, l161, l162, l163 = sch.split(loop=l159, factors=[None, 4, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l163)
sch.bind(loop=l162, thread_axis="threadIdx.x")
sch.bind(loop=l161, thread_axis="threadIdx.y")
sch.unannotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch")
l164, l165, l166, l167, l168 = sch.get_loops(block=b93)
l169, l170, l171, l172 = sch.split(loop=l168, factors=[None, 4, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l172)
sch.bind(loop=l171, thread_axis="threadIdx.x")
sch.bind(loop=l170, thread_axis="threadIdx.y")
sch.unannotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch")
l173, l174, l175, l176, l177 = sch.get_loops(block=b102)
l178, l179, l180, l181 = sch.split(loop=l177, factors=[None, 4, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l181)
sch.bind(loop=l180, thread_axis="threadIdx.x")
sch.bind(loop=l179, thread_axis="threadIdx.y")
b182 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b182, ann_key="meta_schedule.unroll_explicit")
b183, b184, b185, b186, b187, b188, b189 = sch.get_child_blocks(b182)
l190, l191, l192, l193, l194, l195, l196, l197 = sch.get_loops(block=b183)
sch.annotate(block_or_loop=l190, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l190, ann_key="pragma_unroll_explicit", ann_val=1)
l198, l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b184)
sch.annotate(block_or_loop=l198, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l198, ann_key="pragma_unroll_explicit", ann_val=1)
l206, l207, l208, l209, l210, l211, l212 = sch.get_loops(block=b185)
sch.annotate(block_or_loop=l206, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l206, ann_key="pragma_unroll_explicit", ann_val=1)
l213, l214, l215, l216, l217, l218, l219 = sch.get_loops(block=b186)
sch.annotate(block_or_loop=l213, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l213, ann_key="pragma_unroll_explicit", ann_val=1)
l220, l221, l222, l223, l224, l225, l226, l227, l228, l229 = sch.get_loops(block=b187)
sch.annotate(block_or_loop=l220, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l220, ann_key="pragma_unroll_explicit", ann_val=1)
l230, l231, l232, l233, l234, l235 = sch.get_loops(block=b188)
sch.annotate(block_or_loop=l230, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l230, ann_key="pragma_unroll_explicit", ann_val=1)
l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b189)
sch.annotate(block_or_loop=l236, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l236, ann_key="pragma_unroll_explicit", ann_val=1)
b243 = sch.get_block(name="B_o", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b243)
b254 = sch.decompose_reduction(block=b243, loop=l247)
sch.unannotate(block_or_loop=b254, ann_key="meta_schedule.auto_tensorize")
sch.annotate(block_or_loop=b254, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_fill_16x16x16_f16")
sch.unannotate(block_or_loop=b243, ann_key="meta_schedule.auto_tensorize_init")
sch.unannotate(block_or_loop=b254, ann_key="meta_schedule.auto_tensorize_init")
b255 = sch.get_block(name="B_o_init", func_name="main")
sch.unannotate(block_or_loop=b255, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b255, tensor_intrin="wmma_fill_16x16x16_f16", preserve_unit_iters=True)
b256 = sch.get_block(name="A_reindex_shared.dyn_wmma.matrix_a_o", func_name="main")
sch.unannotate(block_or_loop=b256, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b256, tensor_intrin="wmma_load_16x16x16_f16_a_shared_dyn", preserve_unit_iters=True)
b257 = sch.get_block(name="B_decompress_reindex_shared.dyn_wmma.matrix_b_o", func_name="main")
sch.unannotate(block_or_loop=b257, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b257, tensor_intrin="wmma_load_16x16x16_f16_b_trans_shared_dyn", preserve_unit_iters=True)
b258 = sch.get_block(name="B_o_update", func_name="main")
sch.unannotate(block_or_loop=b258, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b258, tensor_intrin="wmma_sync_16x16x16_f16f16f16_trans", preserve_unit_iters=True)
b259 = sch.get_block(name="C_reindex_shared.dyn_wmma.accumulator_o", func_name="main")
sch.unannotate(block_or_loop=b259, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b259, tensor_intrin="wmma_store_16x16x16_f16_shared_dyn", preserve_unit_iters=True)
2023-05-01 16:11:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #4: GFLOPs: 8913.5887. Time: 987300.2113 us. Best GFLOPs: 42782.4588
2023-05-01 16:11:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #5: GFLOPs: 18607.7701. Time: 472941.5690 us. Best GFLOPs: 42782.4588
2023-05-01 16:11:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #6: GFLOPs: 69558.8258. Time: 126517.2017 us. Best GFLOPs: 69558.8258
2023-05-01 16:11:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #7: GFLOPs: 18115.5689. Time: 485791.4223 us. Best GFLOPs: 69558.8258
2023-05-01 16:11:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #8: GFLOPs: 70769.6862. Time: 124352.5083 us. Best GFLOPs: 70769.6862
2023-05-01 16:11:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #9: GFLOPs: 60216.7087. Time: 146145.2840 us. Best GFLOPs: 70769.6862
2023-05-01 16:11:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #10: GFLOPs: 35145.2532. Time: 250400.4720 us. Best GFLOPs: 70769.6862
2023-05-01 16:11:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #11: GFLOPs: 19629.6063. Time: 448322.1840 us. Best GFLOPs: 70769.6862
2023-05-01 16:11:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #12: GFLOPs: 55189.1544. Time: 159458.6487 us. Best GFLOPs: 70769.6862
2023-05-01 16:11:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #13: GFLOPs: 40890.6114. Time: 215217.8140 us. Best GFLOPs: 70769.6862
2023-05-01 16:11:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #14: GFLOPs: 45231.6904. Time: 194562.4387 us. Best GFLOPs: 70769.6862
2023-05-01 16:11:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #15: GFLOPs: 29356.8808. Time: 299772.5830 us. Best GFLOPs: 70769.6862
2023-05-01 16:11:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #16: GFLOPs: 51203.9910. Time: 171869.1810 us. Best GFLOPs: 70769.6862
2023-05-01 16:11:27 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 16:11:28 [INFO] [evolutionary_search.cc:715] Picked top 15 candidate(s) from database
2023-05-01 16:11:32 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 479 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:11:36 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 966 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:11:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1453 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:11:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1943 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:11:49 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2434 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:11:49 [INFO] [evolutionary_search.cc:723] Sampled 51 candidate(s)
2023-05-01 16:11:56 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 101 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:12:01 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 77 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:12:07 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 78 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:12:13 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 62 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:12:13 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9994  0.9984  0.9981  0.9980  0.9973  0.9957  0.9950  0.9950  0.9939  0.9932  0.9927  0.9918  0.9906  0.9901  0.9899  0.9898
2023-05-01 16:12:14 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 16:12:14 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 16:19:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #17: GFLOPs: 57423.0772. Time: 153255.2490 us. Best GFLOPs: 70769.6862
2023-05-01 16:19:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #18: GFLOPs: 19614.0902. Time: 448676.8390 us. Best GFLOPs: 70769.6862
2023-05-01 16:19:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #19: GFLOPs: 16458.2045. Time: 534711.3037 us. Best GFLOPs: 70769.6862
2023-05-01 16:19:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #20: GFLOPs: 64865.5945. Time: 135671.1220 us. Best GFLOPs: 70769.6862
2023-05-01 16:19:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #21: GFLOPs: 27104.0054. Time: 324689.5750 us. Best GFLOPs: 70769.6862
2023-05-01 16:19:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #22: GFLOPs: 26078.9558. Time: 337451.7007 us. Best GFLOPs: 70769.6862
2023-05-01 16:19:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #23: GFLOPs: 42980.8177. Time: 204751.5257 us. Best GFLOPs: 70769.6862
2023-05-01 16:19:23 [INFO] [task_scheduler.cc:121] [Task #0: main] Trial #24: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 8192), "int8"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        C_reindex_shared_dyn = T.alloc_buffer((128, 64, 8, 16, 16, 16), "float16", scope="shared.dyn")
        C_reindex_shared_dyn_wmma_accumulator = T.alloc_buffer((128, 64, 8, 16, 16, 16), "float16", scope="wmma.accumulator")
        A_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
        B_decompress_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
        A_reindex_shared_dyn_wmma_matrix_a = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_a")
        B_decompress_reindex_shared_dyn_wmma_matrix_b = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_b")
        for ax0_0_0_ax1_0_0_fused in T.thread_binding(128, thread="blockIdx.y", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ax0_0_1_ax1_0_1_fused in T.thread_binding(32, thread="blockIdx.x"):
                for ax0_0_2_ax1_0_2_fused in T.thread_binding(2, thread="threadIdx.y"):
                    for ax0_0_3_init, ax1_0_3_init, ax0_0_4_init, ax1_0_4_init in T.grid(8, 8, 1, 2):
                        with T.block("B_o_init"):
                            v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 32 * 256 + ax0_0_1_ax1_0_1_fused // 2 * 16 + ax0_0_2_ax1_0_2_fused * 8 + ax0_0_3_init + ax0_0_4_init)
                            v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 32 * 32 + ax0_0_1_ax1_0_1_fused % 2 * 16 + ax1_0_3_init * 2 + ax1_0_4_init)
                            T.reads()
                            T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 8, v1_o // 16, v0_o % 8, v1_o % 16, 0:16, 0:16])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                            C_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0_o // 8, v1_o // 16, v0_o % 8, v1_o % 16, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.accumulator", offset_factor=16)
                            T.tvm_fill_fragment(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.float32(0))
                    for ax2_0_0 in range(512):
                        for ax0_ax1_fused_0 in range(128):
                            for ax0_ax1_fused_1 in T.thread_binding(2, thread="threadIdx.y"):
                                for ax0_ax1_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                    with T.block("A_reindex_shared.dyn"):
                                        v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused // 32 * 4096 + ax0_0_1_ax1_0_1_fused // 2 * 256 + (ax0_ax1_fused_0 * 64 + ax0_ax1_fused_1 * 32 + ax0_ax1_fused_2) // 32)
                                        v1 = T.axis.spatial(16384, ax2_0_0 * 32 + (ax0_ax1_fused_0 * 64 + ax0_ax1_fused_1 * 32 + ax0_ax1_fused_2) % 32)
                                        T.reads(A[v0, v1])
                                        T.writes(A_reindex_shared_dyn[v0, v1])
                                        T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]]})
                                        A_reindex_shared_dyn[v0, v1] = A[v0, v1]
                        for ax0_ax1_fused_0 in range(32):
                            for ax0_ax1_fused_1 in T.thread_binding(2, thread="threadIdx.y"):
                                for ax0_ax1_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                    for ax0_ax1_fused_3 in T.vectorized(4):
                                        with T.block("B_decompress_reindex_shared.dyn"):
                                            v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused % 32 * 512 + ax0_0_1_ax1_0_1_fused % 2 * 256 + (ax0_ax1_fused_0 * 256 + ax0_ax1_fused_1 * 128 + ax0_ax1_fused_2 * 4 + ax0_ax1_fused_3) // 32)
                                            v1 = T.axis.spatial(16384, ax2_0_0 * 32 + (ax0_ax1_fused_0 * 256 + ax0_ax1_fused_1 * 128 + ax0_ax1_fused_2 * 4 + ax0_ax1_fused_3) % 32)
                                            T.reads(B[v0, v1 // 2:v1 // 2 + 2])
                                            T.writes(B_decompress_reindex_shared_dyn[v0, v1])
                                            T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]]})
                                            B_decompress_reindex_shared_dyn[v0, v1] = T.Select(v1 % 32 * 4 % 8 <= 5, T.Cast("float16", T.bitwise_and(T.shift_right(T.Cast("int32", B[v0, v1 // 32 * 16 + v1 % 32 * 4 // 8]), v1 % 32 * 4 % 8), 15)), T.Cast("float16", T.bitwise_or(T.Cast("int8", T.bitwise_and(T.shift_right(T.Cast("int32", B[v0, v1 // 32 * 16 + v1 % 32 * 4 // 8]), v1 % 32 * 4 % 8), T.shift_left(1, 8 - v1 % 32 * 4 % 8) - 1)), T.Cast("int8", T.bitwise_and(T.bitwise_and(T.shift_left(T.Cast("int32", B[v0, v1 // 32 * 16 + v1 % 32 * 4 // 8 + 1]), 8 - v1 % 32 * 4 % 8), T.shift_left(15, 8 - v1 % 32 * 4 % 8)), 15)))))
                        for ax2_0_1 in range(2):
                            for ax0_0, ax1_0 in T.grid(8, 1):
                                with T.block("A_reindex_shared.dyn_wmma.matrix_a_o"):
                                    v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 32 * 256 + ax0_0_1_ax1_0_1_fused // 2 * 16 + ax0_0_2_ax1_0_2_fused * 8 + ax0_0)
                                    v1_o = T.axis.spatial(1024, ax2_0_0 * 2 + ax2_0_1 + ax1_0)
                                    T.reads(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    A_1 = T.match_buffer(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="shared.dyn", offset_factor=16)
                                    C_1 = T.match_buffer(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.matrix_a", offset_factor=16)
                                    T.tvm_load_matrix_sync(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), A_1.data, A_1.elem_offset, A_1.strides[0] * 16, 1), A_1.strides[0], "row_major")
                            for ax0_0, ax1_0 in T.grid(16, 1):
                                with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b_o"):
                                    v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 32 * 32 + ax0_0_1_ax1_0_1_fused % 2 * 16 + ax0_0)
                                    v1_o = T.axis.spatial(1024, ax2_0_0 * 2 + ax2_0_1 + ax1_0)
                                    T.reads(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    A_1 = T.match_buffer(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="shared.dyn", offset_factor=16)
                                    C_1 = T.match_buffer(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.matrix_b", offset_factor=16)
                                    T.tvm_load_matrix_sync(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), A_1.data, A_1.elem_offset, A_1.strides[0] * 16, 1), A_1.strides[0], "col_major")
                            for ax0_0_3, ax1_0_3, ax2_0_2, ax0_0_4, ax1_0_4 in T.grid(8, 8, 1, 1, 2):
                                with T.block("B_o_update"):
                                    v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 32 * 256 + ax0_0_1_ax1_0_1_fused // 2 * 16 + ax0_0_2_ax1_0_2_fused * 8 + ax0_0_3 + ax0_0_4)
                                    v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 32 * 32 + ax0_0_1_ax1_0_1_fused % 2 * 16 + ax1_0_3 * 2 + ax1_0_4)
                                    v2_o = T.axis.reduce(1024, ax2_0_0 * 2 + ax2_0_1 + ax2_0_2)
                                    T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o // 8, v1_o // 16, v0_o % 8, v1_o % 16, 0:16, 0:16], A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], B_decompress_reindex_shared_dyn_wmma_matrix_b[v1_o * 16:v1_o * 16 + 16, v2_o * 16:v2_o * 16 + 16])
                                    T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 8, v1_o // 16, v0_o % 8, v1_o % 16, 0:16, 0:16])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                                    A_1 = T.match_buffer(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="wmma.matrix_a", offset_factor=16)
                                    B_1 = T.match_buffer(B_decompress_reindex_shared_dyn_wmma_matrix_b[v1_o * 16:v1_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], (16, 16), "float16", strides=("B_s0", "B_s1"), scope="wmma.matrix_b", offset_factor=16)
                                    C_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0_o // 8, v1_o // 16, v0_o % 8, v1_o % 16, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.accumulator", offset_factor=16)
                                    T.tvm_mma_sync(C_1.data, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, A_1.data, A_1.elem_offset // A_1.strides[0] // 16 * (A_1.strides[0] // 16) + A_1.elem_offset % A_1.strides[0] // 16, B_1.data, B_1.elem_offset // B_1.strides[0] // 16 * (B_1.strides[0] // 16) + B_1.elem_offset % B_1.strides[0] // 16, C_1.data, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16)
                for ax2 in range(8):
                    for ax0_ax1_fused in T.thread_binding(2, thread="threadIdx.y"):
                        for ax2_1, ax3 in T.grid(1, 16):
                            with T.block("C_reindex_shared.dyn_wmma.accumulator_o"):
                                v0 = T.axis.spatial(128, ax0_0_0_ax1_0_0_fused // 32 * 32 + ax0_0_1_ax1_0_1_fused // 2 * 2 + ax0_ax1_fused)
                                v1 = T.axis.spatial(64, ax0_0_0_ax1_0_0_fused % 32 * 2 + ax0_0_1_ax1_0_1_fused % 2)
                                v2 = T.axis.spatial(8, ax2 + ax2_1)
                                v3 = T.axis.spatial(16, ax3)
                                v4_o = T.axis.spatial(1, 0)
                                v5_o = T.axis.spatial(1, 0)
                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16])
                                T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16])
                                A_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="wmma.accumulator", offset_factor=16)
                                C_1 = T.match_buffer(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="shared.dyn", offset_factor=16)
                                T.tvm_store_matrix_sync(A_1.data, 16, 16, 16, A_1.elem_offset // A_1.strides[0] // 16 * (A_1.strides[0] // 16) + A_1.elem_offset % A_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), C_1.data, C_1.elem_offset, C_1.strides[0] * 16, 2), C_1.strides[0], "row_major")
                    for ax0_ax1_ax3_ax4_ax5_fused_0 in range(128):
                        for ax0_ax1_ax3_ax4_ax5_fused_1 in T.thread_binding(2, thread="threadIdx.y"):
                            for ax0_ax1_ax3_ax4_ax5_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("C_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(128, ax0_0_0_ax1_0_0_fused // 32 * 32 + ax0_0_1_ax1_0_1_fused // 2 * 2 + (ax0_ax1_ax3_ax4_ax5_fused_0 * 64 + ax0_ax1_ax3_ax4_ax5_fused_1 * 32 + ax0_ax1_ax3_ax4_ax5_fused_2) // 4096)
                                    v1 = T.axis.spatial(64, ax0_0_0_ax1_0_0_fused % 32 * 2 + ax0_0_1_ax1_0_1_fused % 2)
                                    v2 = T.axis.spatial(8, ax2)
                                    v3 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 64 + ax0_ax1_ax3_ax4_ax5_fused_1 * 32 + ax0_ax1_ax3_ax4_ax5_fused_2) % 4096 // 256)
                                    v4 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 64 + ax0_ax1_ax3_ax4_ax5_fused_1 * 32 + ax0_ax1_ax3_ax4_ax5_fused_2) % 256 // 16)
                                    v5 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 64 + ax0_ax1_ax3_ax4_ax5_fused_1 * 32 + ax0_ax1_ax3_ax4_ax5_fused_2) % 16)
                                    T.reads(C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5])
                                    T.writes(C[v4 + v2 * 16 + v0 * 128, v5 + v3 * 16 + v1 * 256])
                                    C[v4 + v2 * 16 + v0 * 128, v5 + v3 * 16 + v1 * 256] = C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5]
b0 = sch.get_block(name="B_decompress", func_name="main")
b1 = sch.get_block(name="B", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
b3 = sch.reindex(block=b1, buffer=("write", 0))
b4 = sch.reindex(block=b1, buffer=("read", 0))
b5 = sch.reindex(block=b1, buffer=("read", 1))
sch.transform_layout(block=b1, buffer=("read", 0), index_map=lambda vi, vk: (vi, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("read", 1), index_map=lambda vj, vk: (vj, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("write", 0), index_map=lambda vi, vj: (vi, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_block_layout(block=b3, index_map=lambda vi, vj: (vi, vj,))
sch.transform_block_layout(block=b4, index_map=lambda vi, vk: (vi, vk,))
sch.transform_block_layout(block=b5, index_map=lambda vj, vk: (vj, vk,))
sch.transform_block_layout(block=b1, index_map=lambda vi, vj, vk: (vi, vj, vk,))
l6, l7, l8 = sch.get_loops(block=b1)
l9, l10 = sch.split(loop=l8, factors=[None, 16], preserve_unit_iters=True)
l11, l12 = sch.split(loop=l7, factors=[None, 16], preserve_unit_iters=True)
l13, l14 = sch.split(loop=l6, factors=[None, 16], preserve_unit_iters=True)
l15, l16, l17, l18, l19, l20 = sch.get_loops(block=b1)
sch.reorder(l17, l19, l14, l12, l10)
b21 = sch.blockize(loop=l14, preserve_unit_iters=True)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_sync_16x16x16_f16f16f16_trans")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize_init", ann_val="wmma_fill_16x16x16_f16")
sch.annotate(block_or_loop=b21, ann_key="warp_execution", ann_val=1)
l22, l23, l24 = sch.get_loops(block=b21)
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l22, n=5, max_innermost_factor=4, decision=[4, 16, 2, 8, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l22, factors=[v25, v26, v27, v28, v29], preserve_unit_iters=True)
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l23, n=5, max_innermost_factor=4, decision=[32, 2, 1, 8, 2])
l40, l41, l42, l43, l44 = sch.split(loop=l23, factors=[v35, v36, v37, v38, v39], preserve_unit_iters=True)
v45, v46, v47 = sch.sample_perfect_tile(loop=l24, n=3, max_innermost_factor=4, decision=[512, 2, 1])
l48, l49, l50 = sch.split(loop=l24, factors=[v45, v46, v47], preserve_unit_iters=True)
sch.reorder(l30, l40, l31, l41, l32, l42, l48, l49, l33, l43, l50, l34, l44)
l51 = sch.fuse(l30, l40, preserve_unit_iters=True)
sch.bind(loop=l51, thread_axis="blockIdx.y")
l52 = sch.fuse(l31, l41, preserve_unit_iters=True)
sch.bind(loop=l52, thread_axis="blockIdx.x")
l53 = sch.fuse(l32, l42, preserve_unit_iters=True)
sch.bind(loop=l53, thread_axis="threadIdx.y")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
sch.transform_layout(block=b21, buffer=("write", 0), index_map=lambda i0, i1: (i0 // 16 // (v28 * v29), i1 // 16 // (v38 * v39), i0 // 16 % (v28 * v29), i1 // 16 % (v38 * v39), i0 % 16, i1 % 16,), pad_value=None, assume_injective_transform=True)
b54 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="shared.dyn")
sch.reverse_compute_at(block=b54, loop=l52, preserve_unit_loops=True, index=-1)
b55 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="wmma.accumulator")
l56, l57, l58, l59, l60, l61, l62, l63 = sch.get_loops(block=b54)
sch.reorder(l60, l58, l59, l61)
sch.compute_at(block=b55, loop=l60, preserve_unit_loops=True, index=-1)
l64, l65, l66, l67, l68, l69, l70, l71, l72 = sch.get_loops(block=b55)
l73 = sch.fuse(l67, l68, preserve_unit_iters=True)
sch.bind(loop=l73, thread_axis="threadIdx.y")
sch.reverse_compute_inline(block=b3)
l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b55)
b82 = sch.blockize(loop=l80, preserve_unit_iters=True)
sch.annotate(block_or_loop=b82, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_store_16x16x16_f16_shared_dyn")
l83, l84, l85, l86, l87, l88, l89, l90 = sch.get_loops(block=b54)
l91 = sch.fuse(l86, l87, l88, l89, l90, preserve_unit_iters=True)
v92 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch", ann_val=v92)
b93 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b93, loop=l48, preserve_unit_loops=True, index=-1)
l94, l95, l96, l97, l98, l99 = sch.get_loops(block=b93)
l100 = sch.fuse(l98, l99, preserve_unit_iters=True)
v101 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch", ann_val=v101)
b102 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b102, loop=l48, preserve_unit_loops=True, index=-1)
l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b102)
l109 = sch.fuse(l107, l108, preserve_unit_iters=True)
v110 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch", ann_val=v110)
b111 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="wmma.matrix_a")
sch.compute_at(block=b111, loop=l49, preserve_unit_loops=True, index=-1)
l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b111)
l119, l120 = sch.split(loop=l118, factors=[None, 16], preserve_unit_iters=True)
l121, l122 = sch.split(loop=l117, factors=[None, 16], preserve_unit_iters=True)
l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b111)
sch.reorder(l130, l122, l120)
b132 = sch.blockize(loop=l122, preserve_unit_iters=True)
sch.annotate(block_or_loop=b132, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_a_shared_dyn")
b133 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="wmma.matrix_b")
sch.compute_at(block=b133, loop=l49, preserve_unit_loops=True, index=-1)
l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b133)
l141, l142 = sch.split(loop=l140, factors=[None, 16], preserve_unit_iters=True)
l143, l144 = sch.split(loop=l139, factors=[None, 16], preserve_unit_iters=True)
l145, l146, l147, l148, l149, l150, l151, l152, l153 = sch.get_loops(block=b133)
sch.reorder(l152, l144, l142)
b154 = sch.blockize(loop=l144, preserve_unit_iters=True)
sch.annotate(block_or_loop=b154, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_b_trans_shared_dyn")
sch.compute_inline(block=b4)
sch.compute_inline(block=b5)
sch.storage_align(block=b93, buffer_index=0, axis=-2, factor=32, offset=8)
sch.storage_align(block=b102, buffer_index=0, axis=-2, factor=32, offset=8)
sch.compute_inline(block=b0)
v155 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v155)
sch.enter_postproc()
sch.unannotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch")
l156, l157, l158, l159 = sch.get_loops(block=b54)
l160, l161, l162 = sch.split(loop=l159, factors=[None, 2, 32], preserve_unit_iters=True)
sch.bind(loop=l162, thread_axis="threadIdx.x")
sch.bind(loop=l161, thread_axis="threadIdx.y")
sch.unannotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch")
l163, l164, l165, l166, l167 = sch.get_loops(block=b93)
l168, l169, l170 = sch.split(loop=l167, factors=[None, 2, 32], preserve_unit_iters=True)
sch.bind(loop=l170, thread_axis="threadIdx.x")
sch.bind(loop=l169, thread_axis="threadIdx.y")
sch.unannotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch")
l171, l172, l173, l174, l175 = sch.get_loops(block=b102)
l176, l177, l178, l179 = sch.split(loop=l175, factors=[None, 2, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l179)
sch.bind(loop=l178, thread_axis="threadIdx.x")
sch.bind(loop=l177, thread_axis="threadIdx.y")
b180 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b180, ann_key="meta_schedule.unroll_explicit")
b181, b182, b183, b184, b185, b186, b187 = sch.get_child_blocks(b180)
l188, l189, l190, l191, l192, l193, l194 = sch.get_loops(block=b181)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l195, l196, l197, l198, l199, l200, l201, l202 = sch.get_loops(block=b182)
sch.annotate(block_or_loop=l195, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l195, ann_key="pragma_unroll_explicit", ann_val=1)
l203, l204, l205, l206, l207, l208, l209 = sch.get_loops(block=b183)
sch.annotate(block_or_loop=l203, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l203, ann_key="pragma_unroll_explicit", ann_val=1)
l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b184)
sch.annotate(block_or_loop=l210, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l210, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220, l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b185)
sch.annotate(block_or_loop=l217, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l217, ann_key="pragma_unroll_explicit", ann_val=1)
l227, l228, l229, l230, l231, l232 = sch.get_loops(block=b186)
sch.annotate(block_or_loop=l227, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l227, ann_key="pragma_unroll_explicit", ann_val=1)
l233, l234, l235, l236, l237, l238 = sch.get_loops(block=b187)
sch.annotate(block_or_loop=l233, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l233, ann_key="pragma_unroll_explicit", ann_val=1)
b239 = sch.get_block(name="B_o", func_name="main")
l240, l241, l242, l243, l244, l245, l246, l247, l248, l249 = sch.get_loops(block=b239)
b250 = sch.decompose_reduction(block=b239, loop=l243)
sch.unannotate(block_or_loop=b250, ann_key="meta_schedule.auto_tensorize")
sch.annotate(block_or_loop=b250, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_fill_16x16x16_f16")
sch.unannotate(block_or_loop=b239, ann_key="meta_schedule.auto_tensorize_init")
sch.unannotate(block_or_loop=b250, ann_key="meta_schedule.auto_tensorize_init")
b251 = sch.get_block(name="B_o_init", func_name="main")
sch.unannotate(block_or_loop=b251, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b251, tensor_intrin="wmma_fill_16x16x16_f16", preserve_unit_iters=True)
b252 = sch.get_block(name="A_reindex_shared.dyn_wmma.matrix_a_o", func_name="main")
sch.unannotate(block_or_loop=b252, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b252, tensor_intrin="wmma_load_16x16x16_f16_a_shared_dyn", preserve_unit_iters=True)
b253 = sch.get_block(name="B_decompress_reindex_shared.dyn_wmma.matrix_b_o", func_name="main")
sch.unannotate(block_or_loop=b253, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b253, tensor_intrin="wmma_load_16x16x16_f16_b_trans_shared_dyn", preserve_unit_iters=True)
b254 = sch.get_block(name="B_o_update", func_name="main")
sch.unannotate(block_or_loop=b254, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b254, tensor_intrin="wmma_sync_16x16x16_f16f16f16_trans", preserve_unit_iters=True)
b255 = sch.get_block(name="C_reindex_shared.dyn_wmma.accumulator_o", func_name="main")
sch.unannotate(block_or_loop=b255, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b255, tensor_intrin="wmma_store_16x16x16_f16_shared_dyn", preserve_unit_iters=True)
2023-05-01 16:19:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #25: GFLOPs: 14571.4500. Time: 603947.3060 us. Best GFLOPs: 70769.6862
2023-05-01 16:19:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #26: GFLOPs: 11595.2810. Time: 758962.8903 us. Best GFLOPs: 70769.6862
2023-05-01 16:19:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #27: GFLOPs: 21629.3389. Time: 406872.7213 us. Best GFLOPs: 70769.6862
2023-05-01 16:19:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #28: GFLOPs: 35595.9375. Time: 247230.1227 us. Best GFLOPs: 70769.6862
2023-05-01 16:19:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #29: GFLOPs: 51848.4047. Time: 169733.0523 us. Best GFLOPs: 70769.6862
2023-05-01 16:19:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #30: GFLOPs: 16702.7103. Time: 526883.8297 us. Best GFLOPs: 70769.6862
2023-05-01 16:19:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #31: GFLOPs: 39291.2042. Time: 223978.5763 us. Best GFLOPs: 70769.6862
2023-05-01 16:19:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #32: GFLOPs: 48012.0744. Time: 183295.3083 us. Best GFLOPs: 70769.6862
2023-05-01 16:19:23 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 16:19:24 [INFO] [evolutionary_search.cc:715] Picked top 30 candidate(s) from database
2023-05-01 16:19:28 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 472 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:19:32 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 944 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:19:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1415 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:19:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1889 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:19:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2363 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:19:49 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2833 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:19:49 [INFO] [evolutionary_search.cc:723] Sampled 59 candidate(s)
2023-05-01 16:19:55 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 85 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:20:01 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 77 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:20:07 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 83 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:20:13 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 81 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:20:14 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9989  0.9988  0.9983  0.9982  0.9979  0.9941  0.9935  0.9927  0.9923  0.9914  0.9912  0.9909  0.9907  0.9906  0.9905  0.9893
2023-05-01 16:20:14 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 16:20:14 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 16:27:36 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #33: GFLOPs: 31846.4244. Time: 276338.3380 us. Best GFLOPs: 70769.6862
2023-05-01 16:27:36 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #34: GFLOPs: 19270.8316. Time: 456668.8230 us. Best GFLOPs: 70769.6862
2023-05-01 16:27:36 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #35: GFLOPs: 27502.5624. Time: 319984.2933 us. Best GFLOPs: 70769.6862
2023-05-01 16:27:36 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #36: GFLOPs: 16598.8870. Time: 530179.4027 us. Best GFLOPs: 70769.6862
2023-05-01 16:27:36 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #37: GFLOPs: 18984.8884. Time: 463546.9970 us. Best GFLOPs: 70769.6862
2023-05-01 16:27:36 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #38: GFLOPs: 28100.3885. Time: 313176.7373 us. Best GFLOPs: 70769.6862
2023-05-01 16:27:36 [INFO] [task_scheduler.cc:121] [Task #0: main] Trial #39: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 8192), "int8"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        C_reindex_shared_dyn = T.alloc_buffer((1024, 256, 1, 4, 16, 16), "float16", scope="shared.dyn")
        C_reindex_shared_dyn_wmma_accumulator = T.alloc_buffer((1024, 256, 1, 4, 16, 16), "float16", scope="wmma.accumulator")
        A_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
        B_decompress_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
        A_reindex_shared_dyn_wmma_matrix_a = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_a")
        B_decompress_reindex_shared_dyn_wmma_matrix_b = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_b")
        for ax0_0_0_ax1_0_0_fused in T.thread_binding(16, thread="blockIdx.y", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ax0_0_1_ax1_0_1_fused in T.thread_binding(16384, thread="blockIdx.x"):
                for ax0_0_2_ax1_0_2_fused in T.thread_binding(1, thread="threadIdx.y"):
                    for ax0_0_3_init, ax1_0_3_init, ax0_0_4_init, ax1_0_4_init in T.grid(1, 4, 1, 1):
                        with T.block("B_o_init"):
                            v0_o = T.axis.spatial(1024, ax0_0_4_init + ax0_0_0_ax1_0_0_fused * 64 + ax0_0_1_ax1_0_1_fused // 256 + ax0_0_3_init)
                            v1_o = T.axis.spatial(1024, ax1_0_4_init + ax0_0_1_ax1_0_1_fused % 256 * 4 + ax1_0_3_init)
                            T.reads()
                            T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 4, 0, v1_o % 4, 0:16, 0:16])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                            C_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 4, 0, v1_o % 4, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.accumulator", offset_factor=16)
                            T.tvm_fill_fragment(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.float32(0))
                    for ax2_0_0 in range(64):
                        for ax0_ax1_fused_0 in range(64):
                            for ax0_ax1_fused_1 in T.thread_binding(1, thread="threadIdx.y"):
                                for ax0_ax1_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                    for ax0_ax1_fused_3 in T.vectorized(2):
                                        with T.block("A_reindex_shared.dyn"):
                                            v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused * 1024 + ax0_0_1_ax1_0_1_fused // 256 * 16 + (ax0_ax1_fused_0 * 64 + ax0_ax1_fused_1 * 64 + ax0_ax1_fused_2 * 2 + ax0_ax1_fused_3) // 256)
                                            v1 = T.axis.spatial(16384, ax2_0_0 * 256 + (ax0_ax1_fused_0 * 64 + ax0_ax1_fused_1 * 64 + ax0_ax1_fused_2 * 2 + ax0_ax1_fused_3) % 256)
                                            T.reads(A[v0, v1])
                                            T.writes(A_reindex_shared_dyn[v0, v1])
                                            T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]]})
                                            A_reindex_shared_dyn[v0, v1] = A[v0, v1]
                        for ax0_ax1_fused_0 in range(256):
                            for ax0_ax1_fused_1 in T.thread_binding(1, thread="threadIdx.y"):
                                for ax0_ax1_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                    for ax0_ax1_fused_3 in T.vectorized(2):
                                        with T.block("B_decompress_reindex_shared.dyn"):
                                            v0 = T.axis.spatial(16384, ax2_0_0 * 256 + (ax0_ax1_fused_0 * 64 + ax0_ax1_fused_1 * 64 + ax0_ax1_fused_2 * 2 + ax0_ax1_fused_3) // 64)
                                            v1 = T.axis.spatial(16384, ax0_0_1_ax1_0_1_fused % 256 * 64 + (ax0_ax1_fused_0 * 64 + ax0_ax1_fused_1 * 64 + ax0_ax1_fused_2 * 2 + ax0_ax1_fused_3) % 64)
                                            T.reads(B[v1, v0 // 2:v0 // 2 + 2])
                                            T.writes(B_decompress_reindex_shared_dyn[v0, v1])
                                            T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]]})
                                            B_decompress_reindex_shared_dyn[v0, v1] = T.Select(v0 % 32 * 4 % 8 <= 5, T.Cast("float16", T.bitwise_and(T.shift_right(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8]), v0 % 32 * 4 % 8), 15)), T.Cast("float16", T.bitwise_or(T.Cast("int8", T.bitwise_and(T.shift_right(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8]), v0 % 32 * 4 % 8), T.shift_left(1, 8 - v0 % 32 * 4 % 8) - 1)), T.Cast("int8", T.bitwise_and(T.bitwise_and(T.shift_left(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8 + 1]), 8 - v0 % 32 * 4 % 8), T.shift_left(15, 8 - v0 % 32 * 4 % 8)), 15)))))
                        for ax2_0_1 in range(8):
                            for ax0_0, ax1_0 in T.grid(1, 2):
                                with T.block("A_reindex_shared.dyn_wmma.matrix_a_o"):
                                    v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused * 64 + ax0_0_1_ax1_0_1_fused // 256 + ax0_0)
                                    v1_o = T.axis.spatial(1024, ax2_0_0 * 16 + ax2_0_1 * 2 + ax1_0)
                                    T.reads(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    A_1 = T.match_buffer(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="shared.dyn", offset_factor=16)
                                    C_1 = T.match_buffer(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.matrix_a", offset_factor=16)
                                    T.tvm_load_matrix_sync(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), A_1.data, A_1.elem_offset, A_1.strides[0] * 16, 1), A_1.strides[0], "row_major")
                            for ax0_0, ax1_0 in T.grid(2, 4):
                                with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b_o"):
                                    v0_o = T.axis.spatial(1024, ax2_0_0 * 16 + ax2_0_1 * 2 + ax0_0)
                                    v1_o = T.axis.spatial(1024, ax0_0_1_ax1_0_1_fused % 256 * 4 + ax1_0)
                                    T.reads(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    A_1 = T.match_buffer(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="shared.dyn", offset_factor=16)
                                    C_1 = T.match_buffer(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.matrix_b", offset_factor=16)
                                    T.tvm_load_matrix_sync(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), A_1.data, A_1.elem_offset, A_1.strides[0] * 16, 1), A_1.strides[0], "row_major")
                            for ax0_0_3, ax1_0_3, ax2_0_2, ax0_0_4, ax1_0_4 in T.grid(1, 4, 2, 1, 1):
                                with T.block("B_o_update"):
                                    v0_o = T.axis.spatial(1024, ax0_0_4 + ax0_0_0_ax1_0_0_fused * 64 + ax0_0_1_ax1_0_1_fused // 256 + ax0_0_3)
                                    v1_o = T.axis.spatial(1024, ax1_0_4 + ax0_0_1_ax1_0_1_fused % 256 * 4 + ax1_0_3)
                                    v2_o = T.axis.reduce(1024, ax2_0_0 * 16 + ax2_0_1 * 2 + ax2_0_2)
                                    T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 4, 0, v1_o % 4, 0:16, 0:16], A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], B_decompress_reindex_shared_dyn_wmma_matrix_b[v2_o * 16:v2_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 4, 0, v1_o % 4, 0:16, 0:16])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                                    A_1 = T.match_buffer(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="wmma.matrix_a", offset_factor=16)
                                    B_1 = T.match_buffer(B_decompress_reindex_shared_dyn_wmma_matrix_b[v2_o * 16:v2_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("B_s0", "B_s1"), scope="wmma.matrix_b", offset_factor=16)
                                    C_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 4, 0, v1_o % 4, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.accumulator", offset_factor=16)
                                    T.tvm_mma_sync(C_1.data, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, A_1.data, A_1.elem_offset // A_1.strides[0] // 16 * (A_1.strides[0] // 16) + A_1.elem_offset % A_1.strides[0] // 16, B_1.data, B_1.elem_offset // B_1.strides[0] // 16 * (B_1.strides[0] // 16) + B_1.elem_offset % B_1.strides[0] // 16, C_1.data, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16)
                for ax2 in range(1):
                    for ax0_ax1_fused in T.thread_binding(1, thread="threadIdx.y"):
                        for ax2_1, ax3 in T.grid(1, 4):
                            with T.block("C_reindex_shared.dyn_wmma.accumulator_o"):
                                v0 = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused * 64 + ax0_0_1_ax1_0_1_fused // 256)
                                v1 = T.axis.spatial(256, ax0_0_1_ax1_0_1_fused % 256)
                                v2, v3 = T.axis.remap("SS", [ax2_1, ax3])
                                v4_o = T.axis.spatial(1, 0)
                                v5_o = T.axis.spatial(1, 0)
                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16])
                                T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16])
                                A_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="wmma.accumulator", offset_factor=16)
                                C_1 = T.match_buffer(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="shared.dyn", offset_factor=16)
                                T.tvm_store_matrix_sync(A_1.data, 16, 16, 16, A_1.elem_offset // A_1.strides[0] // 16 * (A_1.strides[0] // 16) + A_1.elem_offset % A_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), C_1.data, C_1.elem_offset, C_1.strides[0] * 16, 2), C_1.strides[0], "row_major")
                    for ax0_ax1_ax3_ax4_ax5_fused_0 in range(4):
                        for ax0_ax1_ax3_ax4_ax5_fused_1 in T.thread_binding(1, thread="threadIdx.y"):
                            for ax0_ax1_ax3_ax4_ax5_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax3_ax4_ax5_fused_3 in T.vectorized(8):
                                    with T.block("C_reindex_shared.dyn"):
                                        v0 = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused * 64 + ax0_0_1_ax1_0_1_fused // 256)
                                        v1 = T.axis.spatial(256, ax0_0_1_ax1_0_1_fused % 256)
                                        v2 = T.axis.spatial(1, ax2)
                                        v3 = T.axis.spatial(4, (ax0_ax1_ax3_ax4_ax5_fused_0 * 256 + ax0_ax1_ax3_ax4_ax5_fused_1 * 256 + ax0_ax1_ax3_ax4_ax5_fused_2 * 8 + ax0_ax1_ax3_ax4_ax5_fused_3) // 256)
                                        v4 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 256 + ax0_ax1_ax3_ax4_ax5_fused_1 * 256 + ax0_ax1_ax3_ax4_ax5_fused_2 * 8 + ax0_ax1_ax3_ax4_ax5_fused_3) % 256 // 16)
                                        v5 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 256 + ax0_ax1_ax3_ax4_ax5_fused_1 * 256 + ax0_ax1_ax3_ax4_ax5_fused_2 * 8 + ax0_ax1_ax3_ax4_ax5_fused_3) % 16)
                                        T.reads(C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5])
                                        T.writes(C[v4 + v0 * 16, v5 + v3 * 16 + v1 * 64])
                                        C[v4 + v0 * 16, v5 + v3 * 16 + v1 * 64] = C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5]
b0 = sch.get_block(name="B_decompress", func_name="main")
b1 = sch.get_block(name="B", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
b3 = sch.reindex(block=b1, buffer=("write", 0))
b4 = sch.reindex(block=b1, buffer=("read", 0))
b5 = sch.reindex(block=b1, buffer=("read", 1))
sch.transform_layout(block=b1, buffer=("read", 0), index_map=lambda vi, vk: (vi, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("read", 1), index_map=lambda vj, vk: (vk, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("write", 0), index_map=lambda vi, vj: (vi, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_block_layout(block=b3, index_map=lambda vi, vj: (vi, vj,))
sch.transform_block_layout(block=b4, index_map=lambda vi, vk: (vi, vk,))
sch.transform_block_layout(block=b5, index_map=lambda vj, vk: (vk, vj,))
sch.transform_block_layout(block=b1, index_map=lambda vi, vj, vk: (vi, vj, vk,))
l6, l7, l8 = sch.get_loops(block=b1)
l9, l10 = sch.split(loop=l8, factors=[None, 16], preserve_unit_iters=True)
l11, l12 = sch.split(loop=l7, factors=[None, 16], preserve_unit_iters=True)
l13, l14 = sch.split(loop=l6, factors=[None, 16], preserve_unit_iters=True)
l15, l16, l17, l18, l19, l20 = sch.get_loops(block=b1)
sch.reorder(l17, l19, l14, l12, l10)
b21 = sch.blockize(loop=l14, preserve_unit_iters=True)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_sync_16x16x16_f16f16f16")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize_init", ann_val="wmma_fill_16x16x16_f16")
sch.annotate(block_or_loop=b21, ann_key="warp_execution", ann_val=1)
l22, l23, l24 = sch.get_loops(block=b21)
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l22, n=5, max_innermost_factor=4, decision=[16, 64, 1, 1, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l22, factors=[v25, v26, v27, v28, v29], preserve_unit_iters=True)
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l23, n=5, max_innermost_factor=4, decision=[1, 256, 1, 4, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l23, factors=[v35, v36, v37, v38, v39], preserve_unit_iters=True)
v45, v46, v47 = sch.sample_perfect_tile(loop=l24, n=3, max_innermost_factor=4, decision=[64, 8, 2])
l48, l49, l50 = sch.split(loop=l24, factors=[v45, v46, v47], preserve_unit_iters=True)
sch.reorder(l30, l40, l31, l41, l32, l42, l48, l49, l33, l43, l50, l34, l44)
l51 = sch.fuse(l30, l40, preserve_unit_iters=True)
sch.bind(loop=l51, thread_axis="blockIdx.y")
l52 = sch.fuse(l31, l41, preserve_unit_iters=True)
sch.bind(loop=l52, thread_axis="blockIdx.x")
l53 = sch.fuse(l32, l42, preserve_unit_iters=True)
sch.bind(loop=l53, thread_axis="threadIdx.y")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
sch.transform_layout(block=b21, buffer=("write", 0), index_map=lambda i0, i1: (i0 // 16 // (v28 * v29), i1 // 16 // (v38 * v39), i0 // 16 % (v28 * v29), i1 // 16 % (v38 * v39), i0 % 16, i1 % 16,), pad_value=None, assume_injective_transform=True)
b54 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="shared.dyn")
sch.reverse_compute_at(block=b54, loop=l52, preserve_unit_loops=True, index=-1)
b55 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="wmma.accumulator")
l56, l57, l58, l59, l60, l61, l62, l63 = sch.get_loops(block=b54)
sch.reorder(l60, l58, l59, l61)
sch.compute_at(block=b55, loop=l60, preserve_unit_loops=True, index=-1)
l64, l65, l66, l67, l68, l69, l70, l71, l72 = sch.get_loops(block=b55)
l73 = sch.fuse(l67, l68, preserve_unit_iters=True)
sch.bind(loop=l73, thread_axis="threadIdx.y")
sch.reverse_compute_inline(block=b3)
l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b55)
b82 = sch.blockize(loop=l80, preserve_unit_iters=True)
sch.annotate(block_or_loop=b82, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_store_16x16x16_f16_shared_dyn")
l83, l84, l85, l86, l87, l88, l89, l90 = sch.get_loops(block=b54)
l91 = sch.fuse(l86, l87, l88, l89, l90, preserve_unit_iters=True)
v92 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch", ann_val=v92)
b93 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b93, loop=l48, preserve_unit_loops=True, index=-1)
l94, l95, l96, l97, l98, l99 = sch.get_loops(block=b93)
l100 = sch.fuse(l98, l99, preserve_unit_iters=True)
v101 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch", ann_val=v101)
b102 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b102, loop=l48, preserve_unit_loops=True, index=-1)
l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b102)
l109 = sch.fuse(l107, l108, preserve_unit_iters=True)
v110 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch", ann_val=v110)
b111 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="wmma.matrix_a")
sch.compute_at(block=b111, loop=l49, preserve_unit_loops=True, index=-1)
l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b111)
l119, l120 = sch.split(loop=l118, factors=[None, 16], preserve_unit_iters=True)
l121, l122 = sch.split(loop=l117, factors=[None, 16], preserve_unit_iters=True)
l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b111)
sch.reorder(l130, l122, l120)
b132 = sch.blockize(loop=l122, preserve_unit_iters=True)
sch.annotate(block_or_loop=b132, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_a_shared_dyn")
b133 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="wmma.matrix_b")
sch.compute_at(block=b133, loop=l49, preserve_unit_loops=True, index=-1)
l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b133)
l141, l142 = sch.split(loop=l140, factors=[None, 16], preserve_unit_iters=True)
l143, l144 = sch.split(loop=l139, factors=[None, 16], preserve_unit_iters=True)
l145, l146, l147, l148, l149, l150, l151, l152, l153 = sch.get_loops(block=b133)
sch.reorder(l152, l144, l142)
b154 = sch.blockize(loop=l144, preserve_unit_iters=True)
sch.annotate(block_or_loop=b154, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_b_shared_dyn")
sch.compute_inline(block=b4)
sch.compute_inline(block=b5)
sch.storage_align(block=b93, buffer_index=0, axis=-2, factor=32, offset=8)
sch.storage_align(block=b102, buffer_index=0, axis=-2, factor=32, offset=8)
sch.compute_inline(block=b0)
v155 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v155)
sch.enter_postproc()
sch.unannotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch")
l156, l157, l158, l159 = sch.get_loops(block=b54)
l160, l161, l162, l163 = sch.split(loop=l159, factors=[None, 1, 32, 8], preserve_unit_iters=True)
sch.vectorize(loop=l163)
sch.bind(loop=l162, thread_axis="threadIdx.x")
sch.bind(loop=l161, thread_axis="threadIdx.y")
sch.unannotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch")
l164, l165, l166, l167, l168 = sch.get_loops(block=b93)
l169, l170, l171, l172 = sch.split(loop=l168, factors=[None, 1, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l172)
sch.bind(loop=l171, thread_axis="threadIdx.x")
sch.bind(loop=l170, thread_axis="threadIdx.y")
sch.unannotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch")
l173, l174, l175, l176, l177 = sch.get_loops(block=b102)
l178, l179, l180, l181 = sch.split(loop=l177, factors=[None, 1, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l181)
sch.bind(loop=l180, thread_axis="threadIdx.x")
sch.bind(loop=l179, thread_axis="threadIdx.y")
b182 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b182, ann_key="meta_schedule.unroll_explicit")
b183, b184, b185, b186, b187, b188, b189 = sch.get_child_blocks(b182)
l190, l191, l192, l193, l194, l195, l196, l197 = sch.get_loops(block=b183)
sch.annotate(block_or_loop=l190, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l190, ann_key="pragma_unroll_explicit", ann_val=1)
l198, l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b184)
sch.annotate(block_or_loop=l198, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l198, ann_key="pragma_unroll_explicit", ann_val=1)
l206, l207, l208, l209, l210, l211, l212 = sch.get_loops(block=b185)
sch.annotate(block_or_loop=l206, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l206, ann_key="pragma_unroll_explicit", ann_val=1)
l213, l214, l215, l216, l217, l218, l219 = sch.get_loops(block=b186)
sch.annotate(block_or_loop=l213, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l213, ann_key="pragma_unroll_explicit", ann_val=1)
l220, l221, l222, l223, l224, l225, l226, l227, l228, l229 = sch.get_loops(block=b187)
sch.annotate(block_or_loop=l220, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l220, ann_key="pragma_unroll_explicit", ann_val=1)
l230, l231, l232, l233, l234, l235 = sch.get_loops(block=b188)
sch.annotate(block_or_loop=l230, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l230, ann_key="pragma_unroll_explicit", ann_val=1)
l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b189)
sch.annotate(block_or_loop=l236, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l236, ann_key="pragma_unroll_explicit", ann_val=1)
b243 = sch.get_block(name="B_o", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b243)
b254 = sch.decompose_reduction(block=b243, loop=l247)
sch.unannotate(block_or_loop=b254, ann_key="meta_schedule.auto_tensorize")
sch.annotate(block_or_loop=b254, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_fill_16x16x16_f16")
sch.unannotate(block_or_loop=b243, ann_key="meta_schedule.auto_tensorize_init")
sch.unannotate(block_or_loop=b254, ann_key="meta_schedule.auto_tensorize_init")
b255 = sch.get_block(name="B_o_init", func_name="main")
sch.unannotate(block_or_loop=b255, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b255, tensor_intrin="wmma_fill_16x16x16_f16", preserve_unit_iters=True)
b256 = sch.get_block(name="A_reindex_shared.dyn_wmma.matrix_a_o", func_name="main")
sch.unannotate(block_or_loop=b256, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b256, tensor_intrin="wmma_load_16x16x16_f16_a_shared_dyn", preserve_unit_iters=True)
b257 = sch.get_block(name="B_decompress_reindex_shared.dyn_wmma.matrix_b_o", func_name="main")
sch.unannotate(block_or_loop=b257, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b257, tensor_intrin="wmma_load_16x16x16_f16_b_shared_dyn", preserve_unit_iters=True)
b258 = sch.get_block(name="B_o_update", func_name="main")
sch.unannotate(block_or_loop=b258, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b258, tensor_intrin="wmma_sync_16x16x16_f16f16f16", preserve_unit_iters=True)
b259 = sch.get_block(name="C_reindex_shared.dyn_wmma.accumulator_o", func_name="main")
sch.unannotate(block_or_loop=b259, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b259, tensor_intrin="wmma_store_16x16x16_f16_shared_dyn", preserve_unit_iters=True)
2023-05-01 16:27:36 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #40: GFLOPs: 30577.5596. Time: 287805.4400 us. Best GFLOPs: 70769.6862
2023-05-01 16:27:36 [INFO] [task_scheduler.cc:121] [Task #0: main] Trial #41: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 8192), "int8"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        C_reindex_shared_dyn = T.alloc_buffer((1024, 256, 1, 4, 16, 16), "float16", scope="shared.dyn")
        C_reindex_shared_dyn_wmma_accumulator = T.alloc_buffer((1024, 256, 1, 4, 16, 16), "float16", scope="wmma.accumulator")
        A_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
        B_decompress_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
        A_reindex_shared_dyn_wmma_matrix_a = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_a")
        B_decompress_reindex_shared_dyn_wmma_matrix_b = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_b")
        for ax0_0_0_ax1_0_0_fused in T.thread_binding(2, thread="blockIdx.y", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ax0_0_1_ax1_0_1_fused in T.thread_binding(16384, thread="blockIdx.x"):
                for ax0_0_2_ax1_0_2_fused in T.thread_binding(8, thread="threadIdx.y"):
                    for ax0_0_3_init, ax1_0_3_init, ax0_0_4_init, ax1_0_4_init in T.grid(1, 1, 1, 4):
                        with T.block("B_o_init"):
                            v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused * 512 + ax0_0_1_ax1_0_1_fused // 64 * 2 + ax0_0_2_ax1_0_2_fused // 4 + ax0_0_3_init + ax0_0_4_init)
                            v1_o = T.axis.spatial(1024, ax0_0_1_ax1_0_1_fused % 64 * 16 + ax0_0_2_ax1_0_2_fused % 4 * 4 + ax1_0_3_init * 4 + ax1_0_4_init)
                            T.reads()
                            T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 4, 0, v1_o % 4, 0:16, 0:16])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                            C_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 4, 0, v1_o % 4, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.accumulator", offset_factor=16)
                            T.tvm_fill_fragment(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.float32(0))
                    for ax2_0_0 in range(1024):
                        for ax0_ax1_fused_0 in range(1):
                            for ax0_ax1_fused_1 in T.thread_binding(8, thread="threadIdx.y"):
                                for ax0_ax1_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                    for ax0_ax1_fused_3 in T.vectorized(2):
                                        with T.block("A_reindex_shared.dyn"):
                                            v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused * 8192 + ax0_0_1_ax1_0_1_fused // 64 * 32 + (ax0_ax1_fused_0 * 512 + ax0_ax1_fused_1 * 64 + ax0_ax1_fused_2 * 2 + ax0_ax1_fused_3) // 16)
                                            v1 = T.axis.spatial(16384, ax2_0_0 * 16 + (ax0_ax1_fused_0 * 512 + ax0_ax1_fused_1 * 64 + ax0_ax1_fused_2 * 2 + ax0_ax1_fused_3) % 16)
                                            T.reads(A[v0, v1])
                                            T.writes(A_reindex_shared_dyn[v0, v1])
                                            T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]]})
                                            A_reindex_shared_dyn[v0, v1] = A[v0, v1]
                        for ax0_ax1_fused_0 in range(16):
                            for ax0_ax1_fused_1 in T.thread_binding(8, thread="threadIdx.y"):
                                for ax0_ax1_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                    with T.block("B_decompress_reindex_shared.dyn"):
                                        v0 = T.axis.spatial(16384, ax0_0_1_ax1_0_1_fused % 64 * 256 + (ax0_ax1_fused_0 * 256 + ax0_ax1_fused_1 * 32 + ax0_ax1_fused_2) // 16)
                                        v1 = T.axis.spatial(16384, ax2_0_0 * 16 + (ax0_ax1_fused_0 * 256 + ax0_ax1_fused_1 * 32 + ax0_ax1_fused_2) % 16)
                                        T.reads(B[v0, v1 // 2:v1 // 2 + 2])
                                        T.writes(B_decompress_reindex_shared_dyn[v0, v1])
                                        T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]]})
                                        B_decompress_reindex_shared_dyn[v0, v1] = T.Select(v1 % 32 * 4 % 8 <= 5, T.Cast("float16", T.bitwise_and(T.shift_right(T.Cast("int32", B[v0, v1 // 32 * 16 + v1 % 32 * 4 // 8]), v1 % 32 * 4 % 8), 15)), T.Cast("float16", T.bitwise_or(T.Cast("int8", T.bitwise_and(T.shift_right(T.Cast("int32", B[v0, v1 // 32 * 16 + v1 % 32 * 4 // 8]), v1 % 32 * 4 % 8), T.shift_left(1, 8 - v1 % 32 * 4 % 8) - 1)), T.Cast("int8", T.bitwise_and(T.bitwise_and(T.shift_left(T.Cast("int32", B[v0, v1 // 32 * 16 + v1 % 32 * 4 // 8 + 1]), 8 - v1 % 32 * 4 % 8), T.shift_left(15, 8 - v1 % 32 * 4 % 8)), 15)))))
                        for ax2_0_1 in range(1):
                            for ax0_0, ax1_0 in T.grid(1, 1):
                                with T.block("A_reindex_shared.dyn_wmma.matrix_a_o"):
                                    v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused * 512 + ax0_0_1_ax1_0_1_fused // 64 * 2 + ax0_0_2_ax1_0_2_fused // 4 + ax0_0)
                                    v1_o = T.axis.spatial(1024, ax2_0_0 + ax1_0)
                                    T.reads(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    A_1 = T.match_buffer(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="shared.dyn", offset_factor=16)
                                    C_1 = T.match_buffer(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.matrix_a", offset_factor=16)
                                    T.tvm_load_matrix_sync(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), A_1.data, A_1.elem_offset, A_1.strides[0] * 16, 1), A_1.strides[0], "row_major")
                            for ax0_0, ax1_0 in T.grid(4, 1):
                                with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b_o"):
                                    v0_o = T.axis.spatial(1024, ax0_0_1_ax1_0_1_fused % 64 * 16 + ax0_0_2_ax1_0_2_fused % 4 * 4 + ax0_0)
                                    v1_o = T.axis.spatial(1024, ax2_0_0 + ax1_0)
                                    T.reads(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    A_1 = T.match_buffer(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="shared.dyn", offset_factor=16)
                                    C_1 = T.match_buffer(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.matrix_b", offset_factor=16)
                                    T.tvm_load_matrix_sync(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), A_1.data, A_1.elem_offset, A_1.strides[0] * 16, 1), A_1.strides[0], "col_major")
                            for ax0_0_3, ax1_0_3, ax2_0_2, ax0_0_4, ax1_0_4 in T.grid(1, 1, 1, 1, 4):
                                with T.block("B_o_update"):
                                    v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused * 512 + ax0_0_1_ax1_0_1_fused // 64 * 2 + ax0_0_2_ax1_0_2_fused // 4 + ax0_0_3 + ax0_0_4)
                                    v1_o = T.axis.spatial(1024, ax0_0_1_ax1_0_1_fused % 64 * 16 + ax0_0_2_ax1_0_2_fused % 4 * 4 + ax1_0_3 * 4 + ax1_0_4)
                                    v2_o = T.axis.reduce(1024, ax2_0_1 + ax2_0_2 + ax2_0_0)
                                    T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 4, 0, v1_o % 4, 0:16, 0:16], A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], B_decompress_reindex_shared_dyn_wmma_matrix_b[v1_o * 16:v1_o * 16 + 16, v2_o * 16:v2_o * 16 + 16])
                                    T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 4, 0, v1_o % 4, 0:16, 0:16])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                                    A_1 = T.match_buffer(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="wmma.matrix_a", offset_factor=16)
                                    B_1 = T.match_buffer(B_decompress_reindex_shared_dyn_wmma_matrix_b[v1_o * 16:v1_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], (16, 16), "float16", strides=("B_s0", "B_s1"), scope="wmma.matrix_b", offset_factor=16)
                                    C_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 4, 0, v1_o % 4, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.accumulator", offset_factor=16)
                                    T.tvm_mma_sync(C_1.data, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, A_1.data, A_1.elem_offset // A_1.strides[0] // 16 * (A_1.strides[0] // 16) + A_1.elem_offset % A_1.strides[0] // 16, B_1.data, B_1.elem_offset // B_1.strides[0] // 16 * (B_1.strides[0] // 16) + B_1.elem_offset % B_1.strides[0] // 16, C_1.data, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16)
                for ax2 in range(1):
                    for ax0_ax1_fused in T.thread_binding(8, thread="threadIdx.y"):
                        for ax2_1, ax3 in T.grid(1, 4):
                            with T.block("C_reindex_shared.dyn_wmma.accumulator_o"):
                                v0 = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused * 512 + ax0_0_1_ax1_0_1_fused // 64 * 2 + ax0_ax1_fused // 4)
                                v1 = T.axis.spatial(256, ax0_0_1_ax1_0_1_fused % 64 * 4 + ax0_ax1_fused % 4)
                                v2, v3 = T.axis.remap("SS", [ax2_1, ax3])
                                v4_o = T.axis.spatial(1, 0)
                                v5_o = T.axis.spatial(1, 0)
                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16])
                                T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16])
                                A_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="wmma.accumulator", offset_factor=16)
                                C_1 = T.match_buffer(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="shared.dyn", offset_factor=16)
                                T.tvm_store_matrix_sync(A_1.data, 16, 16, 16, A_1.elem_offset // A_1.strides[0] // 16 * (A_1.strides[0] // 16) + A_1.elem_offset % A_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), C_1.data, C_1.elem_offset, C_1.strides[0] * 16, 2), C_1.strides[0], "row_major")
                    for ax0_ax1_ax3_ax4_ax5_fused_0 in range(4):
                        for ax0_ax1_ax3_ax4_ax5_fused_1 in T.thread_binding(8, thread="threadIdx.y"):
                            for ax0_ax1_ax3_ax4_ax5_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax3_ax4_ax5_fused_3 in T.vectorized(8):
                                    with T.block("C_reindex_shared.dyn"):
                                        v0 = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused * 512 + ax0_0_1_ax1_0_1_fused // 64 * 2 + (ax0_ax1_ax3_ax4_ax5_fused_0 * 2048 + ax0_ax1_ax3_ax4_ax5_fused_1 * 256 + ax0_ax1_ax3_ax4_ax5_fused_2 * 8 + ax0_ax1_ax3_ax4_ax5_fused_3) // 4096)
                                        v1 = T.axis.spatial(256, ax0_0_1_ax1_0_1_fused % 64 * 4 + (ax0_ax1_ax3_ax4_ax5_fused_0 * 2048 + ax0_ax1_ax3_ax4_ax5_fused_1 * 256 + ax0_ax1_ax3_ax4_ax5_fused_2 * 8 + ax0_ax1_ax3_ax4_ax5_fused_3) % 4096 // 1024)
                                        v2 = T.axis.spatial(1, ax2)
                                        v3 = T.axis.spatial(4, (ax0_ax1_ax3_ax4_ax5_fused_0 * 2048 + ax0_ax1_ax3_ax4_ax5_fused_1 * 256 + ax0_ax1_ax3_ax4_ax5_fused_2 * 8 + ax0_ax1_ax3_ax4_ax5_fused_3) % 1024 // 256)
                                        v4 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 2048 + ax0_ax1_ax3_ax4_ax5_fused_1 * 256 + ax0_ax1_ax3_ax4_ax5_fused_2 * 8 + ax0_ax1_ax3_ax4_ax5_fused_3) % 256 // 16)
                                        v5 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 2048 + ax0_ax1_ax3_ax4_ax5_fused_1 * 256 + ax0_ax1_ax3_ax4_ax5_fused_2 * 8 + ax0_ax1_ax3_ax4_ax5_fused_3) % 16)
                                        T.reads(C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5])
                                        T.writes(C[v4 + v0 * 16, v5 + v3 * 16 + v1 * 64])
                                        C[v4 + v0 * 16, v5 + v3 * 16 + v1 * 64] = C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5]
b0 = sch.get_block(name="B_decompress", func_name="main")
b1 = sch.get_block(name="B", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
b3 = sch.reindex(block=b1, buffer=("write", 0))
b4 = sch.reindex(block=b1, buffer=("read", 0))
b5 = sch.reindex(block=b1, buffer=("read", 1))
sch.transform_layout(block=b1, buffer=("read", 0), index_map=lambda vi, vk: (vi, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("read", 1), index_map=lambda vj, vk: (vj, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("write", 0), index_map=lambda vi, vj: (vi, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_block_layout(block=b3, index_map=lambda vi, vj: (vi, vj,))
sch.transform_block_layout(block=b4, index_map=lambda vi, vk: (vi, vk,))
sch.transform_block_layout(block=b5, index_map=lambda vj, vk: (vj, vk,))
sch.transform_block_layout(block=b1, index_map=lambda vi, vj, vk: (vi, vj, vk,))
l6, l7, l8 = sch.get_loops(block=b1)
l9, l10 = sch.split(loop=l8, factors=[None, 16], preserve_unit_iters=True)
l11, l12 = sch.split(loop=l7, factors=[None, 16], preserve_unit_iters=True)
l13, l14 = sch.split(loop=l6, factors=[None, 16], preserve_unit_iters=True)
l15, l16, l17, l18, l19, l20 = sch.get_loops(block=b1)
sch.reorder(l17, l19, l14, l12, l10)
b21 = sch.blockize(loop=l14, preserve_unit_iters=True)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_sync_16x16x16_f16f16f16_trans")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize_init", ann_val="wmma_fill_16x16x16_f16")
sch.annotate(block_or_loop=b21, ann_key="warp_execution", ann_val=1)
l22, l23, l24 = sch.get_loops(block=b21)
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l22, n=5, max_innermost_factor=4, decision=[2, 256, 2, 1, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l22, factors=[v25, v26, v27, v28, v29], preserve_unit_iters=True)
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l23, n=5, max_innermost_factor=4, decision=[1, 64, 4, 1, 4])
l40, l41, l42, l43, l44 = sch.split(loop=l23, factors=[v35, v36, v37, v38, v39], preserve_unit_iters=True)
v45, v46, v47 = sch.sample_perfect_tile(loop=l24, n=3, max_innermost_factor=4, decision=[1024, 1, 1])
l48, l49, l50 = sch.split(loop=l24, factors=[v45, v46, v47], preserve_unit_iters=True)
sch.reorder(l30, l40, l31, l41, l32, l42, l48, l49, l33, l43, l50, l34, l44)
l51 = sch.fuse(l30, l40, preserve_unit_iters=True)
sch.bind(loop=l51, thread_axis="blockIdx.y")
l52 = sch.fuse(l31, l41, preserve_unit_iters=True)
sch.bind(loop=l52, thread_axis="blockIdx.x")
l53 = sch.fuse(l32, l42, preserve_unit_iters=True)
sch.bind(loop=l53, thread_axis="threadIdx.y")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
sch.transform_layout(block=b21, buffer=("write", 0), index_map=lambda i0, i1: (i0 // 16 // (v28 * v29), i1 // 16 // (v38 * v39), i0 // 16 % (v28 * v29), i1 // 16 % (v38 * v39), i0 % 16, i1 % 16,), pad_value=None, assume_injective_transform=True)
b54 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="shared.dyn")
sch.reverse_compute_at(block=b54, loop=l52, preserve_unit_loops=True, index=-1)
b55 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="wmma.accumulator")
l56, l57, l58, l59, l60, l61, l62, l63 = sch.get_loops(block=b54)
sch.reorder(l60, l58, l59, l61)
sch.compute_at(block=b55, loop=l60, preserve_unit_loops=True, index=-1)
l64, l65, l66, l67, l68, l69, l70, l71, l72 = sch.get_loops(block=b55)
l73 = sch.fuse(l67, l68, preserve_unit_iters=True)
sch.bind(loop=l73, thread_axis="threadIdx.y")
sch.reverse_compute_inline(block=b3)
l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b55)
b82 = sch.blockize(loop=l80, preserve_unit_iters=True)
sch.annotate(block_or_loop=b82, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_store_16x16x16_f16_shared_dyn")
l83, l84, l85, l86, l87, l88, l89, l90 = sch.get_loops(block=b54)
l91 = sch.fuse(l86, l87, l88, l89, l90, preserve_unit_iters=True)
v92 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch", ann_val=v92)
b93 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b93, loop=l48, preserve_unit_loops=True, index=-1)
l94, l95, l96, l97, l98, l99 = sch.get_loops(block=b93)
l100 = sch.fuse(l98, l99, preserve_unit_iters=True)
v101 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch", ann_val=v101)
b102 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b102, loop=l48, preserve_unit_loops=True, index=-1)
l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b102)
l109 = sch.fuse(l107, l108, preserve_unit_iters=True)
v110 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch", ann_val=v110)
b111 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="wmma.matrix_a")
sch.compute_at(block=b111, loop=l49, preserve_unit_loops=True, index=-1)
l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b111)
l119, l120 = sch.split(loop=l118, factors=[None, 16], preserve_unit_iters=True)
l121, l122 = sch.split(loop=l117, factors=[None, 16], preserve_unit_iters=True)
l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b111)
sch.reorder(l130, l122, l120)
b132 = sch.blockize(loop=l122, preserve_unit_iters=True)
sch.annotate(block_or_loop=b132, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_a_shared_dyn")
b133 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="wmma.matrix_b")
sch.compute_at(block=b133, loop=l49, preserve_unit_loops=True, index=-1)
l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b133)
l141, l142 = sch.split(loop=l140, factors=[None, 16], preserve_unit_iters=True)
l143, l144 = sch.split(loop=l139, factors=[None, 16], preserve_unit_iters=True)
l145, l146, l147, l148, l149, l150, l151, l152, l153 = sch.get_loops(block=b133)
sch.reorder(l152, l144, l142)
b154 = sch.blockize(loop=l144, preserve_unit_iters=True)
sch.annotate(block_or_loop=b154, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_b_trans_shared_dyn")
sch.compute_inline(block=b4)
sch.compute_inline(block=b5)
sch.storage_align(block=b93, buffer_index=0, axis=-2, factor=32, offset=8)
sch.storage_align(block=b102, buffer_index=0, axis=-2, factor=32, offset=8)
sch.compute_inline(block=b0)
v155 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v155)
sch.enter_postproc()
sch.unannotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch")
l156, l157, l158, l159 = sch.get_loops(block=b54)
l160, l161, l162, l163 = sch.split(loop=l159, factors=[None, 8, 32, 8], preserve_unit_iters=True)
sch.vectorize(loop=l163)
sch.bind(loop=l162, thread_axis="threadIdx.x")
sch.bind(loop=l161, thread_axis="threadIdx.y")
sch.unannotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch")
l164, l165, l166, l167, l168 = sch.get_loops(block=b93)
l169, l170, l171, l172 = sch.split(loop=l168, factors=[None, 8, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l172)
sch.bind(loop=l171, thread_axis="threadIdx.x")
sch.bind(loop=l170, thread_axis="threadIdx.y")
sch.unannotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch")
l173, l174, l175, l176, l177 = sch.get_loops(block=b102)
l178, l179, l180 = sch.split(loop=l177, factors=[None, 8, 32], preserve_unit_iters=True)
sch.bind(loop=l180, thread_axis="threadIdx.x")
sch.bind(loop=l179, thread_axis="threadIdx.y")
b181 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b181, ann_key="meta_schedule.unroll_explicit")
b182, b183, b184, b185, b186, b187, b188 = sch.get_child_blocks(b181)
l189, l190, l191, l192, l193, l194, l195, l196 = sch.get_loops(block=b182)
sch.annotate(block_or_loop=l189, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l189, ann_key="pragma_unroll_explicit", ann_val=1)
l197, l198, l199, l200, l201, l202, l203 = sch.get_loops(block=b183)
sch.annotate(block_or_loop=l197, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l197, ann_key="pragma_unroll_explicit", ann_val=1)
l204, l205, l206, l207, l208, l209, l210 = sch.get_loops(block=b184)
sch.annotate(block_or_loop=l204, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l204, ann_key="pragma_unroll_explicit", ann_val=1)
l211, l212, l213, l214, l215, l216, l217 = sch.get_loops(block=b185)
sch.annotate(block_or_loop=l211, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l211, ann_key="pragma_unroll_explicit", ann_val=1)
l218, l219, l220, l221, l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b186)
sch.annotate(block_or_loop=l218, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l218, ann_key="pragma_unroll_explicit", ann_val=1)
l228, l229, l230, l231, l232, l233 = sch.get_loops(block=b187)
sch.annotate(block_or_loop=l228, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l228, ann_key="pragma_unroll_explicit", ann_val=1)
l234, l235, l236, l237, l238, l239, l240 = sch.get_loops(block=b188)
sch.annotate(block_or_loop=l234, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l234, ann_key="pragma_unroll_explicit", ann_val=1)
b241 = sch.get_block(name="B_o", func_name="main")
l242, l243, l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b241)
b252 = sch.decompose_reduction(block=b241, loop=l245)
sch.unannotate(block_or_loop=b252, ann_key="meta_schedule.auto_tensorize")
sch.annotate(block_or_loop=b252, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_fill_16x16x16_f16")
sch.unannotate(block_or_loop=b241, ann_key="meta_schedule.auto_tensorize_init")
sch.unannotate(block_or_loop=b252, ann_key="meta_schedule.auto_tensorize_init")
b253 = sch.get_block(name="B_o_init", func_name="main")
sch.unannotate(block_or_loop=b253, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b253, tensor_intrin="wmma_fill_16x16x16_f16", preserve_unit_iters=True)
b254 = sch.get_block(name="A_reindex_shared.dyn_wmma.matrix_a_o", func_name="main")
sch.unannotate(block_or_loop=b254, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b254, tensor_intrin="wmma_load_16x16x16_f16_a_shared_dyn", preserve_unit_iters=True)
b255 = sch.get_block(name="B_decompress_reindex_shared.dyn_wmma.matrix_b_o", func_name="main")
sch.unannotate(block_or_loop=b255, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b255, tensor_intrin="wmma_load_16x16x16_f16_b_trans_shared_dyn", preserve_unit_iters=True)
b256 = sch.get_block(name="B_o_update", func_name="main")
sch.unannotate(block_or_loop=b256, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b256, tensor_intrin="wmma_sync_16x16x16_f16f16f16_trans", preserve_unit_iters=True)
b257 = sch.get_block(name="C_reindex_shared.dyn_wmma.accumulator_o", func_name="main")
sch.unannotate(block_or_loop=b257, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b257, tensor_intrin="wmma_store_16x16x16_f16_shared_dyn", preserve_unit_iters=True)
2023-05-01 16:27:36 [INFO] [task_scheduler.cc:121] [Task #0: main] Trial #42: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 8192), "int8"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        C_reindex_shared_dyn = T.alloc_buffer((1024, 128, 1, 8, 16, 16), "float16", scope="shared.dyn")
        C_reindex_shared_dyn_wmma_accumulator = T.alloc_buffer((1024, 128, 1, 8, 16, 16), "float16", scope="wmma.accumulator")
        A_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
        B_decompress_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
        A_reindex_shared_dyn_wmma_matrix_a = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_a")
        B_decompress_reindex_shared_dyn_wmma_matrix_b = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_b")
        for ax0_0_0_ax1_0_0_fused in T.thread_binding(32768, thread="blockIdx.y", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ax0_0_1_ax1_0_1_fused in T.thread_binding(2, thread="blockIdx.x"):
                for ax0_0_2_ax1_0_2_fused in T.thread_binding(2, thread="threadIdx.y"):
                    for ax0_0_3_init, ax1_0_3_init, ax0_0_4_init, ax1_0_4_init in T.grid(1, 2, 1, 4):
                        with T.block("B_o_init"):
                            v0_o = T.axis.spatial(1024, ax0_0_3_init + ax0_0_4_init + ax0_0_0_ax1_0_0_fused // 32)
                            v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 32 * 32 + ax0_0_1_ax1_0_1_fused * 16 + ax0_0_2_ax1_0_2_fused * 8 + ax1_0_3_init * 4 + ax1_0_4_init)
                            T.reads()
                            T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 8, 0, v1_o % 8, 0:16, 0:16])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                            C_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 8, 0, v1_o % 8, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.accumulator", offset_factor=16)
                            T.tvm_fill_fragment(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.float32(0))
                    for ax2_0_0 in range(1024):
                        for ax0_ax1_fused_0 in range(4):
                            for ax0_ax1_fused_1 in T.thread_binding(2, thread="threadIdx.y"):
                                for ax0_ax1_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                    with T.block("A_reindex_shared.dyn"):
                                        v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused // 32 * 16 + (ax0_ax1_fused_0 * 64 + ax0_ax1_fused_1 * 32 + ax0_ax1_fused_2) // 16)
                                        v1 = T.axis.spatial(16384, ax2_0_0 * 16 + (ax0_ax1_fused_0 * 64 + ax0_ax1_fused_1 * 32 + ax0_ax1_fused_2) % 16)
                                        T.reads(A[v0, v1])
                                        T.writes(A_reindex_shared_dyn[v0, v1])
                                        T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]]})
                                        A_reindex_shared_dyn[v0, v1] = A[v0, v1]
                        for ax0_ax1_fused_0 in range(64):
                            for ax0_ax1_fused_1 in T.thread_binding(2, thread="threadIdx.y"):
                                for ax0_ax1_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                    with T.block("B_decompress_reindex_shared.dyn"):
                                        v0 = T.axis.spatial(16384, ax2_0_0 * 16 + (ax0_ax1_fused_0 * 64 + ax0_ax1_fused_1 * 32 + ax0_ax1_fused_2) // 256)
                                        v1 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused % 32 * 512 + ax0_0_1_ax1_0_1_fused * 256 + (ax0_ax1_fused_0 * 64 + ax0_ax1_fused_1 * 32 + ax0_ax1_fused_2) % 256)
                                        T.reads(B[v1, v0 // 2:v0 // 2 + 2])
                                        T.writes(B_decompress_reindex_shared_dyn[v0, v1])
                                        T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]]})
                                        B_decompress_reindex_shared_dyn[v0, v1] = T.Select(v0 % 32 * 4 % 8 <= 5, T.Cast("float16", T.bitwise_and(T.shift_right(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8]), v0 % 32 * 4 % 8), 15)), T.Cast("float16", T.bitwise_or(T.Cast("int8", T.bitwise_and(T.shift_right(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8]), v0 % 32 * 4 % 8), T.shift_left(1, 8 - v0 % 32 * 4 % 8) - 1)), T.Cast("int8", T.bitwise_and(T.bitwise_and(T.shift_left(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8 + 1]), 8 - v0 % 32 * 4 % 8), T.shift_left(15, 8 - v0 % 32 * 4 % 8)), 15)))))
                        for ax2_0_1 in range(1):
                            for ax0_0, ax1_0 in T.grid(1, 1):
                                with T.block("A_reindex_shared.dyn_wmma.matrix_a_o"):
                                    v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 32 + ax0_0)
                                    v1_o = T.axis.spatial(1024, ax2_0_0 + ax1_0)
                                    T.reads(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    A_1 = T.match_buffer(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="shared.dyn", offset_factor=16)
                                    C_1 = T.match_buffer(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.matrix_a", offset_factor=16)
                                    T.tvm_load_matrix_sync(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), A_1.data, A_1.elem_offset, A_1.strides[0] * 16, 1), A_1.strides[0], "row_major")
                            for ax0_0, ax1_0 in T.grid(1, 8):
                                with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b_o"):
                                    v0_o = T.axis.spatial(1024, ax2_0_0 + ax0_0)
                                    v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 32 * 32 + ax0_0_1_ax1_0_1_fused * 16 + ax0_0_2_ax1_0_2_fused * 8 + ax1_0)
                                    T.reads(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    A_1 = T.match_buffer(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="shared.dyn", offset_factor=16)
                                    C_1 = T.match_buffer(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.matrix_b", offset_factor=16)
                                    T.tvm_load_matrix_sync(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), A_1.data, A_1.elem_offset, A_1.strides[0] * 16, 1), A_1.strides[0], "row_major")
                            for ax0_0_3, ax1_0_3, ax2_0_2, ax0_0_4, ax1_0_4 in T.grid(1, 2, 1, 1, 4):
                                with T.block("B_o_update"):
                                    v0_o = T.axis.spatial(1024, ax0_0_3 + ax0_0_4 + ax0_0_0_ax1_0_0_fused // 32)
                                    v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 32 * 32 + ax0_0_1_ax1_0_1_fused * 16 + ax0_0_2_ax1_0_2_fused * 8 + ax1_0_3 * 4 + ax1_0_4)
                                    v2_o = T.axis.reduce(1024, ax2_0_1 + ax2_0_2 + ax2_0_0)
                                    T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 8, 0, v1_o % 8, 0:16, 0:16], A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], B_decompress_reindex_shared_dyn_wmma_matrix_b[v2_o * 16:v2_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 8, 0, v1_o % 8, 0:16, 0:16])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                                    A_1 = T.match_buffer(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="wmma.matrix_a", offset_factor=16)
                                    B_1 = T.match_buffer(B_decompress_reindex_shared_dyn_wmma_matrix_b[v2_o * 16:v2_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("B_s0", "B_s1"), scope="wmma.matrix_b", offset_factor=16)
                                    C_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 8, 0, v1_o % 8, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.accumulator", offset_factor=16)
                                    T.tvm_mma_sync(C_1.data, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, A_1.data, A_1.elem_offset // A_1.strides[0] // 16 * (A_1.strides[0] // 16) + A_1.elem_offset % A_1.strides[0] // 16, B_1.data, B_1.elem_offset // B_1.strides[0] // 16 * (B_1.strides[0] // 16) + B_1.elem_offset % B_1.strides[0] // 16, C_1.data, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16)
                for ax2 in range(1):
                    for ax0_ax1_fused in T.thread_binding(2, thread="threadIdx.y"):
                        for ax2_1, ax3 in T.grid(1, 8):
                            with T.block("C_reindex_shared.dyn_wmma.accumulator_o"):
                                v0 = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 32)
                                v1 = T.axis.spatial(128, ax0_0_0_ax1_0_0_fused % 32 * 4 + ax0_0_1_ax1_0_1_fused * 2 + ax0_ax1_fused)
                                v2, v3 = T.axis.remap("SS", [ax2_1, ax3])
                                v4_o = T.axis.spatial(1, 0)
                                v5_o = T.axis.spatial(1, 0)
                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16])
                                T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16])
                                A_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="wmma.accumulator", offset_factor=16)
                                C_1 = T.match_buffer(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="shared.dyn", offset_factor=16)
                                T.tvm_store_matrix_sync(A_1.data, 16, 16, 16, A_1.elem_offset // A_1.strides[0] // 16 * (A_1.strides[0] // 16) + A_1.elem_offset % A_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), C_1.data, C_1.elem_offset, C_1.strides[0] * 16, 2), C_1.strides[0], "row_major")
                    for ax0_ax1_ax3_ax4_ax5_fused_0 in range(32):
                        for ax0_ax1_ax3_ax4_ax5_fused_1 in T.thread_binding(2, thread="threadIdx.y"):
                            for ax0_ax1_ax3_ax4_ax5_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax3_ax4_ax5_fused_3 in T.vectorized(2):
                                    with T.block("C_reindex_shared.dyn"):
                                        v0 = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 32)
                                        v1 = T.axis.spatial(128, ax0_0_0_ax1_0_0_fused % 32 * 4 + ax0_0_1_ax1_0_1_fused * 2 + (ax0_ax1_ax3_ax4_ax5_fused_0 * 128 + ax0_ax1_ax3_ax4_ax5_fused_1 * 64 + ax0_ax1_ax3_ax4_ax5_fused_2 * 2 + ax0_ax1_ax3_ax4_ax5_fused_3) // 2048)
                                        v2 = T.axis.spatial(1, ax2)
                                        v3 = T.axis.spatial(8, (ax0_ax1_ax3_ax4_ax5_fused_0 * 128 + ax0_ax1_ax3_ax4_ax5_fused_1 * 64 + ax0_ax1_ax3_ax4_ax5_fused_2 * 2 + ax0_ax1_ax3_ax4_ax5_fused_3) % 2048 // 256)
                                        v4 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 128 + ax0_ax1_ax3_ax4_ax5_fused_1 * 64 + ax0_ax1_ax3_ax4_ax5_fused_2 * 2 + ax0_ax1_ax3_ax4_ax5_fused_3) % 256 // 16)
                                        v5 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 128 + ax0_ax1_ax3_ax4_ax5_fused_1 * 64 + ax0_ax1_ax3_ax4_ax5_fused_2 * 2 + ax0_ax1_ax3_ax4_ax5_fused_3) % 16)
                                        T.reads(C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5])
                                        T.writes(C[v4 + v0 * 16, v5 + v3 * 16 + v1 * 128])
                                        C[v4 + v0 * 16, v5 + v3 * 16 + v1 * 128] = C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5]
b0 = sch.get_block(name="B_decompress", func_name="main")
b1 = sch.get_block(name="B", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
b3 = sch.reindex(block=b1, buffer=("write", 0))
b4 = sch.reindex(block=b1, buffer=("read", 0))
b5 = sch.reindex(block=b1, buffer=("read", 1))
sch.transform_layout(block=b1, buffer=("read", 0), index_map=lambda vi, vk: (vi, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("read", 1), index_map=lambda vj, vk: (vk, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("write", 0), index_map=lambda vi, vj: (vi, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_block_layout(block=b3, index_map=lambda vi, vj: (vi, vj,))
sch.transform_block_layout(block=b4, index_map=lambda vi, vk: (vi, vk,))
sch.transform_block_layout(block=b5, index_map=lambda vj, vk: (vk, vj,))
sch.transform_block_layout(block=b1, index_map=lambda vi, vj, vk: (vi, vj, vk,))
l6, l7, l8 = sch.get_loops(block=b1)
l9, l10 = sch.split(loop=l8, factors=[None, 16], preserve_unit_iters=True)
l11, l12 = sch.split(loop=l7, factors=[None, 16], preserve_unit_iters=True)
l13, l14 = sch.split(loop=l6, factors=[None, 16], preserve_unit_iters=True)
l15, l16, l17, l18, l19, l20 = sch.get_loops(block=b1)
sch.reorder(l17, l19, l14, l12, l10)
b21 = sch.blockize(loop=l14, preserve_unit_iters=True)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_sync_16x16x16_f16f16f16")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize_init", ann_val="wmma_fill_16x16x16_f16")
sch.annotate(block_or_loop=b21, ann_key="warp_execution", ann_val=1)
l22, l23, l24 = sch.get_loops(block=b21)
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l22, n=5, max_innermost_factor=4, decision=[1024, 1, 1, 1, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l22, factors=[v25, v26, v27, v28, v29], preserve_unit_iters=True)
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l23, n=5, max_innermost_factor=4, decision=[32, 2, 2, 2, 4])
l40, l41, l42, l43, l44 = sch.split(loop=l23, factors=[v35, v36, v37, v38, v39], preserve_unit_iters=True)
v45, v46, v47 = sch.sample_perfect_tile(loop=l24, n=3, max_innermost_factor=4, decision=[1024, 1, 1])
l48, l49, l50 = sch.split(loop=l24, factors=[v45, v46, v47], preserve_unit_iters=True)
sch.reorder(l30, l40, l31, l41, l32, l42, l48, l49, l33, l43, l50, l34, l44)
l51 = sch.fuse(l30, l40, preserve_unit_iters=True)
sch.bind(loop=l51, thread_axis="blockIdx.y")
l52 = sch.fuse(l31, l41, preserve_unit_iters=True)
sch.bind(loop=l52, thread_axis="blockIdx.x")
l53 = sch.fuse(l32, l42, preserve_unit_iters=True)
sch.bind(loop=l53, thread_axis="threadIdx.y")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
sch.transform_layout(block=b21, buffer=("write", 0), index_map=lambda i0, i1: (i0 // 16 // (v28 * v29), i1 // 16 // (v38 * v39), i0 // 16 % (v28 * v29), i1 // 16 % (v38 * v39), i0 % 16, i1 % 16,), pad_value=None, assume_injective_transform=True)
b54 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="shared.dyn")
sch.reverse_compute_at(block=b54, loop=l52, preserve_unit_loops=True, index=-1)
b55 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="wmma.accumulator")
l56, l57, l58, l59, l60, l61, l62, l63 = sch.get_loops(block=b54)
sch.reorder(l60, l58, l59, l61)
sch.compute_at(block=b55, loop=l60, preserve_unit_loops=True, index=-1)
l64, l65, l66, l67, l68, l69, l70, l71, l72 = sch.get_loops(block=b55)
l73 = sch.fuse(l67, l68, preserve_unit_iters=True)
sch.bind(loop=l73, thread_axis="threadIdx.y")
sch.reverse_compute_inline(block=b3)
l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b55)
b82 = sch.blockize(loop=l80, preserve_unit_iters=True)
sch.annotate(block_or_loop=b82, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_store_16x16x16_f16_shared_dyn")
l83, l84, l85, l86, l87, l88, l89, l90 = sch.get_loops(block=b54)
l91 = sch.fuse(l86, l87, l88, l89, l90, preserve_unit_iters=True)
v92 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch", ann_val=v92)
b93 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b93, loop=l48, preserve_unit_loops=True, index=-1)
l94, l95, l96, l97, l98, l99 = sch.get_loops(block=b93)
l100 = sch.fuse(l98, l99, preserve_unit_iters=True)
v101 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch", ann_val=v101)
b102 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b102, loop=l48, preserve_unit_loops=True, index=-1)
l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b102)
l109 = sch.fuse(l107, l108, preserve_unit_iters=True)
v110 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch", ann_val=v110)
b111 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="wmma.matrix_a")
sch.compute_at(block=b111, loop=l49, preserve_unit_loops=True, index=-1)
l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b111)
l119, l120 = sch.split(loop=l118, factors=[None, 16], preserve_unit_iters=True)
l121, l122 = sch.split(loop=l117, factors=[None, 16], preserve_unit_iters=True)
l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b111)
sch.reorder(l130, l122, l120)
b132 = sch.blockize(loop=l122, preserve_unit_iters=True)
sch.annotate(block_or_loop=b132, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_a_shared_dyn")
b133 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="wmma.matrix_b")
sch.compute_at(block=b133, loop=l49, preserve_unit_loops=True, index=-1)
l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b133)
l141, l142 = sch.split(loop=l140, factors=[None, 16], preserve_unit_iters=True)
l143, l144 = sch.split(loop=l139, factors=[None, 16], preserve_unit_iters=True)
l145, l146, l147, l148, l149, l150, l151, l152, l153 = sch.get_loops(block=b133)
sch.reorder(l152, l144, l142)
b154 = sch.blockize(loop=l144, preserve_unit_iters=True)
sch.annotate(block_or_loop=b154, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_b_shared_dyn")
sch.compute_inline(block=b4)
sch.compute_inline(block=b5)
sch.storage_align(block=b93, buffer_index=0, axis=-2, factor=32, offset=8)
sch.storage_align(block=b102, buffer_index=0, axis=-2, factor=32, offset=8)
sch.compute_inline(block=b0)
v155 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v155)
sch.enter_postproc()
sch.unannotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch")
l156, l157, l158, l159 = sch.get_loops(block=b54)
l160, l161, l162, l163 = sch.split(loop=l159, factors=[None, 2, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l163)
sch.bind(loop=l162, thread_axis="threadIdx.x")
sch.bind(loop=l161, thread_axis="threadIdx.y")
sch.unannotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch")
l164, l165, l166, l167, l168 = sch.get_loops(block=b93)
l169, l170, l171 = sch.split(loop=l168, factors=[None, 2, 32], preserve_unit_iters=True)
sch.bind(loop=l171, thread_axis="threadIdx.x")
sch.bind(loop=l170, thread_axis="threadIdx.y")
sch.unannotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch")
l172, l173, l174, l175, l176 = sch.get_loops(block=b102)
l177, l178, l179 = sch.split(loop=l176, factors=[None, 2, 32], preserve_unit_iters=True)
sch.bind(loop=l179, thread_axis="threadIdx.x")
sch.bind(loop=l178, thread_axis="threadIdx.y")
b180 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b180, ann_key="meta_schedule.unroll_explicit")
b181, b182, b183, b184, b185, b186, b187 = sch.get_child_blocks(b180)
l188, l189, l190, l191, l192, l193, l194 = sch.get_loops(block=b181)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b182)
sch.annotate(block_or_loop=l195, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l195, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b183)
sch.annotate(block_or_loop=l202, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l202, ann_key="pragma_unroll_explicit", ann_val=1)
l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b184)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l216, l217, l218, l219, l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b185)
sch.annotate(block_or_loop=l216, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l216, ann_key="pragma_unroll_explicit", ann_val=1)
l226, l227, l228, l229, l230, l231 = sch.get_loops(block=b186)
sch.annotate(block_or_loop=l226, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l226, ann_key="pragma_unroll_explicit", ann_val=1)
l232, l233, l234, l235, l236, l237, l238 = sch.get_loops(block=b187)
sch.annotate(block_or_loop=l232, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l232, ann_key="pragma_unroll_explicit", ann_val=1)
b239 = sch.get_block(name="B_o", func_name="main")
l240, l241, l242, l243, l244, l245, l246, l247, l248, l249 = sch.get_loops(block=b239)
b250 = sch.decompose_reduction(block=b239, loop=l243)
sch.unannotate(block_or_loop=b250, ann_key="meta_schedule.auto_tensorize")
sch.annotate(block_or_loop=b250, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_fill_16x16x16_f16")
sch.unannotate(block_or_loop=b239, ann_key="meta_schedule.auto_tensorize_init")
sch.unannotate(block_or_loop=b250, ann_key="meta_schedule.auto_tensorize_init")
b251 = sch.get_block(name="B_o_init", func_name="main")
sch.unannotate(block_or_loop=b251, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b251, tensor_intrin="wmma_fill_16x16x16_f16", preserve_unit_iters=True)
b252 = sch.get_block(name="A_reindex_shared.dyn_wmma.matrix_a_o", func_name="main")
sch.unannotate(block_or_loop=b252, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b252, tensor_intrin="wmma_load_16x16x16_f16_a_shared_dyn", preserve_unit_iters=True)
b253 = sch.get_block(name="B_decompress_reindex_shared.dyn_wmma.matrix_b_o", func_name="main")
sch.unannotate(block_or_loop=b253, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b253, tensor_intrin="wmma_load_16x16x16_f16_b_shared_dyn", preserve_unit_iters=True)
b254 = sch.get_block(name="B_o_update", func_name="main")
sch.unannotate(block_or_loop=b254, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b254, tensor_intrin="wmma_sync_16x16x16_f16f16f16", preserve_unit_iters=True)
b255 = sch.get_block(name="C_reindex_shared.dyn_wmma.accumulator_o", func_name="main")
sch.unannotate(block_or_loop=b255, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b255, tensor_intrin="wmma_store_16x16x16_f16_shared_dyn", preserve_unit_iters=True)
2023-05-01 16:27:36 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #43: GFLOPs: 7926.9181. Time: 1110190.3480 us. Best GFLOPs: 70769.6862
2023-05-01 16:27:36 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #44: GFLOPs: 19954.0481. Time: 441032.7147 us. Best GFLOPs: 70769.6862
2023-05-01 16:27:36 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #45: GFLOPs: 16399.5714. Time: 536623.0467 us. Best GFLOPs: 70769.6862
2023-05-01 16:27:36 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #46: GFLOPs: 14935.9902. Time: 589206.8683 us. Best GFLOPs: 70769.6862
2023-05-01 16:27:36 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #47: GFLOPs: 31391.8605. Time: 280339.8030 us. Best GFLOPs: 70769.6862
2023-05-01 16:27:36 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #48: GFLOPs: 49216.4595. Time: 178809.8550 us. Best GFLOPs: 70769.6862
2023-05-01 16:27:36 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 16:27:37 [INFO] [evolutionary_search.cc:715] Picked top 43 candidate(s) from database
2023-05-01 16:27:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 453 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:27:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 910 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:27:49 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1367 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:27:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1826 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:27:53 [INFO] [evolutionary_search.cc:723] Sampled 50 candidate(s)
2023-05-01 16:27:59 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 72 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:28:05 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 81 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:28:12 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 106 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:28:18 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 98 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:28:18 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9994  0.9994  0.9990  0.9987  0.9985  0.9984  0.9983  0.9977  0.9976  0.9974  0.9927  0.9916  0.9912  0.9911  0.9907  0.9889
2023-05-01 16:28:18 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 16:28:18 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 16:35:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #49: GFLOPs: 33503.7298. Time: 262668.9043 us. Best GFLOPs: 70769.6862
2023-05-01 16:35:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #50: GFLOPs: 35409.1398. Time: 248534.3627 us. Best GFLOPs: 70769.6862
2023-05-01 16:35:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #51: GFLOPs: 16649.8677. Time: 528556.0300 us. Best GFLOPs: 70769.6862
2023-05-01 16:35:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #52: GFLOPs: 23776.0678. Time: 370136.3930 us. Best GFLOPs: 70769.6862
2023-05-01 16:35:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #53: GFLOPs: 27962.1171. Time: 314725.3823 us. Best GFLOPs: 70769.6862
2023-05-01 16:35:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #54: GFLOPs: 49349.6647. Time: 178327.2093 us. Best GFLOPs: 70769.6862
2023-05-01 16:35:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #55: GFLOPs: 7882.2077. Time: 1116487.7113 us. Best GFLOPs: 70769.6862
2023-05-01 16:35:27 [INFO] [task_scheduler.cc:121] [Task #0: main] Trial #56: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 8192), "int8"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        C_reindex_shared_dyn = T.alloc_buffer((256, 32, 4, 32, 16, 16), "float16", scope="shared.dyn")
        C_reindex_shared_dyn_wmma_accumulator = T.alloc_buffer((256, 32, 4, 32, 16, 16), "float16", scope="wmma.accumulator")
        A_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
        B_decompress_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
        A_reindex_shared_dyn_wmma_matrix_a = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_a")
        B_decompress_reindex_shared_dyn_wmma_matrix_b = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_b")
        for ax0_0_0_ax1_0_0_fused in T.thread_binding(4, thread="blockIdx.y", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ax0_0_1_ax1_0_1_fused in T.thread_binding(2048, thread="blockIdx.x"):
                for ax0_0_2_ax1_0_2_fused in T.thread_binding(1, thread="threadIdx.y"):
                    for ax0_0_3_init, ax1_0_3_init, ax0_0_4_init, ax1_0_4_init in T.grid(1, 32, 4, 1):
                        with T.block("B_o_init"):
                            v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 2 * 512 + ax0_0_1_ax1_0_1_fused // 16 * 4 + ax0_0_3_init * 4 + ax0_0_4_init)
                            v1_o = T.axis.spatial(1024, ax1_0_4_init + ax0_0_0_ax1_0_0_fused % 2 * 512 + ax0_0_1_ax1_0_1_fused % 16 * 32 + ax1_0_3_init)
                            T.reads()
                            T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 4, v1_o // 32, v0_o % 4, v1_o % 32, 0:16, 0:16])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                            C_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0_o // 4, v1_o // 32, v0_o % 4, v1_o % 32, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.accumulator", offset_factor=16)
                            T.tvm_fill_fragment(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.float32(0))
                    for ax2_0_0 in range(1024):
                        for ax0_ax1_fused_0 in range(8):
                            for ax0_ax1_fused_1 in T.thread_binding(1, thread="threadIdx.y"):
                                for ax0_ax1_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                    for ax0_ax1_fused_3 in T.vectorized(4):
                                        with T.block("A_reindex_shared.dyn"):
                                            v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused // 2 * 8192 + ax0_0_1_ax1_0_1_fused // 16 * 64 + (ax0_ax1_fused_0 * 128 + ax0_ax1_fused_1 * 128 + ax0_ax1_fused_2 * 4 + ax0_ax1_fused_3) // 16)
                                            v1 = T.axis.spatial(16384, ax2_0_0 * 16 + (ax0_ax1_fused_0 * 128 + ax0_ax1_fused_1 * 128 + ax0_ax1_fused_2 * 4 + ax0_ax1_fused_3) % 16)
                                            T.reads(A[v0, v1])
                                            T.writes(A_reindex_shared_dyn[v0, v1])
                                            T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]]})
                                            A_reindex_shared_dyn[v0, v1] = A[v0, v1]
                        for ax0_ax1_fused_0 in range(64):
                            for ax0_ax1_fused_1 in T.thread_binding(1, thread="threadIdx.y"):
                                for ax0_ax1_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                    for ax0_ax1_fused_3 in T.vectorized(4):
                                        with T.block("B_decompress_reindex_shared.dyn"):
                                            v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused % 2 * 8192 + ax0_0_1_ax1_0_1_fused % 16 * 512 + (ax0_ax1_fused_0 * 128 + ax0_ax1_fused_1 * 128 + ax0_ax1_fused_2 * 4 + ax0_ax1_fused_3) // 16)
                                            v1 = T.axis.spatial(16384, ax2_0_0 * 16 + (ax0_ax1_fused_0 * 128 + ax0_ax1_fused_1 * 128 + ax0_ax1_fused_2 * 4 + ax0_ax1_fused_3) % 16)
                                            T.reads(B[v0, v1 // 2:v1 // 2 + 2])
                                            T.writes(B_decompress_reindex_shared_dyn[v0, v1])
                                            T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]]})
                                            B_decompress_reindex_shared_dyn[v0, v1] = T.Select(v1 % 32 * 4 % 8 <= 5, T.Cast("float16", T.bitwise_and(T.shift_right(T.Cast("int32", B[v0, v1 // 32 * 16 + v1 % 32 * 4 // 8]), v1 % 32 * 4 % 8), 15)), T.Cast("float16", T.bitwise_or(T.Cast("int8", T.bitwise_and(T.shift_right(T.Cast("int32", B[v0, v1 // 32 * 16 + v1 % 32 * 4 // 8]), v1 % 32 * 4 % 8), T.shift_left(1, 8 - v1 % 32 * 4 % 8) - 1)), T.Cast("int8", T.bitwise_and(T.bitwise_and(T.shift_left(T.Cast("int32", B[v0, v1 // 32 * 16 + v1 % 32 * 4 // 8 + 1]), 8 - v1 % 32 * 4 % 8), T.shift_left(15, 8 - v1 % 32 * 4 % 8)), 15)))))
                        for ax2_0_1 in range(1):
                            for ax0_0, ax1_0 in T.grid(4, 1):
                                with T.block("A_reindex_shared.dyn_wmma.matrix_a_o"):
                                    v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 2 * 512 + ax0_0_1_ax1_0_1_fused // 16 * 4 + ax0_0)
                                    v1_o = T.axis.spatial(1024, ax2_0_0 + ax1_0)
                                    T.reads(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    A_1 = T.match_buffer(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="shared.dyn", offset_factor=16)
                                    C_1 = T.match_buffer(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.matrix_a", offset_factor=16)
                                    T.tvm_load_matrix_sync(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), A_1.data, A_1.elem_offset, A_1.strides[0] * 16, 1), A_1.strides[0], "row_major")
                            for ax0_0, ax1_0 in T.grid(32, 1):
                                with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b_o"):
                                    v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 2 * 512 + ax0_0_1_ax1_0_1_fused % 16 * 32 + ax0_0)
                                    v1_o = T.axis.spatial(1024, ax2_0_0 + ax1_0)
                                    T.reads(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    A_1 = T.match_buffer(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="shared.dyn", offset_factor=16)
                                    C_1 = T.match_buffer(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.matrix_b", offset_factor=16)
                                    T.tvm_load_matrix_sync(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), A_1.data, A_1.elem_offset, A_1.strides[0] * 16, 1), A_1.strides[0], "col_major")
                            for ax0_0_3, ax1_0_3, ax2_0_2, ax0_0_4, ax1_0_4 in T.grid(1, 32, 1, 4, 1):
                                with T.block("B_o_update"):
                                    v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 2 * 512 + ax0_0_1_ax1_0_1_fused // 16 * 4 + ax0_0_3 * 4 + ax0_0_4)
                                    v1_o = T.axis.spatial(1024, ax1_0_4 + ax0_0_0_ax1_0_0_fused % 2 * 512 + ax0_0_1_ax1_0_1_fused % 16 * 32 + ax1_0_3)
                                    v2_o = T.axis.reduce(1024, ax2_0_1 + ax2_0_2 + ax2_0_0)
                                    T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o // 4, v1_o // 32, v0_o % 4, v1_o % 32, 0:16, 0:16], A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], B_decompress_reindex_shared_dyn_wmma_matrix_b[v1_o * 16:v1_o * 16 + 16, v2_o * 16:v2_o * 16 + 16])
                                    T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 4, v1_o // 32, v0_o % 4, v1_o % 32, 0:16, 0:16])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                                    A_1 = T.match_buffer(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="wmma.matrix_a", offset_factor=16)
                                    B_1 = T.match_buffer(B_decompress_reindex_shared_dyn_wmma_matrix_b[v1_o * 16:v1_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], (16, 16), "float16", strides=("B_s0", "B_s1"), scope="wmma.matrix_b", offset_factor=16)
                                    C_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0_o // 4, v1_o // 32, v0_o % 4, v1_o % 32, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.accumulator", offset_factor=16)
                                    T.tvm_mma_sync(C_1.data, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, A_1.data, A_1.elem_offset // A_1.strides[0] // 16 * (A_1.strides[0] // 16) + A_1.elem_offset % A_1.strides[0] // 16, B_1.data, B_1.elem_offset // B_1.strides[0] // 16 * (B_1.strides[0] // 16) + B_1.elem_offset % B_1.strides[0] // 16, C_1.data, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16)
                for ax2 in range(4):
                    for ax0_ax1_fused in T.thread_binding(1, thread="threadIdx.y"):
                        for ax2_1, ax3 in T.grid(1, 32):
                            with T.block("C_reindex_shared.dyn_wmma.accumulator_o"):
                                v0 = T.axis.spatial(256, ax0_0_0_ax1_0_0_fused // 2 * 128 + ax0_0_1_ax1_0_1_fused // 16)
                                v1 = T.axis.spatial(32, ax0_0_0_ax1_0_0_fused % 2 * 16 + ax0_0_1_ax1_0_1_fused % 16)
                                v2 = T.axis.spatial(4, ax2 + ax2_1)
                                v3 = T.axis.spatial(32, ax3)
                                v4_o = T.axis.spatial(1, 0)
                                v5_o = T.axis.spatial(1, 0)
                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16])
                                T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16])
                                A_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="wmma.accumulator", offset_factor=16)
                                C_1 = T.match_buffer(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="shared.dyn", offset_factor=16)
                                T.tvm_store_matrix_sync(A_1.data, 16, 16, 16, A_1.elem_offset // A_1.strides[0] // 16 * (A_1.strides[0] // 16) + A_1.elem_offset % A_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), C_1.data, C_1.elem_offset, C_1.strides[0] * 16, 2), C_1.strides[0], "row_major")
                    for ax0_ax1_ax3_ax4_ax5_fused_0 in range(64):
                        for ax0_ax1_ax3_ax4_ax5_fused_1 in T.thread_binding(1, thread="threadIdx.y"):
                            for ax0_ax1_ax3_ax4_ax5_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax3_ax4_ax5_fused_3 in T.vectorized(4):
                                    with T.block("C_reindex_shared.dyn"):
                                        v0 = T.axis.spatial(256, ax0_0_0_ax1_0_0_fused // 2 * 128 + ax0_0_1_ax1_0_1_fused // 16)
                                        v1 = T.axis.spatial(32, ax0_0_0_ax1_0_0_fused % 2 * 16 + ax0_0_1_ax1_0_1_fused % 16)
                                        v2 = T.axis.spatial(4, ax2)
                                        v3 = T.axis.spatial(32, (ax0_ax1_ax3_ax4_ax5_fused_0 * 128 + ax0_ax1_ax3_ax4_ax5_fused_1 * 128 + ax0_ax1_ax3_ax4_ax5_fused_2 * 4 + ax0_ax1_ax3_ax4_ax5_fused_3) // 256)
                                        v4 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 128 + ax0_ax1_ax3_ax4_ax5_fused_1 * 128 + ax0_ax1_ax3_ax4_ax5_fused_2 * 4 + ax0_ax1_ax3_ax4_ax5_fused_3) % 256 // 16)
                                        v5 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 128 + ax0_ax1_ax3_ax4_ax5_fused_1 * 128 + ax0_ax1_ax3_ax4_ax5_fused_2 * 4 + ax0_ax1_ax3_ax4_ax5_fused_3) % 16)
                                        T.reads(C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5])
                                        T.writes(C[v4 + v2 * 16 + v0 * 64, v5 + v3 * 16 + v1 * 512])
                                        C[v4 + v2 * 16 + v0 * 64, v5 + v3 * 16 + v1 * 512] = C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5]
b0 = sch.get_block(name="B_decompress", func_name="main")
b1 = sch.get_block(name="B", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
b3 = sch.reindex(block=b1, buffer=("write", 0))
b4 = sch.reindex(block=b1, buffer=("read", 0))
b5 = sch.reindex(block=b1, buffer=("read", 1))
sch.transform_layout(block=b1, buffer=("read", 0), index_map=lambda vi, vk: (vi, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("read", 1), index_map=lambda vj, vk: (vj, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("write", 0), index_map=lambda vi, vj: (vi, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_block_layout(block=b3, index_map=lambda vi, vj: (vi, vj,))
sch.transform_block_layout(block=b4, index_map=lambda vi, vk: (vi, vk,))
sch.transform_block_layout(block=b5, index_map=lambda vj, vk: (vj, vk,))
sch.transform_block_layout(block=b1, index_map=lambda vi, vj, vk: (vi, vj, vk,))
l6, l7, l8 = sch.get_loops(block=b1)
l9, l10 = sch.split(loop=l8, factors=[None, 16], preserve_unit_iters=True)
l11, l12 = sch.split(loop=l7, factors=[None, 16], preserve_unit_iters=True)
l13, l14 = sch.split(loop=l6, factors=[None, 16], preserve_unit_iters=True)
l15, l16, l17, l18, l19, l20 = sch.get_loops(block=b1)
sch.reorder(l17, l19, l14, l12, l10)
b21 = sch.blockize(loop=l14, preserve_unit_iters=True)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_sync_16x16x16_f16f16f16_trans")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize_init", ann_val="wmma_fill_16x16x16_f16")
sch.annotate(block_or_loop=b21, ann_key="warp_execution", ann_val=1)
l22, l23, l24 = sch.get_loops(block=b21)
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l22, n=5, max_innermost_factor=4, decision=[2, 128, 1, 1, 4])
l30, l31, l32, l33, l34 = sch.split(loop=l22, factors=[v25, v26, v27, v28, v29], preserve_unit_iters=True)
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l23, n=5, max_innermost_factor=4, decision=[2, 16, 1, 32, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l23, factors=[v35, v36, v37, v38, v39], preserve_unit_iters=True)
v45, v46, v47 = sch.sample_perfect_tile(loop=l24, n=3, max_innermost_factor=4, decision=[1024, 1, 1])
l48, l49, l50 = sch.split(loop=l24, factors=[v45, v46, v47], preserve_unit_iters=True)
sch.reorder(l30, l40, l31, l41, l32, l42, l48, l49, l33, l43, l50, l34, l44)
l51 = sch.fuse(l30, l40, preserve_unit_iters=True)
sch.bind(loop=l51, thread_axis="blockIdx.y")
l52 = sch.fuse(l31, l41, preserve_unit_iters=True)
sch.bind(loop=l52, thread_axis="blockIdx.x")
l53 = sch.fuse(l32, l42, preserve_unit_iters=True)
sch.bind(loop=l53, thread_axis="threadIdx.y")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
sch.transform_layout(block=b21, buffer=("write", 0), index_map=lambda i0, i1: (i0 // 16 // (v28 * v29), i1 // 16 // (v38 * v39), i0 // 16 % (v28 * v29), i1 // 16 % (v38 * v39), i0 % 16, i1 % 16,), pad_value=None, assume_injective_transform=True)
b54 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="shared.dyn")
sch.reverse_compute_at(block=b54, loop=l52, preserve_unit_loops=True, index=-1)
b55 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="wmma.accumulator")
l56, l57, l58, l59, l60, l61, l62, l63 = sch.get_loops(block=b54)
sch.reorder(l60, l58, l59, l61)
sch.compute_at(block=b55, loop=l60, preserve_unit_loops=True, index=-1)
l64, l65, l66, l67, l68, l69, l70, l71, l72 = sch.get_loops(block=b55)
l73 = sch.fuse(l67, l68, preserve_unit_iters=True)
sch.bind(loop=l73, thread_axis="threadIdx.y")
sch.reverse_compute_inline(block=b3)
l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b55)
b82 = sch.blockize(loop=l80, preserve_unit_iters=True)
sch.annotate(block_or_loop=b82, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_store_16x16x16_f16_shared_dyn")
l83, l84, l85, l86, l87, l88, l89, l90 = sch.get_loops(block=b54)
l91 = sch.fuse(l86, l87, l88, l89, l90, preserve_unit_iters=True)
v92 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch", ann_val=v92)
b93 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b93, loop=l48, preserve_unit_loops=True, index=-1)
l94, l95, l96, l97, l98, l99 = sch.get_loops(block=b93)
l100 = sch.fuse(l98, l99, preserve_unit_iters=True)
v101 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch", ann_val=v101)
b102 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b102, loop=l48, preserve_unit_loops=True, index=-1)
l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b102)
l109 = sch.fuse(l107, l108, preserve_unit_iters=True)
v110 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch", ann_val=v110)
b111 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="wmma.matrix_a")
sch.compute_at(block=b111, loop=l49, preserve_unit_loops=True, index=-1)
l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b111)
l119, l120 = sch.split(loop=l118, factors=[None, 16], preserve_unit_iters=True)
l121, l122 = sch.split(loop=l117, factors=[None, 16], preserve_unit_iters=True)
l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b111)
sch.reorder(l130, l122, l120)
b132 = sch.blockize(loop=l122, preserve_unit_iters=True)
sch.annotate(block_or_loop=b132, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_a_shared_dyn")
b133 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="wmma.matrix_b")
sch.compute_at(block=b133, loop=l49, preserve_unit_loops=True, index=-1)
l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b133)
l141, l142 = sch.split(loop=l140, factors=[None, 16], preserve_unit_iters=True)
l143, l144 = sch.split(loop=l139, factors=[None, 16], preserve_unit_iters=True)
l145, l146, l147, l148, l149, l150, l151, l152, l153 = sch.get_loops(block=b133)
sch.reorder(l152, l144, l142)
b154 = sch.blockize(loop=l144, preserve_unit_iters=True)
sch.annotate(block_or_loop=b154, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_b_trans_shared_dyn")
sch.compute_inline(block=b4)
sch.compute_inline(block=b5)
sch.storage_align(block=b93, buffer_index=0, axis=-2, factor=32, offset=8)
sch.storage_align(block=b102, buffer_index=0, axis=-2, factor=32, offset=8)
sch.compute_inline(block=b0)
v155 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v155)
sch.enter_postproc()
sch.unannotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch")
l156, l157, l158, l159 = sch.get_loops(block=b54)
l160, l161, l162, l163 = sch.split(loop=l159, factors=[None, 1, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l163)
sch.bind(loop=l162, thread_axis="threadIdx.x")
sch.bind(loop=l161, thread_axis="threadIdx.y")
sch.unannotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch")
l164, l165, l166, l167, l168 = sch.get_loops(block=b93)
l169, l170, l171, l172 = sch.split(loop=l168, factors=[None, 1, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l172)
sch.bind(loop=l171, thread_axis="threadIdx.x")
sch.bind(loop=l170, thread_axis="threadIdx.y")
sch.unannotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch")
l173, l174, l175, l176, l177 = sch.get_loops(block=b102)
l178, l179, l180, l181 = sch.split(loop=l177, factors=[None, 1, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l181)
sch.bind(loop=l180, thread_axis="threadIdx.x")
sch.bind(loop=l179, thread_axis="threadIdx.y")
b182 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b182, ann_key="meta_schedule.unroll_explicit")
b183, b184, b185, b186, b187, b188, b189 = sch.get_child_blocks(b182)
l190, l191, l192, l193, l194, l195, l196, l197 = sch.get_loops(block=b183)
sch.annotate(block_or_loop=l190, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l190, ann_key="pragma_unroll_explicit", ann_val=1)
l198, l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b184)
sch.annotate(block_or_loop=l198, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l198, ann_key="pragma_unroll_explicit", ann_val=1)
l206, l207, l208, l209, l210, l211, l212 = sch.get_loops(block=b185)
sch.annotate(block_or_loop=l206, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l206, ann_key="pragma_unroll_explicit", ann_val=1)
l213, l214, l215, l216, l217, l218, l219 = sch.get_loops(block=b186)
sch.annotate(block_or_loop=l213, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l213, ann_key="pragma_unroll_explicit", ann_val=1)
l220, l221, l222, l223, l224, l225, l226, l227, l228, l229 = sch.get_loops(block=b187)
sch.annotate(block_or_loop=l220, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l220, ann_key="pragma_unroll_explicit", ann_val=1)
l230, l231, l232, l233, l234, l235 = sch.get_loops(block=b188)
sch.annotate(block_or_loop=l230, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l230, ann_key="pragma_unroll_explicit", ann_val=1)
l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b189)
sch.annotate(block_or_loop=l236, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l236, ann_key="pragma_unroll_explicit", ann_val=1)
b243 = sch.get_block(name="B_o", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b243)
b254 = sch.decompose_reduction(block=b243, loop=l247)
sch.unannotate(block_or_loop=b254, ann_key="meta_schedule.auto_tensorize")
sch.annotate(block_or_loop=b254, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_fill_16x16x16_f16")
sch.unannotate(block_or_loop=b243, ann_key="meta_schedule.auto_tensorize_init")
sch.unannotate(block_or_loop=b254, ann_key="meta_schedule.auto_tensorize_init")
b255 = sch.get_block(name="B_o_init", func_name="main")
sch.unannotate(block_or_loop=b255, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b255, tensor_intrin="wmma_fill_16x16x16_f16", preserve_unit_iters=True)
b256 = sch.get_block(name="A_reindex_shared.dyn_wmma.matrix_a_o", func_name="main")
sch.unannotate(block_or_loop=b256, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b256, tensor_intrin="wmma_load_16x16x16_f16_a_shared_dyn", preserve_unit_iters=True)
b257 = sch.get_block(name="B_decompress_reindex_shared.dyn_wmma.matrix_b_o", func_name="main")
sch.unannotate(block_or_loop=b257, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b257, tensor_intrin="wmma_load_16x16x16_f16_b_trans_shared_dyn", preserve_unit_iters=True)
b258 = sch.get_block(name="B_o_update", func_name="main")
sch.unannotate(block_or_loop=b258, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b258, tensor_intrin="wmma_sync_16x16x16_f16f16f16_trans", preserve_unit_iters=True)
b259 = sch.get_block(name="C_reindex_shared.dyn_wmma.accumulator_o", func_name="main")
sch.unannotate(block_or_loop=b259, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b259, tensor_intrin="wmma_store_16x16x16_f16_shared_dyn", preserve_unit_iters=True)
2023-05-01 16:35:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #57: GFLOPs: 57573.4884. Time: 152854.8683 us. Best GFLOPs: 70769.6862
2023-05-01 16:35:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #58: GFLOPs: 25757.6350. Time: 341661.3360 us. Best GFLOPs: 70769.6862
2023-05-01 16:35:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #59: GFLOPs: 45042.4281. Time: 195379.9640 us. Best GFLOPs: 70769.6862
2023-05-01 16:35:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #60: GFLOPs: 42695.4726. Time: 206119.9340 us. Best GFLOPs: 70769.6862
2023-05-01 16:35:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #61: GFLOPs: 26259.4712. Time: 335131.9580 us. Best GFLOPs: 70769.6862
2023-05-01 16:35:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #62: GFLOPs: 28505.8675. Time: 308721.9847 us. Best GFLOPs: 70769.6862
2023-05-01 16:35:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #63: GFLOPs: 28163.2218. Time: 312478.0273 us. Best GFLOPs: 70769.6862
2023-05-01 16:35:27 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #64: GFLOPs: 89200.0650. Time: 98658.9863 us. Best GFLOPs: 89200.0650
2023-05-01 16:35:27 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 16:35:28 [INFO] [evolutionary_search.cc:715] Picked top 58 candidate(s) from database
2023-05-01 16:35:32 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 438 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:35:36 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 883 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:35:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1323 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:35:44 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1766 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:35:44 [INFO] [evolutionary_search.cc:723] Sampled 50 candidate(s)
2023-05-01 16:35:50 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 92 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:35:56 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 86 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:36:02 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 90 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:36:08 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 85 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:36:09 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9997  0.9992  0.9991  0.9989  0.9985  0.9983  0.9974  0.9972  0.9959  0.9956  0.9948  0.9940  0.9933  0.9917  0.9899  0.9898
2023-05-01 16:36:09 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 16:36:09 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 16:43:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #65: GFLOPs: 49083.6763. Time: 179293.5790 us. Best GFLOPs: 89200.0650
2023-05-01 16:43:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #66: GFLOPs: 41830.1459. Time: 210383.8703 us. Best GFLOPs: 89200.0650
2023-05-01 16:43:23 [INFO] [task_scheduler.cc:121] [Task #0: main] Trial #67: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 8192), "int8"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        C_reindex_shared_dyn = T.alloc_buffer((64, 128, 16, 8, 16, 16), "float16", scope="shared.dyn")
        C_reindex_shared_dyn_wmma_accumulator = T.alloc_buffer((64, 128, 16, 8, 16, 16), "float16", scope="wmma.accumulator")
        A_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
        B_decompress_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
        A_reindex_shared_dyn_wmma_matrix_a = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_a")
        B_decompress_reindex_shared_dyn_wmma_matrix_b = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_b")
        for ax0_0_0_ax1_0_0_fused in T.thread_binding(2048, thread="blockIdx.y", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ax0_0_1_ax1_0_1_fused in T.thread_binding(4, thread="blockIdx.x"):
                for ax0_0_2_ax1_0_2_fused in T.thread_binding(1, thread="threadIdx.y"):
                    for ax0_0_3_init, ax1_0_3_init, ax0_0_4_init, ax1_0_4_init in T.grid(4, 8, 4, 1):
                        with T.block("B_o_init"):
                            v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 32 * 16 + ax0_0_3_init * 4 + ax0_0_4_init)
                            v1_o = T.axis.spatial(1024, ax1_0_4_init + ax0_0_0_ax1_0_0_fused % 32 * 32 + ax0_0_1_ax1_0_1_fused * 8 + ax1_0_3_init)
                            T.reads()
                            T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 16, v1_o // 8, v0_o % 16, v1_o % 8, 0:16, 0:16])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                            C_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0_o // 16, v1_o // 8, v0_o % 16, v1_o % 8, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.accumulator", offset_factor=16)
                            T.tvm_fill_fragment(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.float32(0))
                    for ax2_0_0 in range(512):
                        for ax0_ax1_fused_0 in range(256):
                            for ax0_ax1_fused_1 in T.thread_binding(1, thread="threadIdx.y"):
                                for ax0_ax1_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                    with T.block("A_reindex_shared.dyn"):
                                        v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused // 32 * 256 + (ax0_ax1_fused_0 * 32 + ax0_ax1_fused_1 * 32 + ax0_ax1_fused_2) // 32)
                                        v1 = T.axis.spatial(16384, ax2_0_0 * 32 + (ax0_ax1_fused_0 * 32 + ax0_ax1_fused_1 * 32 + ax0_ax1_fused_2) % 32)
                                        T.reads(A[v0, v1])
                                        T.writes(A_reindex_shared_dyn[v0, v1])
                                        T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]]})
                                        A_reindex_shared_dyn[v0, v1] = A[v0, v1]
                        for ax0_ax1_fused_0 in range(128):
                            for ax0_ax1_fused_1 in T.thread_binding(1, thread="threadIdx.y"):
                                for ax0_ax1_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                    with T.block("B_decompress_reindex_shared.dyn"):
                                        v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused % 32 * 512 + ax0_0_1_ax1_0_1_fused * 128 + (ax0_ax1_fused_0 * 32 + ax0_ax1_fused_1 * 32 + ax0_ax1_fused_2) // 32)
                                        v1 = T.axis.spatial(16384, ax2_0_0 * 32 + (ax0_ax1_fused_0 * 32 + ax0_ax1_fused_1 * 32 + ax0_ax1_fused_2) % 32)
                                        T.reads(B[v0, v1 // 2:v1 // 2 + 2])
                                        T.writes(B_decompress_reindex_shared_dyn[v0, v1])
                                        T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]]})
                                        B_decompress_reindex_shared_dyn[v0, v1] = T.Select(v1 % 32 * 4 % 8 <= 5, T.Cast("float16", T.bitwise_and(T.shift_right(T.Cast("int32", B[v0, v1 // 32 * 16 + v1 % 32 * 4 // 8]), v1 % 32 * 4 % 8), 15)), T.Cast("float16", T.bitwise_or(T.Cast("int8", T.bitwise_and(T.shift_right(T.Cast("int32", B[v0, v1 // 32 * 16 + v1 % 32 * 4 // 8]), v1 % 32 * 4 % 8), T.shift_left(1, 8 - v1 % 32 * 4 % 8) - 1)), T.Cast("int8", T.bitwise_and(T.bitwise_and(T.shift_left(T.Cast("int32", B[v0, v1 // 32 * 16 + v1 % 32 * 4 // 8 + 1]), 8 - v1 % 32 * 4 % 8), T.shift_left(15, 8 - v1 % 32 * 4 % 8)), 15)))))
                        for ax2_0_1 in range(2):
                            for ax0_0, ax1_0 in T.grid(16, 1):
                                with T.block("A_reindex_shared.dyn_wmma.matrix_a_o"):
                                    v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 32 * 16 + ax0_0)
                                    v1_o = T.axis.spatial(1024, ax2_0_0 * 2 + ax2_0_1 + ax1_0)
                                    T.reads(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    A_1 = T.match_buffer(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="shared.dyn", offset_factor=16)
                                    C_1 = T.match_buffer(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.matrix_a", offset_factor=16)
                                    T.tvm_load_matrix_sync(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), A_1.data, A_1.elem_offset, A_1.strides[0] * 16, 1), A_1.strides[0], "row_major")
                            for ax0_0, ax1_0 in T.grid(8, 1):
                                with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b_o"):
                                    v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 32 * 32 + ax0_0_1_ax1_0_1_fused * 8 + ax0_0)
                                    v1_o = T.axis.spatial(1024, ax2_0_0 * 2 + ax2_0_1 + ax1_0)
                                    T.reads(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    A_1 = T.match_buffer(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="shared.dyn", offset_factor=16)
                                    C_1 = T.match_buffer(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.matrix_b", offset_factor=16)
                                    T.tvm_load_matrix_sync(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), A_1.data, A_1.elem_offset, A_1.strides[0] * 16, 1), A_1.strides[0], "col_major")
                            for ax0_0_3, ax1_0_3, ax2_0_2, ax0_0_4, ax1_0_4 in T.grid(4, 8, 1, 4, 1):
                                with T.block("B_o_update"):
                                    v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 32 * 16 + ax0_0_3 * 4 + ax0_0_4)
                                    v1_o = T.axis.spatial(1024, ax1_0_4 + ax0_0_0_ax1_0_0_fused % 32 * 32 + ax0_0_1_ax1_0_1_fused * 8 + ax1_0_3)
                                    v2_o = T.axis.reduce(1024, ax2_0_0 * 2 + ax2_0_1 + ax2_0_2)
                                    T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o // 16, v1_o // 8, v0_o % 16, v1_o % 8, 0:16, 0:16], A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], B_decompress_reindex_shared_dyn_wmma_matrix_b[v1_o * 16:v1_o * 16 + 16, v2_o * 16:v2_o * 16 + 16])
                                    T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 16, v1_o // 8, v0_o % 16, v1_o % 8, 0:16, 0:16])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                                    A_1 = T.match_buffer(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="wmma.matrix_a", offset_factor=16)
                                    B_1 = T.match_buffer(B_decompress_reindex_shared_dyn_wmma_matrix_b[v1_o * 16:v1_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], (16, 16), "float16", strides=("B_s0", "B_s1"), scope="wmma.matrix_b", offset_factor=16)
                                    C_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0_o // 16, v1_o // 8, v0_o % 16, v1_o % 8, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.accumulator", offset_factor=16)
                                    T.tvm_mma_sync(C_1.data, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, A_1.data, A_1.elem_offset // A_1.strides[0] // 16 * (A_1.strides[0] // 16) + A_1.elem_offset % A_1.strides[0] // 16, B_1.data, B_1.elem_offset // B_1.strides[0] // 16 * (B_1.strides[0] // 16) + B_1.elem_offset % B_1.strides[0] // 16, C_1.data, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16)
                for ax2 in range(16):
                    for ax0_ax1_fused in T.thread_binding(1, thread="threadIdx.y"):
                        for ax2_1, ax3 in T.grid(1, 8):
                            with T.block("C_reindex_shared.dyn_wmma.accumulator_o"):
                                v0 = T.axis.spatial(64, ax0_0_0_ax1_0_0_fused // 32)
                                v1 = T.axis.spatial(128, ax0_0_0_ax1_0_0_fused % 32 * 4 + ax0_0_1_ax1_0_1_fused)
                                v2 = T.axis.spatial(16, ax2 + ax2_1)
                                v3 = T.axis.spatial(8, ax3)
                                v4_o = T.axis.spatial(1, 0)
                                v5_o = T.axis.spatial(1, 0)
                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16])
                                T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16])
                                A_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="wmma.accumulator", offset_factor=16)
                                C_1 = T.match_buffer(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="shared.dyn", offset_factor=16)
                                T.tvm_store_matrix_sync(A_1.data, 16, 16, 16, A_1.elem_offset // A_1.strides[0] // 16 * (A_1.strides[0] // 16) + A_1.elem_offset % A_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), C_1.data, C_1.elem_offset, C_1.strides[0] * 16, 2), C_1.strides[0], "row_major")
                    for ax0_ax1_ax3_ax4_ax5_fused_0 in range(64):
                        for ax0_ax1_ax3_ax4_ax5_fused_1 in T.thread_binding(1, thread="threadIdx.y"):
                            for ax0_ax1_ax3_ax4_ax5_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("C_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(64, ax0_0_0_ax1_0_0_fused // 32)
                                    v1 = T.axis.spatial(128, ax0_0_0_ax1_0_0_fused % 32 * 4 + ax0_0_1_ax1_0_1_fused)
                                    v2 = T.axis.spatial(16, ax2)
                                    v3 = T.axis.spatial(8, (ax0_ax1_ax3_ax4_ax5_fused_0 * 32 + ax0_ax1_ax3_ax4_ax5_fused_1 * 32 + ax0_ax1_ax3_ax4_ax5_fused_2) // 256)
                                    v4 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 32 + ax0_ax1_ax3_ax4_ax5_fused_1 * 32 + ax0_ax1_ax3_ax4_ax5_fused_2) % 256 // 16)
                                    v5 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 32 + ax0_ax1_ax3_ax4_ax5_fused_1 * 32 + ax0_ax1_ax3_ax4_ax5_fused_2) % 16)
                                    T.reads(C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5])
                                    T.writes(C[v4 + v2 * 16 + v0 * 256, v5 + v3 * 16 + v1 * 128])
                                    C[v4 + v2 * 16 + v0 * 256, v5 + v3 * 16 + v1 * 128] = C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5]
b0 = sch.get_block(name="B_decompress", func_name="main")
b1 = sch.get_block(name="B", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
b3 = sch.reindex(block=b1, buffer=("write", 0))
b4 = sch.reindex(block=b1, buffer=("read", 0))
b5 = sch.reindex(block=b1, buffer=("read", 1))
sch.transform_layout(block=b1, buffer=("read", 0), index_map=lambda vi, vk: (vi, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("read", 1), index_map=lambda vj, vk: (vj, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("write", 0), index_map=lambda vi, vj: (vi, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_block_layout(block=b3, index_map=lambda vi, vj: (vi, vj,))
sch.transform_block_layout(block=b4, index_map=lambda vi, vk: (vi, vk,))
sch.transform_block_layout(block=b5, index_map=lambda vj, vk: (vj, vk,))
sch.transform_block_layout(block=b1, index_map=lambda vi, vj, vk: (vi, vj, vk,))
l6, l7, l8 = sch.get_loops(block=b1)
l9, l10 = sch.split(loop=l8, factors=[None, 16], preserve_unit_iters=True)
l11, l12 = sch.split(loop=l7, factors=[None, 16], preserve_unit_iters=True)
l13, l14 = sch.split(loop=l6, factors=[None, 16], preserve_unit_iters=True)
l15, l16, l17, l18, l19, l20 = sch.get_loops(block=b1)
sch.reorder(l17, l19, l14, l12, l10)
b21 = sch.blockize(loop=l14, preserve_unit_iters=True)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_sync_16x16x16_f16f16f16_trans")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize_init", ann_val="wmma_fill_16x16x16_f16")
sch.annotate(block_or_loop=b21, ann_key="warp_execution", ann_val=1)
l22, l23, l24 = sch.get_loops(block=b21)
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l22, n=5, max_innermost_factor=4, decision=[64, 1, 1, 4, 4])
l30, l31, l32, l33, l34 = sch.split(loop=l22, factors=[v25, v26, v27, v28, v29], preserve_unit_iters=True)
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l23, n=5, max_innermost_factor=4, decision=[32, 4, 1, 8, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l23, factors=[v35, v36, v37, v38, v39], preserve_unit_iters=True)
v45, v46, v47 = sch.sample_perfect_tile(loop=l24, n=3, max_innermost_factor=4, decision=[512, 2, 1])
l48, l49, l50 = sch.split(loop=l24, factors=[v45, v46, v47], preserve_unit_iters=True)
sch.reorder(l30, l40, l31, l41, l32, l42, l48, l49, l33, l43, l50, l34, l44)
l51 = sch.fuse(l30, l40, preserve_unit_iters=True)
sch.bind(loop=l51, thread_axis="blockIdx.y")
l52 = sch.fuse(l31, l41, preserve_unit_iters=True)
sch.bind(loop=l52, thread_axis="blockIdx.x")
l53 = sch.fuse(l32, l42, preserve_unit_iters=True)
sch.bind(loop=l53, thread_axis="threadIdx.y")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
sch.transform_layout(block=b21, buffer=("write", 0), index_map=lambda i0, i1: (i0 // 16 // (v28 * v29), i1 // 16 // (v38 * v39), i0 // 16 % (v28 * v29), i1 // 16 % (v38 * v39), i0 % 16, i1 % 16,), pad_value=None, assume_injective_transform=True)
b54 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="shared.dyn")
sch.reverse_compute_at(block=b54, loop=l52, preserve_unit_loops=True, index=-1)
b55 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="wmma.accumulator")
l56, l57, l58, l59, l60, l61, l62, l63 = sch.get_loops(block=b54)
sch.reorder(l60, l58, l59, l61)
sch.compute_at(block=b55, loop=l60, preserve_unit_loops=True, index=-1)
l64, l65, l66, l67, l68, l69, l70, l71, l72 = sch.get_loops(block=b55)
l73 = sch.fuse(l67, l68, preserve_unit_iters=True)
sch.bind(loop=l73, thread_axis="threadIdx.y")
sch.reverse_compute_inline(block=b3)
l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b55)
b82 = sch.blockize(loop=l80, preserve_unit_iters=True)
sch.annotate(block_or_loop=b82, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_store_16x16x16_f16_shared_dyn")
l83, l84, l85, l86, l87, l88, l89, l90 = sch.get_loops(block=b54)
l91 = sch.fuse(l86, l87, l88, l89, l90, preserve_unit_iters=True)
v92 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch", ann_val=v92)
b93 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b93, loop=l48, preserve_unit_loops=True, index=-1)
l94, l95, l96, l97, l98, l99 = sch.get_loops(block=b93)
l100 = sch.fuse(l98, l99, preserve_unit_iters=True)
v101 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch", ann_val=v101)
b102 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b102, loop=l48, preserve_unit_loops=True, index=-1)
l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b102)
l109 = sch.fuse(l107, l108, preserve_unit_iters=True)
v110 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch", ann_val=v110)
b111 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="wmma.matrix_a")
sch.compute_at(block=b111, loop=l49, preserve_unit_loops=True, index=-1)
l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b111)
l119, l120 = sch.split(loop=l118, factors=[None, 16], preserve_unit_iters=True)
l121, l122 = sch.split(loop=l117, factors=[None, 16], preserve_unit_iters=True)
l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b111)
sch.reorder(l130, l122, l120)
b132 = sch.blockize(loop=l122, preserve_unit_iters=True)
sch.annotate(block_or_loop=b132, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_a_shared_dyn")
b133 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="wmma.matrix_b")
sch.compute_at(block=b133, loop=l49, preserve_unit_loops=True, index=-1)
l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b133)
l141, l142 = sch.split(loop=l140, factors=[None, 16], preserve_unit_iters=True)
l143, l144 = sch.split(loop=l139, factors=[None, 16], preserve_unit_iters=True)
l145, l146, l147, l148, l149, l150, l151, l152, l153 = sch.get_loops(block=b133)
sch.reorder(l152, l144, l142)
b154 = sch.blockize(loop=l144, preserve_unit_iters=True)
sch.annotate(block_or_loop=b154, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_b_trans_shared_dyn")
sch.compute_inline(block=b4)
sch.compute_inline(block=b5)
sch.storage_align(block=b93, buffer_index=0, axis=-2, factor=32, offset=8)
sch.storage_align(block=b102, buffer_index=0, axis=-2, factor=32, offset=8)
sch.compute_inline(block=b0)
v155 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v155)
sch.enter_postproc()
sch.unannotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch")
l156, l157, l158, l159 = sch.get_loops(block=b54)
l160, l161, l162 = sch.split(loop=l159, factors=[None, 1, 32], preserve_unit_iters=True)
sch.bind(loop=l162, thread_axis="threadIdx.x")
sch.bind(loop=l161, thread_axis="threadIdx.y")
sch.unannotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch")
l163, l164, l165, l166, l167 = sch.get_loops(block=b93)
l168, l169, l170 = sch.split(loop=l167, factors=[None, 1, 32], preserve_unit_iters=True)
sch.bind(loop=l170, thread_axis="threadIdx.x")
sch.bind(loop=l169, thread_axis="threadIdx.y")
sch.unannotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch")
l171, l172, l173, l174, l175 = sch.get_loops(block=b102)
l176, l177, l178 = sch.split(loop=l175, factors=[None, 1, 32], preserve_unit_iters=True)
sch.bind(loop=l178, thread_axis="threadIdx.x")
sch.bind(loop=l177, thread_axis="threadIdx.y")
b179 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b179, ann_key="meta_schedule.unroll_explicit")
b180, b181, b182, b183, b184, b185, b186 = sch.get_child_blocks(b179)
l187, l188, l189, l190, l191, l192, l193 = sch.get_loops(block=b180)
sch.annotate(block_or_loop=l187, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l187, ann_key="pragma_unroll_explicit", ann_val=1)
l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b181)
sch.annotate(block_or_loop=l194, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l194, ann_key="pragma_unroll_explicit", ann_val=1)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b182)
sch.annotate(block_or_loop=l201, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l201, ann_key="pragma_unroll_explicit", ann_val=1)
l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b183)
sch.annotate(block_or_loop=l208, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l208, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218, l219, l220, l221, l222, l223, l224 = sch.get_loops(block=b184)
sch.annotate(block_or_loop=l215, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l215, ann_key="pragma_unroll_explicit", ann_val=1)
l225, l226, l227, l228, l229, l230 = sch.get_loops(block=b185)
sch.annotate(block_or_loop=l225, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l225, ann_key="pragma_unroll_explicit", ann_val=1)
l231, l232, l233, l234, l235, l236 = sch.get_loops(block=b186)
sch.annotate(block_or_loop=l231, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l231, ann_key="pragma_unroll_explicit", ann_val=1)
b237 = sch.get_block(name="B_o", func_name="main")
l238, l239, l240, l241, l242, l243, l244, l245, l246, l247 = sch.get_loops(block=b237)
b248 = sch.decompose_reduction(block=b237, loop=l241)
sch.unannotate(block_or_loop=b248, ann_key="meta_schedule.auto_tensorize")
sch.annotate(block_or_loop=b248, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_fill_16x16x16_f16")
sch.unannotate(block_or_loop=b237, ann_key="meta_schedule.auto_tensorize_init")
sch.unannotate(block_or_loop=b248, ann_key="meta_schedule.auto_tensorize_init")
b249 = sch.get_block(name="B_o_init", func_name="main")
sch.unannotate(block_or_loop=b249, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b249, tensor_intrin="wmma_fill_16x16x16_f16", preserve_unit_iters=True)
b250 = sch.get_block(name="A_reindex_shared.dyn_wmma.matrix_a_o", func_name="main")
sch.unannotate(block_or_loop=b250, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b250, tensor_intrin="wmma_load_16x16x16_f16_a_shared_dyn", preserve_unit_iters=True)
b251 = sch.get_block(name="B_decompress_reindex_shared.dyn_wmma.matrix_b_o", func_name="main")
sch.unannotate(block_or_loop=b251, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b251, tensor_intrin="wmma_load_16x16x16_f16_b_trans_shared_dyn", preserve_unit_iters=True)
b252 = sch.get_block(name="B_o_update", func_name="main")
sch.unannotate(block_or_loop=b252, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b252, tensor_intrin="wmma_sync_16x16x16_f16f16f16_trans", preserve_unit_iters=True)
b253 = sch.get_block(name="C_reindex_shared.dyn_wmma.accumulator_o", func_name="main")
sch.unannotate(block_or_loop=b253, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b253, tensor_intrin="wmma_store_16x16x16_f16_shared_dyn", preserve_unit_iters=True)
2023-05-01 16:43:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #68: GFLOPs: 7745.6984. Time: 1136164.5507 us. Best GFLOPs: 89200.0650
2023-05-01 16:43:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #69: GFLOPs: 13856.0082. Time: 635131.5510 us. Best GFLOPs: 89200.0650
2023-05-01 16:43:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #70: GFLOPs: 48923.6921. Time: 179879.8827 us. Best GFLOPs: 89200.0650
2023-05-01 16:43:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #71: GFLOPs: 28445.0757. Time: 309381.7747 us. Best GFLOPs: 89200.0650
2023-05-01 16:43:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #72: GFLOPs: 45622.3830. Time: 192896.2807 us. Best GFLOPs: 89200.0650
2023-05-01 16:43:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #73: GFLOPs: 35633.0694. Time: 246972.4933 us. Best GFLOPs: 89200.0650
2023-05-01 16:43:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #74: GFLOPs: 25962.9349. Time: 338959.6760 us. Best GFLOPs: 89200.0650
2023-05-01 16:43:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #75: GFLOPs: 13930.3786. Time: 631740.7633 us. Best GFLOPs: 89200.0650
2023-05-01 16:43:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #76: GFLOPs: 57891.2455. Time: 152015.8690 us. Best GFLOPs: 89200.0650
2023-05-01 16:43:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #77: GFLOPs: 78923.9129. Time: 111504.7097 us. Best GFLOPs: 89200.0650
2023-05-01 16:43:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #78: GFLOPs: 58619.2471. Time: 150127.9600 us. Best GFLOPs: 89200.0650
2023-05-01 16:43:23 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #79: GFLOPs: 37088.0472. Time: 237283.6710 us. Best GFLOPs: 89200.0650
2023-05-01 16:43:23 [INFO] [task_scheduler.cc:121] [Task #0: main] Trial #80: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 8192), "int8"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        C_reindex_shared_dyn = T.alloc_buffer((1024, 64, 1, 16, 16, 16), "float16", scope="shared.dyn")
        C_reindex_shared_dyn_wmma_accumulator = T.alloc_buffer((1024, 64, 1, 16, 16, 16), "float16", scope="wmma.accumulator")
        A_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
        B_decompress_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
        A_reindex_shared_dyn_wmma_matrix_a = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_a")
        B_decompress_reindex_shared_dyn_wmma_matrix_b = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_b")
        for ax0_0_0_ax1_0_0_fused in T.thread_binding(512, thread="blockIdx.y"):
            for ax0_0_1_ax1_0_1_fused in T.thread_binding(128, thread="blockIdx.x"):
                for ax0_0_2_ax1_0_2_fused in T.thread_binding(1, thread="threadIdx.y"):
                    for ax0_0_3_init, ax1_0_3_init, ax0_0_4_init, ax1_0_4_init in T.grid(1, 16, 1, 1):
                        with T.block("B_o_init"):
                            v0_o = T.axis.spatial(1024, ax0_0_4_init + ax0_0_0_ax1_0_0_fused // 2 * 4 + ax0_0_1_ax1_0_1_fused // 32 + ax0_0_3_init)
                            v1_o = T.axis.spatial(1024, ax1_0_4_init + ax0_0_0_ax1_0_0_fused % 2 * 512 + ax0_0_1_ax1_0_1_fused % 32 * 16 + ax1_0_3_init)
                            T.reads()
                            T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 16, 0, v1_o % 16, 0:16, 0:16])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                            C_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 16, 0, v1_o % 16, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.accumulator", offset_factor=16)
                            T.tvm_fill_fragment(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.float32(0))
                    for ax2_0_0 in range(1024):
                        for ax0_ax1_fused_0 in range(8):
                            for ax0_ax1_fused_1 in T.thread_binding(1, thread="threadIdx.y"):
                                for ax0_ax1_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                    with T.block("A_reindex_shared.dyn"):
                                        v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused // 2 * 64 + ax0_0_1_ax1_0_1_fused // 32 * 16 + (ax0_ax1_fused_0 * 32 + ax0_ax1_fused_1 * 32 + ax0_ax1_fused_2) // 16)
                                        v1 = T.axis.spatial(16384, ax2_0_0 * 16 + (ax0_ax1_fused_0 * 32 + ax0_ax1_fused_1 * 32 + ax0_ax1_fused_2) % 16)
                                        T.reads(A[v0, v1])
                                        T.writes(A_reindex_shared_dyn[v0, v1])
                                        T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]]})
                                        A_reindex_shared_dyn[v0, v1] = A[v0, v1]
                        for ax0_ax1_fused_0 in range(64):
                            for ax0_ax1_fused_1 in T.thread_binding(1, thread="threadIdx.y"):
                                for ax0_ax1_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                    for ax0_ax1_fused_3 in T.vectorized(2):
                                        with T.block("B_decompress_reindex_shared.dyn"):
                                            v0 = T.axis.spatial(16384, ax2_0_0 * 16 + (ax0_ax1_fused_0 * 64 + ax0_ax1_fused_1 * 64 + ax0_ax1_fused_2 * 2 + ax0_ax1_fused_3) // 256)
                                            v1 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused % 2 * 8192 + ax0_0_1_ax1_0_1_fused % 32 * 256 + (ax0_ax1_fused_0 * 64 + ax0_ax1_fused_1 * 64 + ax0_ax1_fused_2 * 2 + ax0_ax1_fused_3) % 256)
                                            T.reads(B[v1, v0 // 2:v0 // 2 + 2])
                                            T.writes(B_decompress_reindex_shared_dyn[v0, v1])
                                            T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]]})
                                            B_decompress_reindex_shared_dyn[v0, v1] = T.Select(v0 % 32 * 4 % 8 <= 5, T.Cast("float16", T.bitwise_and(T.shift_right(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8]), v0 % 32 * 4 % 8), 15)), T.Cast("float16", T.bitwise_or(T.Cast("int8", T.bitwise_and(T.shift_right(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8]), v0 % 32 * 4 % 8), T.shift_left(1, 8 - v0 % 32 * 4 % 8) - 1)), T.Cast("int8", T.bitwise_and(T.bitwise_and(T.shift_left(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8 + 1]), 8 - v0 % 32 * 4 % 8), T.shift_left(15, 8 - v0 % 32 * 4 % 8)), 15)))))
                        for ax2_0_1 in range(1):
                            for ax0_0, ax1_0 in T.grid(1, 1):
                                with T.block("A_reindex_shared.dyn_wmma.matrix_a_o"):
                                    v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 2 * 4 + ax0_0_1_ax1_0_1_fused // 32 + ax0_0)
                                    v1_o = T.axis.spatial(1024, ax2_0_0 + ax1_0)
                                    T.reads(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    A_1 = T.match_buffer(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="shared.dyn", offset_factor=16)
                                    C_1 = T.match_buffer(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.matrix_a", offset_factor=16)
                                    T.tvm_load_matrix_sync(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), A_1.data, A_1.elem_offset, A_1.strides[0] * 16, 1), A_1.strides[0], "row_major")
                            for ax0_0, ax1_0 in T.grid(1, 16):
                                with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b_o"):
                                    v0_o = T.axis.spatial(1024, ax2_0_0 + ax0_0)
                                    v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 2 * 512 + ax0_0_1_ax1_0_1_fused % 32 * 16 + ax1_0)
                                    T.reads(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    A_1 = T.match_buffer(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="shared.dyn", offset_factor=16)
                                    C_1 = T.match_buffer(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.matrix_b", offset_factor=16)
                                    T.tvm_load_matrix_sync(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), A_1.data, A_1.elem_offset, A_1.strides[0] * 16, 1), A_1.strides[0], "row_major")
                            for ax0_0_3, ax1_0_3, ax2_0_2, ax0_0_4, ax1_0_4 in T.grid(1, 16, 1, 1, 1):
                                with T.block("B_o_update"):
                                    v0_o = T.axis.spatial(1024, ax0_0_4 + ax0_0_0_ax1_0_0_fused // 2 * 4 + ax0_0_1_ax1_0_1_fused // 32 + ax0_0_3)
                                    v1_o = T.axis.spatial(1024, ax1_0_4 + ax0_0_0_ax1_0_0_fused % 2 * 512 + ax0_0_1_ax1_0_1_fused % 32 * 16 + ax1_0_3)
                                    v2_o = T.axis.reduce(1024, ax2_0_1 + ax2_0_2 + ax2_0_0)
                                    T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 16, 0, v1_o % 16, 0:16, 0:16], A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], B_decompress_reindex_shared_dyn_wmma_matrix_b[v2_o * 16:v2_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 16, 0, v1_o % 16, 0:16, 0:16])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                                    A_1 = T.match_buffer(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="wmma.matrix_a", offset_factor=16)
                                    B_1 = T.match_buffer(B_decompress_reindex_shared_dyn_wmma_matrix_b[v2_o * 16:v2_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("B_s0", "B_s1"), scope="wmma.matrix_b", offset_factor=16)
                                    C_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 16, 0, v1_o % 16, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.accumulator", offset_factor=16)
                                    T.tvm_mma_sync(C_1.data, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, A_1.data, A_1.elem_offset // A_1.strides[0] // 16 * (A_1.strides[0] // 16) + A_1.elem_offset % A_1.strides[0] // 16, B_1.data, B_1.elem_offset // B_1.strides[0] // 16 * (B_1.strides[0] // 16) + B_1.elem_offset % B_1.strides[0] // 16, C_1.data, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16)
                for ax2 in range(1):
                    for ax0_ax1_fused in T.thread_binding(1, thread="threadIdx.y"):
                        for ax2_1, ax3 in T.grid(1, 16):
                            with T.block("C_reindex_shared.dyn_wmma.accumulator_o"):
                                v0 = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 2 * 4 + ax0_0_1_ax1_0_1_fused // 32)
                                v1 = T.axis.spatial(64, ax0_0_0_ax1_0_0_fused % 2 * 32 + ax0_0_1_ax1_0_1_fused % 32)
                                v2, v3 = T.axis.remap("SS", [ax2_1, ax3])
                                v4_o = T.axis.spatial(1, 0)
                                v5_o = T.axis.spatial(1, 0)
                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16])
                                T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16])
                                A_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="wmma.accumulator", offset_factor=16)
                                C_1 = T.match_buffer(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="shared.dyn", offset_factor=16)
                                T.tvm_store_matrix_sync(A_1.data, 16, 16, 16, A_1.elem_offset // A_1.strides[0] // 16 * (A_1.strides[0] // 16) + A_1.elem_offset % A_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), C_1.data, C_1.elem_offset, C_1.strides[0] * 16, 2), C_1.strides[0], "row_major")
                    for ax0_ax1_ax3_ax4_ax5_fused_0 in range(128):
                        for ax0_ax1_ax3_ax4_ax5_fused_1 in T.thread_binding(1, thread="threadIdx.y"):
                            for ax0_ax1_ax3_ax4_ax5_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                with T.block("C_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 2 * 4 + ax0_0_1_ax1_0_1_fused // 32)
                                    v1 = T.axis.spatial(64, ax0_0_0_ax1_0_0_fused % 2 * 32 + ax0_0_1_ax1_0_1_fused % 32)
                                    v2 = T.axis.spatial(1, ax2)
                                    v3 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 32 + ax0_ax1_ax3_ax4_ax5_fused_1 * 32 + ax0_ax1_ax3_ax4_ax5_fused_2) // 256)
                                    v4 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 32 + ax0_ax1_ax3_ax4_ax5_fused_1 * 32 + ax0_ax1_ax3_ax4_ax5_fused_2) % 256 // 16)
                                    v5 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 32 + ax0_ax1_ax3_ax4_ax5_fused_1 * 32 + ax0_ax1_ax3_ax4_ax5_fused_2) % 16)
                                    T.reads(C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5])
                                    T.writes(C[v4 + v0 * 16, v5 + v3 * 16 + v1 * 256])
                                    C[v4 + v0 * 16, v5 + v3 * 16 + v1 * 256] = C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5]
b0 = sch.get_block(name="B_decompress", func_name="main")
b1 = sch.get_block(name="B", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
b3 = sch.reindex(block=b1, buffer=("write", 0))
b4 = sch.reindex(block=b1, buffer=("read", 0))
b5 = sch.reindex(block=b1, buffer=("read", 1))
sch.transform_layout(block=b1, buffer=("read", 0), index_map=lambda vi, vk: (vi, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("read", 1), index_map=lambda vj, vk: (vk, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("write", 0), index_map=lambda vi, vj: (vi, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_block_layout(block=b3, index_map=lambda vi, vj: (vi, vj,))
sch.transform_block_layout(block=b4, index_map=lambda vi, vk: (vi, vk,))
sch.transform_block_layout(block=b5, index_map=lambda vj, vk: (vk, vj,))
sch.transform_block_layout(block=b1, index_map=lambda vi, vj, vk: (vi, vj, vk,))
l6, l7, l8 = sch.get_loops(block=b1)
l9, l10 = sch.split(loop=l8, factors=[None, 16], preserve_unit_iters=True)
l11, l12 = sch.split(loop=l7, factors=[None, 16], preserve_unit_iters=True)
l13, l14 = sch.split(loop=l6, factors=[None, 16], preserve_unit_iters=True)
l15, l16, l17, l18, l19, l20 = sch.get_loops(block=b1)
sch.reorder(l17, l19, l14, l12, l10)
b21 = sch.blockize(loop=l14, preserve_unit_iters=True)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_sync_16x16x16_f16f16f16")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize_init", ann_val="wmma_fill_16x16x16_f16")
sch.annotate(block_or_loop=b21, ann_key="warp_execution", ann_val=1)
l22, l23, l24 = sch.get_loops(block=b21)
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l22, n=5, max_innermost_factor=4, decision=[256, 4, 1, 1, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l22, factors=[v25, v26, v27, v28, v29], preserve_unit_iters=True)
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l23, n=5, max_innermost_factor=4, decision=[2, 32, 1, 16, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l23, factors=[v35, v36, v37, v38, v39], preserve_unit_iters=True)
v45, v46, v47 = sch.sample_perfect_tile(loop=l24, n=3, max_innermost_factor=4, decision=[1024, 1, 1])
l48, l49, l50 = sch.split(loop=l24, factors=[v45, v46, v47], preserve_unit_iters=True)
sch.reorder(l30, l40, l31, l41, l32, l42, l48, l49, l33, l43, l50, l34, l44)
l51 = sch.fuse(l30, l40, preserve_unit_iters=True)
sch.bind(loop=l51, thread_axis="blockIdx.y")
l52 = sch.fuse(l31, l41, preserve_unit_iters=True)
sch.bind(loop=l52, thread_axis="blockIdx.x")
l53 = sch.fuse(l32, l42, preserve_unit_iters=True)
sch.bind(loop=l53, thread_axis="threadIdx.y")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
sch.transform_layout(block=b21, buffer=("write", 0), index_map=lambda i0, i1: (i0 // 16 // (v28 * v29), i1 // 16 // (v38 * v39), i0 // 16 % (v28 * v29), i1 // 16 % (v38 * v39), i0 % 16, i1 % 16,), pad_value=None, assume_injective_transform=True)
b54 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="shared.dyn")
sch.reverse_compute_at(block=b54, loop=l52, preserve_unit_loops=True, index=-1)
b55 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="wmma.accumulator")
l56, l57, l58, l59, l60, l61, l62, l63 = sch.get_loops(block=b54)
sch.reorder(l60, l58, l59, l61)
sch.compute_at(block=b55, loop=l60, preserve_unit_loops=True, index=-1)
l64, l65, l66, l67, l68, l69, l70, l71, l72 = sch.get_loops(block=b55)
l73 = sch.fuse(l67, l68, preserve_unit_iters=True)
sch.bind(loop=l73, thread_axis="threadIdx.y")
sch.reverse_compute_inline(block=b3)
l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b55)
b82 = sch.blockize(loop=l80, preserve_unit_iters=True)
sch.annotate(block_or_loop=b82, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_store_16x16x16_f16_shared_dyn")
l83, l84, l85, l86, l87, l88, l89, l90 = sch.get_loops(block=b54)
l91 = sch.fuse(l86, l87, l88, l89, l90, preserve_unit_iters=True)
v92 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch", ann_val=v92)
b93 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b93, loop=l48, preserve_unit_loops=True, index=-1)
l94, l95, l96, l97, l98, l99 = sch.get_loops(block=b93)
l100 = sch.fuse(l98, l99, preserve_unit_iters=True)
v101 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch", ann_val=v101)
b102 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b102, loop=l48, preserve_unit_loops=True, index=-1)
l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b102)
l109 = sch.fuse(l107, l108, preserve_unit_iters=True)
v110 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch", ann_val=v110)
b111 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="wmma.matrix_a")
sch.compute_at(block=b111, loop=l49, preserve_unit_loops=True, index=-1)
l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b111)
l119, l120 = sch.split(loop=l118, factors=[None, 16], preserve_unit_iters=True)
l121, l122 = sch.split(loop=l117, factors=[None, 16], preserve_unit_iters=True)
l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b111)
sch.reorder(l130, l122, l120)
b132 = sch.blockize(loop=l122, preserve_unit_iters=True)
sch.annotate(block_or_loop=b132, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_a_shared_dyn")
b133 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="wmma.matrix_b")
sch.compute_at(block=b133, loop=l49, preserve_unit_loops=True, index=-1)
l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b133)
l141, l142 = sch.split(loop=l140, factors=[None, 16], preserve_unit_iters=True)
l143, l144 = sch.split(loop=l139, factors=[None, 16], preserve_unit_iters=True)
l145, l146, l147, l148, l149, l150, l151, l152, l153 = sch.get_loops(block=b133)
sch.reorder(l152, l144, l142)
b154 = sch.blockize(loop=l144, preserve_unit_iters=True)
sch.annotate(block_or_loop=b154, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_b_shared_dyn")
sch.compute_inline(block=b4)
sch.compute_inline(block=b5)
sch.storage_align(block=b93, buffer_index=0, axis=-2, factor=32, offset=8)
sch.storage_align(block=b102, buffer_index=0, axis=-2, factor=32, offset=8)
sch.compute_inline(block=b0)
v155 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v155)
sch.enter_postproc()
sch.unannotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch")
l156, l157, l158, l159 = sch.get_loops(block=b54)
l160, l161, l162 = sch.split(loop=l159, factors=[None, 1, 32], preserve_unit_iters=True)
sch.bind(loop=l162, thread_axis="threadIdx.x")
sch.bind(loop=l161, thread_axis="threadIdx.y")
sch.unannotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch")
l163, l164, l165, l166, l167 = sch.get_loops(block=b93)
l168, l169, l170 = sch.split(loop=l167, factors=[None, 1, 32], preserve_unit_iters=True)
sch.bind(loop=l170, thread_axis="threadIdx.x")
sch.bind(loop=l169, thread_axis="threadIdx.y")
sch.unannotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch")
l171, l172, l173, l174, l175 = sch.get_loops(block=b102)
l176, l177, l178, l179 = sch.split(loop=l175, factors=[None, 1, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l179)
sch.bind(loop=l178, thread_axis="threadIdx.x")
sch.bind(loop=l177, thread_axis="threadIdx.y")
b180 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b180, ann_key="meta_schedule.unroll_explicit")
b181, b182, b183, b184, b185, b186, b187 = sch.get_child_blocks(b180)
l188, l189, l190, l191, l192, l193, l194 = sch.get_loops(block=b181)
l195, l196, l197, l198, l199, l200, l201, l202 = sch.get_loops(block=b182)
l203, l204, l205, l206, l207, l208, l209 = sch.get_loops(block=b183)
l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b184)
l217, l218, l219, l220, l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b185)
l227, l228, l229, l230, l231, l232 = sch.get_loops(block=b186)
l233, l234, l235, l236, l237, l238 = sch.get_loops(block=b187)
b239 = sch.get_block(name="B_o", func_name="main")
l240, l241, l242, l243, l244, l245, l246, l247, l248, l249 = sch.get_loops(block=b239)
b250 = sch.decompose_reduction(block=b239, loop=l243)
sch.unannotate(block_or_loop=b250, ann_key="meta_schedule.auto_tensorize")
sch.annotate(block_or_loop=b250, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_fill_16x16x16_f16")
sch.unannotate(block_or_loop=b239, ann_key="meta_schedule.auto_tensorize_init")
sch.unannotate(block_or_loop=b250, ann_key="meta_schedule.auto_tensorize_init")
b251 = sch.get_block(name="B_o_init", func_name="main")
sch.unannotate(block_or_loop=b251, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b251, tensor_intrin="wmma_fill_16x16x16_f16", preserve_unit_iters=True)
b252 = sch.get_block(name="A_reindex_shared.dyn_wmma.matrix_a_o", func_name="main")
sch.unannotate(block_or_loop=b252, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b252, tensor_intrin="wmma_load_16x16x16_f16_a_shared_dyn", preserve_unit_iters=True)
b253 = sch.get_block(name="B_decompress_reindex_shared.dyn_wmma.matrix_b_o", func_name="main")
sch.unannotate(block_or_loop=b253, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b253, tensor_intrin="wmma_load_16x16x16_f16_b_shared_dyn", preserve_unit_iters=True)
b254 = sch.get_block(name="B_o_update", func_name="main")
sch.unannotate(block_or_loop=b254, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b254, tensor_intrin="wmma_sync_16x16x16_f16f16f16", preserve_unit_iters=True)
b255 = sch.get_block(name="C_reindex_shared.dyn_wmma.accumulator_o", func_name="main")
sch.unannotate(block_or_loop=b255, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b255, tensor_intrin="wmma_store_16x16x16_f16_shared_dyn", preserve_unit_iters=True)
2023-05-01 16:43:23 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 16:43:24 [INFO] [evolutionary_search.cc:715] Picked top 72 candidate(s) from database
2023-05-01 16:43:28 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 430 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:43:32 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 865 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:43:35 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1300 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:43:39 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1730 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:43:43 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2162 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:43:47 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2592 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:43:51 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 3016 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:43:51 [INFO] [evolutionary_search.cc:723] Sampled 64 candidate(s)
2023-05-01 16:43:57 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 96 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:44:03 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 84 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:44:09 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 99 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:44:15 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 96 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:44:16 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9997  0.9992  0.9985  0.9962  0.9961  0.9949  0.9939  0.9935  0.9932  0.9930  0.9911  0.9905  0.9895  0.9895  0.9893  0.9888
2023-05-01 16:44:16 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 16:44:16 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 16:51:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #81: GFLOPs: 51259.5726. Time: 171682.8203 us. Best GFLOPs: 89200.0650
2023-05-01 16:51:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #82: GFLOPs: 30824.8739. Time: 285496.3173 us. Best GFLOPs: 89200.0650
2023-05-01 16:51:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #83: GFLOPs: 34226.8879. Time: 257119.1403 us. Best GFLOPs: 89200.0650
2023-05-01 16:51:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #84: GFLOPs: 18636.7554. Time: 472206.0137 us. Best GFLOPs: 89200.0650
2023-05-01 16:51:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #85: GFLOPs: 110170.7790. Time: 79879.5113 us. Best GFLOPs: 110170.7790
2023-05-01 16:51:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #86: GFLOPs: 17888.9337. Time: 491945.9227 us. Best GFLOPs: 110170.7790
2023-05-01 16:51:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #87: GFLOPs: 29432.2511. Time: 299004.9233 us. Best GFLOPs: 110170.7790
2023-05-01 16:51:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #88: GFLOPs: 59305.5932. Time: 148390.5230 us. Best GFLOPs: 110170.7790
2023-05-01 16:51:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #89: GFLOPs: 57419.7500. Time: 153264.1293 us. Best GFLOPs: 110170.7790
2023-05-01 16:51:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #90: GFLOPs: 7934.6923. Time: 1109102.6203 us. Best GFLOPs: 110170.7790
2023-05-01 16:51:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #91: GFLOPs: 32473.7272. Time: 271000.2440 us. Best GFLOPs: 110170.7790
2023-05-01 16:51:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #92: GFLOPs: 27789.6920. Time: 316678.1410 us. Best GFLOPs: 110170.7790
2023-05-01 16:51:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #93: GFLOPs: 28467.9073. Time: 309133.6463 us. Best GFLOPs: 110170.7790
2023-05-01 16:51:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #94: GFLOPs: 47052.1191. Time: 187034.8917 us. Best GFLOPs: 110170.7790
2023-05-01 16:51:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #95: GFLOPs: 24660.9532. Time: 356855.1430 us. Best GFLOPs: 110170.7790
2023-05-01 16:51:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #96: GFLOPs: 11123.3014. Time: 791166.9107 us. Best GFLOPs: 110170.7790
2023-05-01 16:51:22 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 16:51:23 [INFO] [evolutionary_search.cc:715] Picked top 88 candidate(s) from database
2023-05-01 16:51:27 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 422 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:51:31 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 837 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:51:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1247 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:51:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1662 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:51:42 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2074 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:51:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2487 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:51:45 [INFO] [evolutionary_search.cc:723] Sampled 57 candidate(s)
2023-05-01 16:51:51 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 86 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:51:58 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 120 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:52:04 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 74 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:52:10 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 73 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:52:10 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9989  0.9986  0.9986  0.9983  0.9972  0.9959  0.9941  0.9941  0.9931  0.9930  0.9927  0.9926  0.9923  0.9922  0.9920  0.9915
2023-05-01 16:52:10 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 16:52:10 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 16:59:19 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #97: GFLOPs: 16388.8842. Time: 536972.9817 us. Best GFLOPs: 110170.7790
2023-05-01 16:59:19 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #98: GFLOPs: 67332.9400. Time: 130699.5950 us. Best GFLOPs: 110170.7790
2023-05-01 16:59:19 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #99: GFLOPs: 80371.0428. Time: 109496.9990 us. Best GFLOPs: 110170.7790
2023-05-01 16:59:19 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #100: GFLOPs: 27602.2880. Time: 318828.2063 us. Best GFLOPs: 110170.7790
2023-05-01 16:59:19 [INFO] [task_scheduler.cc:121] [Task #0: main] Trial #101: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 8192), "int8"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        C_reindex_shared_dyn = T.alloc_buffer((1024, 128, 1, 8, 16, 16), "float16", scope="shared.dyn")
        C_reindex_shared_dyn_wmma_accumulator = T.alloc_buffer((1024, 128, 1, 8, 16, 16), "float16", scope="wmma.accumulator")
        A_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
        B_decompress_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
        A_reindex_shared_dyn_wmma_matrix_a = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_a")
        B_decompress_reindex_shared_dyn_wmma_matrix_b = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_b")
        for ax0_0_0_ax1_0_0_fused in T.thread_binding(32, thread="blockIdx.y", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ax0_0_1_ax1_0_1_fused in T.thread_binding(2048, thread="blockIdx.x"):
                for ax0_0_2_ax1_0_2_fused in T.thread_binding(2, thread="threadIdx.y"):
                    for ax0_0_3_init, ax1_0_3_init, ax0_0_4_init, ax1_0_4_init in T.grid(1, 2, 1, 4):
                        with T.block("B_o_init"):
                            v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 8 * 256 + ax0_0_1_ax1_0_1_fused // 16 * 2 + ax0_0_2_ax1_0_2_fused + ax0_0_3_init + ax0_0_4_init)
                            v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 8 * 128 + ax0_0_1_ax1_0_1_fused % 16 * 8 + ax1_0_3_init * 4 + ax1_0_4_init)
                            T.reads()
                            T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 8, 0, v1_o % 8, 0:16, 0:16])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                            C_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 8, 0, v1_o % 8, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.accumulator", offset_factor=16)
                            T.tvm_fill_fragment(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.float32(0))
                    for ax2_0_0 in range(1024):
                        for ax0_ax1_fused_0 in range(2):
                            for ax0_ax1_fused_1 in T.thread_binding(2, thread="threadIdx.y"):
                                for ax0_ax1_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                    for ax0_ax1_fused_3 in T.vectorized(4):
                                        with T.block("A_reindex_shared.dyn"):
                                            v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused // 8 * 4096 + ax0_0_1_ax1_0_1_fused // 16 * 32 + (ax0_ax1_fused_0 * 256 + ax0_ax1_fused_1 * 128 + ax0_ax1_fused_2 * 4 + ax0_ax1_fused_3) // 16)
                                            v1 = T.axis.spatial(16384, ax2_0_0 * 16 + (ax0_ax1_fused_0 * 256 + ax0_ax1_fused_1 * 128 + ax0_ax1_fused_2 * 4 + ax0_ax1_fused_3) % 16)
                                            T.reads(A[v0, v1])
                                            T.writes(A_reindex_shared_dyn[v0, v1])
                                            T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]]})
                                            A_reindex_shared_dyn[v0, v1] = A[v0, v1]
                        for ax0_ax1_fused_0 in range(8):
                            for ax0_ax1_fused_1 in T.thread_binding(2, thread="threadIdx.y"):
                                for ax0_ax1_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                    for ax0_ax1_fused_3 in T.vectorized(4):
                                        with T.block("B_decompress_reindex_shared.dyn"):
                                            v0 = T.axis.spatial(16384, ax2_0_0 * 16 + (ax0_ax1_fused_0 * 256 + ax0_ax1_fused_1 * 128 + ax0_ax1_fused_2 * 4 + ax0_ax1_fused_3) // 128)
                                            v1 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused % 8 * 2048 + ax0_0_1_ax1_0_1_fused % 16 * 128 + (ax0_ax1_fused_0 * 256 + ax0_ax1_fused_1 * 128 + ax0_ax1_fused_2 * 4 + ax0_ax1_fused_3) % 128)
                                            T.reads(B[v1, v0 // 2:v0 // 2 + 2])
                                            T.writes(B_decompress_reindex_shared_dyn[v0, v1])
                                            T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]]})
                                            B_decompress_reindex_shared_dyn[v0, v1] = T.Select(v0 % 32 * 4 % 8 <= 5, T.Cast("float16", T.bitwise_and(T.shift_right(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8]), v0 % 32 * 4 % 8), 15)), T.Cast("float16", T.bitwise_or(T.Cast("int8", T.bitwise_and(T.shift_right(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8]), v0 % 32 * 4 % 8), T.shift_left(1, 8 - v0 % 32 * 4 % 8) - 1)), T.Cast("int8", T.bitwise_and(T.bitwise_and(T.shift_left(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8 + 1]), 8 - v0 % 32 * 4 % 8), T.shift_left(15, 8 - v0 % 32 * 4 % 8)), 15)))))
                        for ax2_0_1 in range(1):
                            for ax0_0, ax1_0 in T.grid(1, 1):
                                with T.block("A_reindex_shared.dyn_wmma.matrix_a_o"):
                                    v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 8 * 256 + ax0_0_1_ax1_0_1_fused // 16 * 2 + ax0_0_2_ax1_0_2_fused + ax0_0)
                                    v1_o = T.axis.spatial(1024, ax2_0_0 + ax1_0)
                                    T.reads(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    A_1 = T.match_buffer(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="shared.dyn", offset_factor=16)
                                    C_1 = T.match_buffer(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.matrix_a", offset_factor=16)
                                    T.tvm_load_matrix_sync(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), A_1.data, A_1.elem_offset, A_1.strides[0] * 16, 1), A_1.strides[0], "row_major")
                            for ax0_0, ax1_0 in T.grid(1, 8):
                                with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b_o"):
                                    v0_o = T.axis.spatial(1024, ax2_0_0 + ax0_0)
                                    v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 8 * 128 + ax0_0_1_ax1_0_1_fused % 16 * 8 + ax1_0)
                                    T.reads(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    A_1 = T.match_buffer(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="shared.dyn", offset_factor=16)
                                    C_1 = T.match_buffer(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.matrix_b", offset_factor=16)
                                    T.tvm_load_matrix_sync(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), A_1.data, A_1.elem_offset, A_1.strides[0] * 16, 1), A_1.strides[0], "row_major")
                            for ax0_0_3, ax1_0_3, ax2_0_2, ax0_0_4, ax1_0_4 in T.grid(1, 2, 1, 1, 4):
                                with T.block("B_o_update"):
                                    v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 8 * 256 + ax0_0_1_ax1_0_1_fused // 16 * 2 + ax0_0_2_ax1_0_2_fused + ax0_0_3 + ax0_0_4)
                                    v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 8 * 128 + ax0_0_1_ax1_0_1_fused % 16 * 8 + ax1_0_3 * 4 + ax1_0_4)
                                    v2_o = T.axis.reduce(1024, ax2_0_1 + ax2_0_2 + ax2_0_0)
                                    T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 8, 0, v1_o % 8, 0:16, 0:16], A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], B_decompress_reindex_shared_dyn_wmma_matrix_b[v2_o * 16:v2_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 8, 0, v1_o % 8, 0:16, 0:16])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                                    A_1 = T.match_buffer(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="wmma.matrix_a", offset_factor=16)
                                    B_1 = T.match_buffer(B_decompress_reindex_shared_dyn_wmma_matrix_b[v2_o * 16:v2_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("B_s0", "B_s1"), scope="wmma.matrix_b", offset_factor=16)
                                    C_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 8, 0, v1_o % 8, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.accumulator", offset_factor=16)
                                    T.tvm_mma_sync(C_1.data, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, A_1.data, A_1.elem_offset // A_1.strides[0] // 16 * (A_1.strides[0] // 16) + A_1.elem_offset % A_1.strides[0] // 16, B_1.data, B_1.elem_offset // B_1.strides[0] // 16 * (B_1.strides[0] // 16) + B_1.elem_offset % B_1.strides[0] // 16, C_1.data, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16)
                for ax2 in range(1):
                    for ax0_ax1_fused in T.thread_binding(2, thread="threadIdx.y"):
                        for ax2_1, ax3 in T.grid(1, 8):
                            with T.block("C_reindex_shared.dyn_wmma.accumulator_o"):
                                v0 = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 8 * 256 + ax0_0_1_ax1_0_1_fused // 16 * 2 + ax0_ax1_fused)
                                v1 = T.axis.spatial(128, ax0_0_0_ax1_0_0_fused % 8 * 16 + ax0_0_1_ax1_0_1_fused % 16)
                                v2, v3 = T.axis.remap("SS", [ax2_1, ax3])
                                v4_o = T.axis.spatial(1, 0)
                                v5_o = T.axis.spatial(1, 0)
                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16])
                                T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16])
                                A_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="wmma.accumulator", offset_factor=16)
                                C_1 = T.match_buffer(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="shared.dyn", offset_factor=16)
                                T.tvm_store_matrix_sync(A_1.data, 16, 16, 16, A_1.elem_offset // A_1.strides[0] // 16 * (A_1.strides[0] // 16) + A_1.elem_offset % A_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), C_1.data, C_1.elem_offset, C_1.strides[0] * 16, 2), C_1.strides[0], "row_major")
                    for ax0_ax1_ax3_ax4_ax5_fused_0 in range(32):
                        for ax0_ax1_ax3_ax4_ax5_fused_1 in T.thread_binding(2, thread="threadIdx.y"):
                            for ax0_ax1_ax3_ax4_ax5_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax3_ax4_ax5_fused_3 in T.vectorized(2):
                                    with T.block("C_reindex_shared.dyn"):
                                        v0 = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 8 * 256 + ax0_0_1_ax1_0_1_fused // 16 * 2 + (ax0_ax1_ax3_ax4_ax5_fused_0 * 128 + ax0_ax1_ax3_ax4_ax5_fused_1 * 64 + ax0_ax1_ax3_ax4_ax5_fused_2 * 2 + ax0_ax1_ax3_ax4_ax5_fused_3) // 2048)
                                        v1 = T.axis.spatial(128, ax0_0_0_ax1_0_0_fused % 8 * 16 + ax0_0_1_ax1_0_1_fused % 16)
                                        v2 = T.axis.spatial(1, ax2)
                                        v3 = T.axis.spatial(8, (ax0_ax1_ax3_ax4_ax5_fused_0 * 128 + ax0_ax1_ax3_ax4_ax5_fused_1 * 64 + ax0_ax1_ax3_ax4_ax5_fused_2 * 2 + ax0_ax1_ax3_ax4_ax5_fused_3) % 2048 // 256)
                                        v4 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 128 + ax0_ax1_ax3_ax4_ax5_fused_1 * 64 + ax0_ax1_ax3_ax4_ax5_fused_2 * 2 + ax0_ax1_ax3_ax4_ax5_fused_3) % 256 // 16)
                                        v5 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 128 + ax0_ax1_ax3_ax4_ax5_fused_1 * 64 + ax0_ax1_ax3_ax4_ax5_fused_2 * 2 + ax0_ax1_ax3_ax4_ax5_fused_3) % 16)
                                        T.reads(C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5])
                                        T.writes(C[v4 + v0 * 16, v5 + v3 * 16 + v1 * 128])
                                        C[v4 + v0 * 16, v5 + v3 * 16 + v1 * 128] = C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5]
b0 = sch.get_block(name="B_decompress", func_name="main")
b1 = sch.get_block(name="B", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
b3 = sch.reindex(block=b1, buffer=("write", 0))
b4 = sch.reindex(block=b1, buffer=("read", 0))
b5 = sch.reindex(block=b1, buffer=("read", 1))
sch.transform_layout(block=b1, buffer=("read", 0), index_map=lambda vi, vk: (vi, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("read", 1), index_map=lambda vj, vk: (vk, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("write", 0), index_map=lambda vi, vj: (vi, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_block_layout(block=b3, index_map=lambda vi, vj: (vi, vj,))
sch.transform_block_layout(block=b4, index_map=lambda vi, vk: (vi, vk,))
sch.transform_block_layout(block=b5, index_map=lambda vj, vk: (vk, vj,))
sch.transform_block_layout(block=b1, index_map=lambda vi, vj, vk: (vi, vj, vk,))
l6, l7, l8 = sch.get_loops(block=b1)
l9, l10 = sch.split(loop=l8, factors=[None, 16], preserve_unit_iters=True)
l11, l12 = sch.split(loop=l7, factors=[None, 16], preserve_unit_iters=True)
l13, l14 = sch.split(loop=l6, factors=[None, 16], preserve_unit_iters=True)
l15, l16, l17, l18, l19, l20 = sch.get_loops(block=b1)
sch.reorder(l17, l19, l14, l12, l10)
b21 = sch.blockize(loop=l14, preserve_unit_iters=True)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_sync_16x16x16_f16f16f16")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize_init", ann_val="wmma_fill_16x16x16_f16")
sch.annotate(block_or_loop=b21, ann_key="warp_execution", ann_val=1)
l22, l23, l24 = sch.get_loops(block=b21)
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l22, n=5, max_innermost_factor=4, decision=[4, 128, 2, 1, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l22, factors=[v25, v26, v27, v28, v29], preserve_unit_iters=True)
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l23, n=5, max_innermost_factor=4, decision=[8, 16, 1, 2, 4])
l40, l41, l42, l43, l44 = sch.split(loop=l23, factors=[v35, v36, v37, v38, v39], preserve_unit_iters=True)
v45, v46, v47 = sch.sample_perfect_tile(loop=l24, n=3, max_innermost_factor=4, decision=[1024, 1, 1])
l48, l49, l50 = sch.split(loop=l24, factors=[v45, v46, v47], preserve_unit_iters=True)
sch.reorder(l30, l40, l31, l41, l32, l42, l48, l49, l33, l43, l50, l34, l44)
l51 = sch.fuse(l30, l40, preserve_unit_iters=True)
sch.bind(loop=l51, thread_axis="blockIdx.y")
l52 = sch.fuse(l31, l41, preserve_unit_iters=True)
sch.bind(loop=l52, thread_axis="blockIdx.x")
l53 = sch.fuse(l32, l42, preserve_unit_iters=True)
sch.bind(loop=l53, thread_axis="threadIdx.y")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
sch.transform_layout(block=b21, buffer=("write", 0), index_map=lambda i0, i1: (i0 // 16 // (v28 * v29), i1 // 16 // (v38 * v39), i0 // 16 % (v28 * v29), i1 // 16 % (v38 * v39), i0 % 16, i1 % 16,), pad_value=None, assume_injective_transform=True)
b54 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="shared.dyn")
sch.reverse_compute_at(block=b54, loop=l52, preserve_unit_loops=True, index=-1)
b55 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="wmma.accumulator")
l56, l57, l58, l59, l60, l61, l62, l63 = sch.get_loops(block=b54)
sch.reorder(l60, l58, l59, l61)
sch.compute_at(block=b55, loop=l60, preserve_unit_loops=True, index=-1)
l64, l65, l66, l67, l68, l69, l70, l71, l72 = sch.get_loops(block=b55)
l73 = sch.fuse(l67, l68, preserve_unit_iters=True)
sch.bind(loop=l73, thread_axis="threadIdx.y")
sch.reverse_compute_inline(block=b3)
l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b55)
b82 = sch.blockize(loop=l80, preserve_unit_iters=True)
sch.annotate(block_or_loop=b82, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_store_16x16x16_f16_shared_dyn")
l83, l84, l85, l86, l87, l88, l89, l90 = sch.get_loops(block=b54)
l91 = sch.fuse(l86, l87, l88, l89, l90, preserve_unit_iters=True)
v92 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch", ann_val=v92)
b93 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b93, loop=l48, preserve_unit_loops=True, index=-1)
l94, l95, l96, l97, l98, l99 = sch.get_loops(block=b93)
l100 = sch.fuse(l98, l99, preserve_unit_iters=True)
v101 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch", ann_val=v101)
b102 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b102, loop=l48, preserve_unit_loops=True, index=-1)
l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b102)
l109 = sch.fuse(l107, l108, preserve_unit_iters=True)
v110 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch", ann_val=v110)
b111 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="wmma.matrix_a")
sch.compute_at(block=b111, loop=l49, preserve_unit_loops=True, index=-1)
l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b111)
l119, l120 = sch.split(loop=l118, factors=[None, 16], preserve_unit_iters=True)
l121, l122 = sch.split(loop=l117, factors=[None, 16], preserve_unit_iters=True)
l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b111)
sch.reorder(l130, l122, l120)
b132 = sch.blockize(loop=l122, preserve_unit_iters=True)
sch.annotate(block_or_loop=b132, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_a_shared_dyn")
b133 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="wmma.matrix_b")
sch.compute_at(block=b133, loop=l49, preserve_unit_loops=True, index=-1)
l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b133)
l141, l142 = sch.split(loop=l140, factors=[None, 16], preserve_unit_iters=True)
l143, l144 = sch.split(loop=l139, factors=[None, 16], preserve_unit_iters=True)
l145, l146, l147, l148, l149, l150, l151, l152, l153 = sch.get_loops(block=b133)
sch.reorder(l152, l144, l142)
b154 = sch.blockize(loop=l144, preserve_unit_iters=True)
sch.annotate(block_or_loop=b154, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_b_shared_dyn")
sch.compute_inline(block=b4)
sch.compute_inline(block=b5)
sch.storage_align(block=b93, buffer_index=0, axis=-2, factor=32, offset=8)
sch.storage_align(block=b102, buffer_index=0, axis=-2, factor=32, offset=8)
sch.compute_inline(block=b0)
v155 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v155)
sch.enter_postproc()
sch.unannotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch")
l156, l157, l158, l159 = sch.get_loops(block=b54)
l160, l161, l162, l163 = sch.split(loop=l159, factors=[None, 2, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l163)
sch.bind(loop=l162, thread_axis="threadIdx.x")
sch.bind(loop=l161, thread_axis="threadIdx.y")
sch.unannotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch")
l164, l165, l166, l167, l168 = sch.get_loops(block=b93)
l169, l170, l171, l172 = sch.split(loop=l168, factors=[None, 2, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l172)
sch.bind(loop=l171, thread_axis="threadIdx.x")
sch.bind(loop=l170, thread_axis="threadIdx.y")
sch.unannotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch")
l173, l174, l175, l176, l177 = sch.get_loops(block=b102)
l178, l179, l180, l181 = sch.split(loop=l177, factors=[None, 2, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l181)
sch.bind(loop=l180, thread_axis="threadIdx.x")
sch.bind(loop=l179, thread_axis="threadIdx.y")
b182 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b182, ann_key="meta_schedule.unroll_explicit")
b183, b184, b185, b186, b187, b188, b189 = sch.get_child_blocks(b182)
l190, l191, l192, l193, l194, l195, l196, l197 = sch.get_loops(block=b183)
sch.annotate(block_or_loop=l190, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l190, ann_key="pragma_unroll_explicit", ann_val=1)
l198, l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b184)
sch.annotate(block_or_loop=l198, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l198, ann_key="pragma_unroll_explicit", ann_val=1)
l206, l207, l208, l209, l210, l211, l212 = sch.get_loops(block=b185)
sch.annotate(block_or_loop=l206, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l206, ann_key="pragma_unroll_explicit", ann_val=1)
l213, l214, l215, l216, l217, l218, l219 = sch.get_loops(block=b186)
sch.annotate(block_or_loop=l213, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l213, ann_key="pragma_unroll_explicit", ann_val=1)
l220, l221, l222, l223, l224, l225, l226, l227, l228, l229 = sch.get_loops(block=b187)
sch.annotate(block_or_loop=l220, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l220, ann_key="pragma_unroll_explicit", ann_val=1)
l230, l231, l232, l233, l234, l235 = sch.get_loops(block=b188)
sch.annotate(block_or_loop=l230, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l230, ann_key="pragma_unroll_explicit", ann_val=1)
l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b189)
sch.annotate(block_or_loop=l236, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l236, ann_key="pragma_unroll_explicit", ann_val=1)
b243 = sch.get_block(name="B_o", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b243)
b254 = sch.decompose_reduction(block=b243, loop=l247)
sch.unannotate(block_or_loop=b254, ann_key="meta_schedule.auto_tensorize")
sch.annotate(block_or_loop=b254, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_fill_16x16x16_f16")
sch.unannotate(block_or_loop=b243, ann_key="meta_schedule.auto_tensorize_init")
sch.unannotate(block_or_loop=b254, ann_key="meta_schedule.auto_tensorize_init")
b255 = sch.get_block(name="B_o_init", func_name="main")
sch.unannotate(block_or_loop=b255, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b255, tensor_intrin="wmma_fill_16x16x16_f16", preserve_unit_iters=True)
b256 = sch.get_block(name="A_reindex_shared.dyn_wmma.matrix_a_o", func_name="main")
sch.unannotate(block_or_loop=b256, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b256, tensor_intrin="wmma_load_16x16x16_f16_a_shared_dyn", preserve_unit_iters=True)
b257 = sch.get_block(name="B_decompress_reindex_shared.dyn_wmma.matrix_b_o", func_name="main")
sch.unannotate(block_or_loop=b257, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b257, tensor_intrin="wmma_load_16x16x16_f16_b_shared_dyn", preserve_unit_iters=True)
b258 = sch.get_block(name="B_o_update", func_name="main")
sch.unannotate(block_or_loop=b258, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b258, tensor_intrin="wmma_sync_16x16x16_f16f16f16", preserve_unit_iters=True)
b259 = sch.get_block(name="C_reindex_shared.dyn_wmma.accumulator_o", func_name="main")
sch.unannotate(block_or_loop=b259, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b259, tensor_intrin="wmma_store_16x16x16_f16_shared_dyn", preserve_unit_iters=True)
2023-05-01 16:59:19 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #102: GFLOPs: 20056.9492. Time: 438770.0193 us. Best GFLOPs: 110170.7790
2023-05-01 16:59:19 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #103: GFLOPs: 71094.2128. Time: 123784.8713 us. Best GFLOPs: 110170.7790
2023-05-01 16:59:19 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #104: GFLOPs: 7982.3757. Time: 1102477.2947 us. Best GFLOPs: 110170.7790
2023-05-01 16:59:19 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #105: GFLOPs: 27888.2328. Time: 315559.1837 us. Best GFLOPs: 110170.7790
2023-05-01 16:59:19 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #106: GFLOPs: 86344.2324. Time: 101922.1290 us. Best GFLOPs: 110170.7790
2023-05-01 16:59:19 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #107: GFLOPs: 47304.5434. Time: 186036.8447 us. Best GFLOPs: 110170.7790
2023-05-01 16:59:19 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #108: GFLOPs: 26077.8757. Time: 337465.6777 us. Best GFLOPs: 110170.7790
2023-05-01 16:59:19 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #109: GFLOPs: 72236.3664. Time: 121827.6670 us. Best GFLOPs: 110170.7790
2023-05-01 16:59:19 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #110: GFLOPs: 21747.9824. Time: 404653.0760 us. Best GFLOPs: 110170.7790
2023-05-01 16:59:19 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #111: GFLOPs: 27414.0429. Time: 321017.5170 us. Best GFLOPs: 110170.7790
2023-05-01 16:59:19 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #112: GFLOPs: 44943.1241. Time: 195811.6657 us. Best GFLOPs: 110170.7790
2023-05-01 16:59:19 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 16:59:20 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 16:59:24 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 400 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:59:27 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 802 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:59:31 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1204 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:59:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1603 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:59:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2001 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:59:42 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2403 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:59:42 [INFO] [evolutionary_search.cc:723] Sampled 57 candidate(s)
2023-05-01 16:59:48 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 101 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 16:59:56 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 78 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:00:03 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 84 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:00:11 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 114 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:00:12 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9400  0.9382  0.9382  0.9254  0.8518  0.8518  0.8518  0.8506  0.8457  0.8372  0.8364  0.8327  0.8301  0.8301  0.8215  0.8009
2023-05-01 17:00:13 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 17:00:13 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 17:07:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #113: GFLOPs: 112165.5610. Time: 78458.9130 us. Best GFLOPs: 112165.5610
2023-05-01 17:07:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #114: GFLOPs: 111626.0806. Time: 78838.0990 us. Best GFLOPs: 112165.5610
2023-05-01 17:07:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #115: GFLOPs: 110350.9528. Time: 79749.0893 us. Best GFLOPs: 112165.5610
2023-05-01 17:07:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #116: GFLOPs: 94829.9608. Time: 92801.7677 us. Best GFLOPs: 112165.5610
2023-05-01 17:07:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #117: GFLOPs: 107708.8978. Time: 81705.3017 us. Best GFLOPs: 112165.5610
2023-05-01 17:07:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #118: GFLOPs: 61616.8158. Time: 142824.4527 us. Best GFLOPs: 112165.5610
2023-05-01 17:07:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #119: GFLOPs: 60817.8445. Time: 144700.7547 us. Best GFLOPs: 112165.5610
2023-05-01 17:07:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #120: GFLOPs: 75889.4720. Time: 115963.2260 us. Best GFLOPs: 112165.5610
2023-05-01 17:07:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #121: GFLOPs: 70530.2054. Time: 124774.7393 us. Best GFLOPs: 112165.5610
2023-05-01 17:07:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #122: GFLOPs: 60782.5962. Time: 144784.6677 us. Best GFLOPs: 112165.5610
2023-05-01 17:07:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #123: GFLOPs: 110702.0091. Time: 79496.1903 us. Best GFLOPs: 112165.5610
2023-05-01 17:07:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #124: GFLOPs: 72153.2489. Time: 121968.0073 us. Best GFLOPs: 112165.5610
2023-05-01 17:07:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #125: GFLOPs: 72320.4553. Time: 121686.0147 us. Best GFLOPs: 112165.5610
2023-05-01 17:07:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #126: GFLOPs: 76270.6764. Time: 115383.6363 us. Best GFLOPs: 112165.5610
2023-05-01 17:07:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #127: GFLOPs: 68109.3787. Time: 129209.6353 us. Best GFLOPs: 112165.5610
2023-05-01 17:07:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #128: GFLOPs: 90674.8135. Time: 97054.3820 us. Best GFLOPs: 112165.5610
2023-05-01 17:07:05 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 17:07:06 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 17:07:09 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 401 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:07:13 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 799 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:07:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1198 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:07:20 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1599 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:07:24 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1997 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:07:24 [INFO] [evolutionary_search.cc:723] Sampled 53 candidate(s)
2023-05-01 17:07:30 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 97 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:07:38 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 93 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:07:46 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 106 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:07:53 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 100 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:07:55 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	1.0045  0.9965  0.9965  0.9854  0.9818  0.9818  0.9685  0.9685  0.9614  0.9566  0.9566  0.9566  0.9485  0.9461  0.9361  0.9361
2023-05-01 17:07:55 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 17:07:55 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 17:14:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #129: GFLOPs: 113390.9771. Time: 77611.0077 us. Best GFLOPs: 113390.9771
2023-05-01 17:14:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #130: GFLOPs: 111371.9616. Time: 79017.9850 us. Best GFLOPs: 113390.9771
2023-05-01 17:14:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #131: GFLOPs: 111352.2436. Time: 79031.9773 us. Best GFLOPs: 113390.9771
2023-05-01 17:14:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #132: GFLOPs: 112741.4282. Time: 78058.1560 us. Best GFLOPs: 113390.9771
2023-05-01 17:14:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #133: GFLOPs: 110964.5331. Time: 79308.1153 us. Best GFLOPs: 113390.9771
2023-05-01 17:14:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #134: GFLOPs: 112273.6157. Time: 78383.4023 us. Best GFLOPs: 113390.9771
2023-05-01 17:14:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #135: GFLOPs: 109021.1007. Time: 80721.8780 us. Best GFLOPs: 113390.9771
2023-05-01 17:14:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #136: GFLOPs: 112208.0784. Time: 78429.1837 us. Best GFLOPs: 113390.9771
2023-05-01 17:14:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #137: GFLOPs: 108568.4477. Time: 81058.4307 us. Best GFLOPs: 113390.9771
2023-05-01 17:14:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #138: GFLOPs: 109197.8893. Time: 80591.1913 us. Best GFLOPs: 113390.9771
2023-05-01 17:14:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #139: GFLOPs: 108663.5648. Time: 80987.4773 us. Best GFLOPs: 113390.9771
2023-05-01 17:14:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #140: GFLOPs: 112243.2511. Time: 78404.6070 us. Best GFLOPs: 113390.9771
2023-05-01 17:14:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #141: GFLOPs: 75883.9335. Time: 115971.6897 us. Best GFLOPs: 113390.9771
2023-05-01 17:14:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #142: GFLOPs: 59910.2740. Time: 146892.8017 us. Best GFLOPs: 113390.9771
2023-05-01 17:14:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #143: GFLOPs: 59406.9697. Time: 148137.2983 us. Best GFLOPs: 113390.9771
2023-05-01 17:14:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #144: GFLOPs: 60082.5560. Time: 146471.5980 us. Best GFLOPs: 113390.9771
2023-05-01 17:14:45 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 17:14:46 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 17:14:50 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 402 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:14:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 803 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:14:57 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1204 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:15:00 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1604 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:15:04 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2001 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:15:08 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2403 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:15:08 [INFO] [evolutionary_search.cc:723] Sampled 57 candidate(s)
2023-05-01 17:15:14 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 99 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:15:22 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 126 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:15:30 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 104 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:15:38 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 110 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:15:40 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	1.0167  1.0167  1.0045  1.0045  1.0045  1.0045  1.0045  0.9965  0.9940  0.9940  0.9939  0.9854  0.9854  0.9818  0.9816  0.9807
2023-05-01 17:15:40 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 17:15:40 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 17:22:32 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #145: GFLOPs: 54242.9647. Time: 162240.1733 us. Best GFLOPs: 113390.9771
2023-05-01 17:22:32 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #146: GFLOPs: 51189.3511. Time: 171918.3347 us. Best GFLOPs: 113390.9771
2023-05-01 17:22:32 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #147: GFLOPs: 112278.4463. Time: 78380.0300 us. Best GFLOPs: 113390.9771
2023-05-01 17:22:32 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #148: GFLOPs: 112241.2922. Time: 78405.9753 us. Best GFLOPs: 113390.9771
2023-05-01 17:22:32 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #149: GFLOPs: 109428.2392. Time: 80421.5443 us. Best GFLOPs: 113390.9771
2023-05-01 17:22:32 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #150: GFLOPs: 109718.3510. Time: 80208.8977 us. Best GFLOPs: 113390.9771
2023-05-01 17:22:32 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #151: GFLOPs: 109030.7258. Time: 80714.7520 us. Best GFLOPs: 113390.9771
2023-05-01 17:22:32 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #152: GFLOPs: 112189.0377. Time: 78442.4947 us. Best GFLOPs: 113390.9771
2023-05-01 17:22:32 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #153: GFLOPs: 52491.1360. Time: 167654.7443 us. Best GFLOPs: 113390.9771
2023-05-01 17:22:32 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #154: GFLOPs: 52287.1856. Time: 168308.6953 us. Best GFLOPs: 113390.9771
2023-05-01 17:22:32 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #155: GFLOPs: 80233.7270. Time: 109684.3973 us. Best GFLOPs: 113390.9771
2023-05-01 17:22:32 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #156: GFLOPs: 108830.1508. Time: 80863.5100 us. Best GFLOPs: 113390.9771
2023-05-01 17:22:32 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #157: GFLOPs: 109837.0774. Time: 80122.1973 us. Best GFLOPs: 113390.9771
2023-05-01 17:22:32 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #158: GFLOPs: 111618.8435. Time: 78843.2107 us. Best GFLOPs: 113390.9771
2023-05-01 17:22:32 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #159: GFLOPs: 77576.0544. Time: 113442.0673 us. Best GFLOPs: 113390.9771
2023-05-01 17:22:32 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #160: GFLOPs: 53628.3931. Time: 164099.4160 us. Best GFLOPs: 113390.9771
2023-05-01 17:22:32 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 17:22:33 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 17:22:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 404 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:22:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 801 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:22:44 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1197 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:22:47 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1599 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:22:51 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1998 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:22:51 [INFO] [evolutionary_search.cc:723] Sampled 52 candidate(s)
2023-05-01 17:22:58 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 106 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:23:06 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 93 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:23:14 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 125 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:23:22 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 116 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:23:24 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	1.0531  0.9880  0.9775  0.9775  0.9774  0.9774  0.9774  0.9694  0.9694  0.9693  0.9693  0.9693  0.9693  0.9641  0.9641  0.9641
2023-05-01 17:23:24 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 17:23:24 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 17:30:14 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #161: GFLOPs: 111863.8784. Time: 78670.5067 us. Best GFLOPs: 113390.9771
2023-05-01 17:30:14 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #162: GFLOPs: 112246.6736. Time: 78402.2163 us. Best GFLOPs: 113390.9771
2023-05-01 17:30:14 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #163: GFLOPs: 112759.2087. Time: 78045.8473 us. Best GFLOPs: 113390.9771
2023-05-01 17:30:14 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #164: GFLOPs: 105041.7238. Time: 83779.9273 us. Best GFLOPs: 113390.9771
2023-05-01 17:30:14 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #165: GFLOPs: 109604.6158. Time: 80292.1293 us. Best GFLOPs: 113390.9771
2023-05-01 17:30:14 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #166: GFLOPs: 112222.7287. Time: 78418.9450 us. Best GFLOPs: 113390.9771
2023-05-01 17:30:14 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #167: GFLOPs: 111227.3609. Time: 79120.7120 us. Best GFLOPs: 113390.9771
2023-05-01 17:30:14 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #168: GFLOPs: 108908.2163. Time: 80805.5470 us. Best GFLOPs: 113390.9771
2023-05-01 17:30:14 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #169: GFLOPs: 109416.7104. Time: 80430.0180 us. Best GFLOPs: 113390.9771
2023-05-01 17:30:14 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #170: GFLOPs: 109694.5336. Time: 80226.3130 us. Best GFLOPs: 113390.9771
2023-05-01 17:30:14 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #171: GFLOPs: 111798.8762. Time: 78716.2473 us. Best GFLOPs: 113390.9771
2023-05-01 17:30:14 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #172: GFLOPs: 111469.1989. Time: 78949.0557 us. Best GFLOPs: 113390.9771
2023-05-01 17:30:14 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #173: GFLOPs: 109837.5444. Time: 80121.8567 us. Best GFLOPs: 113390.9771
2023-05-01 17:30:14 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #174: GFLOPs: 111440.8036. Time: 78969.1720 us. Best GFLOPs: 113390.9771
2023-05-01 17:30:14 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #175: GFLOPs: 110670.1671. Time: 79519.0630 us. Best GFLOPs: 113390.9771
2023-05-01 17:30:14 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #176: GFLOPs: 108421.8506. Time: 81168.0297 us. Best GFLOPs: 113390.9771
2023-05-01 17:30:14 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 17:30:16 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 17:30:19 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 401 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:30:23 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 805 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:30:26 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1207 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:30:30 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1610 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:30:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2010 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:30:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2409 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:30:37 [INFO] [evolutionary_search.cc:723] Sampled 51 candidate(s)
2023-05-01 17:30:44 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 105 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:30:53 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 130 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:31:01 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 121 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:31:09 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 110 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:31:10 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	1.0531  1.0531  1.0531  0.9880  0.9880  0.9880  0.9880  0.9880  0.9880  0.9775  0.9775  0.9775  0.9774  0.9774  0.9774  0.9774
2023-05-01 17:31:11 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 17:31:11 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 17:37:59 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #177: GFLOPs: 112404.8111. Time: 78291.9157 us. Best GFLOPs: 113390.9771
2023-05-01 17:37:59 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #178: GFLOPs: 111342.1404. Time: 79039.1487 us. Best GFLOPs: 113390.9771
2023-05-01 17:37:59 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #179: GFLOPs: 113377.1273. Time: 77620.4883 us. Best GFLOPs: 113390.9771
2023-05-01 17:37:59 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #180: GFLOPs: 112301.9192. Time: 78363.6473 us. Best GFLOPs: 113390.9771
2023-05-01 17:37:59 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #181: GFLOPs: 110530.2055. Time: 79619.7560 us. Best GFLOPs: 113390.9771
2023-05-01 17:37:59 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #182: GFLOPs: 112045.6679. Time: 78542.8670 us. Best GFLOPs: 113390.9771
2023-05-01 17:37:59 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #183: GFLOPs: 111696.2754. Time: 78788.5537 us. Best GFLOPs: 113390.9771
2023-05-01 17:37:59 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #184: GFLOPs: 110635.0247. Time: 79544.3217 us. Best GFLOPs: 113390.9771
2023-05-01 17:37:59 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #185: GFLOPs: 111177.0530. Time: 79156.5143 us. Best GFLOPs: 113390.9771
2023-05-01 17:37:59 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #186: GFLOPs: 109813.6894. Time: 80139.2617 us. Best GFLOPs: 113390.9771
2023-05-01 17:37:59 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #187: GFLOPs: 111914.3464. Time: 78635.0300 us. Best GFLOPs: 113390.9771
2023-05-01 17:37:59 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #188: GFLOPs: 102251.0053. Time: 86066.5180 us. Best GFLOPs: 113390.9771
2023-05-01 17:37:59 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #189: GFLOPs: 109558.4358. Time: 80325.9733 us. Best GFLOPs: 113390.9771
2023-05-01 17:37:59 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #190: GFLOPs: 111652.2283. Time: 78819.6360 us. Best GFLOPs: 113390.9771
2023-05-01 17:37:59 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #191: GFLOPs: 109716.4861. Time: 80210.2610 us. Best GFLOPs: 113390.9771
2023-05-01 17:37:59 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #192: GFLOPs: 111744.6077. Time: 78754.4757 us. Best GFLOPs: 113390.9771
2023-05-01 17:37:59 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 17:38:00 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 17:38:04 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 404 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:38:08 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 810 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:38:11 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1213 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:38:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1616 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:38:18 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2015 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:38:22 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2420 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:38:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2817 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:38:25 [INFO] [evolutionary_search.cc:723] Sampled 53 candidate(s)
2023-05-01 17:38:33 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 114 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:38:41 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 131 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:38:49 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 106 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:38:57 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 133 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:38:59 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	1.0094  0.9958  0.9958  0.9919  0.9919  0.9919  0.9842  0.9816  0.9798  0.9741  0.9741  0.9724  0.9724  0.9724  0.9724  0.9672
2023-05-01 17:38:59 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 17:38:59 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 17:45:50 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #193: GFLOPs: 111397.9476. Time: 78999.5523 us. Best GFLOPs: 113390.9771
2023-05-01 17:45:50 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #194: GFLOPs: 111304.5724. Time: 79065.8263 us. Best GFLOPs: 113390.9771
2023-05-01 17:45:50 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #195: GFLOPs: 113568.7924. Time: 77489.4917 us. Best GFLOPs: 113568.7924
2023-05-01 17:45:50 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #196: GFLOPs: 112608.4790. Time: 78150.3140 us. Best GFLOPs: 113568.7924
2023-05-01 17:45:50 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #197: GFLOPs: 112587.8223. Time: 78164.6523 us. Best GFLOPs: 113568.7924
2023-05-01 17:45:50 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #198: GFLOPs: 109457.5012. Time: 80400.0447 us. Best GFLOPs: 113568.7924
2023-05-01 17:45:50 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #199: GFLOPs: 110203.2750. Time: 79855.9570 us. Best GFLOPs: 113568.7924
2023-05-01 17:45:50 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #200: GFLOPs: 43686.9711. Time: 201441.9350 us. Best GFLOPs: 113568.7924
2023-05-01 17:45:50 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #201: GFLOPs: 109974.8194. Time: 80021.8453 us. Best GFLOPs: 113568.7924
2023-05-01 17:45:50 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #202: GFLOPs: 93435.4323. Time: 94186.8387 us. Best GFLOPs: 113568.7924
2023-05-01 17:45:50 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #203: GFLOPs: 108745.6079. Time: 80926.3763 us. Best GFLOPs: 113568.7924
2023-05-01 17:45:50 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #204: GFLOPs: 94304.8779. Time: 93318.4813 us. Best GFLOPs: 113568.7924
2023-05-01 17:45:50 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #205: GFLOPs: 111341.6601. Time: 79039.4897 us. Best GFLOPs: 113568.7924
2023-05-01 17:45:50 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #206: GFLOPs: 109065.7772. Time: 80688.8120 us. Best GFLOPs: 113568.7924
2023-05-01 17:45:50 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #207: GFLOPs: 109070.8579. Time: 80685.0533 us. Best GFLOPs: 113568.7924
2023-05-01 17:45:50 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #208: GFLOPs: 111786.7630. Time: 78724.7770 us. Best GFLOPs: 113568.7924
2023-05-01 17:45:50 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 17:45:51 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 17:45:55 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 401 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:45:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 799 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:46:02 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1195 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:46:06 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1589 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:46:06 [INFO] [evolutionary_search.cc:723] Sampled 51 candidate(s)
2023-05-01 17:46:13 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 126 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:46:22 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 119 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:46:30 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 117 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:46:38 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 121 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:46:40 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9958  0.9958  0.9958  0.9958  0.9958  0.9919  0.9919  0.9919  0.9854  0.9854  0.9854  0.9854  0.9842  0.9842  0.9798  0.9741
2023-05-01 17:46:40 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 17:46:40 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 17:53:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #209: GFLOPs: 113778.7840. Time: 77346.4760 us. Best GFLOPs: 113778.7840
2023-05-01 17:53:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #210: GFLOPs: 111082.6211. Time: 79223.8057 us. Best GFLOPs: 113778.7840
2023-05-01 17:53:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #211: GFLOPs: 110385.4003. Time: 79724.2023 us. Best GFLOPs: 113778.7840
2023-05-01 17:53:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #212: GFLOPs: 110873.8649. Time: 79372.9703 us. Best GFLOPs: 113778.7840
2023-05-01 17:53:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #213: GFLOPs: 109932.6154. Time: 80052.5663 us. Best GFLOPs: 113778.7840
2023-05-01 17:53:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #214: GFLOPs: 110460.1357. Time: 79670.2623 us. Best GFLOPs: 113778.7840
2023-05-01 17:53:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #215: GFLOPs: 108762.5813. Time: 80913.7470 us. Best GFLOPs: 113778.7840
2023-05-01 17:53:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #216: GFLOPs: 109478.8814. Time: 80384.3433 us. Best GFLOPs: 113778.7840
2023-05-01 17:53:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #217: GFLOPs: 102565.8425. Time: 85802.3273 us. Best GFLOPs: 113778.7840
2023-05-01 17:53:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #218: GFLOPs: 112532.7854. Time: 78202.8807 us. Best GFLOPs: 113778.7840
2023-05-01 17:53:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #219: GFLOPs: 96582.7842. Time: 91117.5637 us. Best GFLOPs: 113778.7840
2023-05-01 17:53:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #220: GFLOPs: 107687.7544. Time: 81721.3437 us. Best GFLOPs: 113778.7840
2023-05-01 17:53:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #221: GFLOPs: 110401.4736. Time: 79712.5953 us. Best GFLOPs: 113778.7840
2023-05-01 17:53:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #222: GFLOPs: 111677.3291. Time: 78801.9203 us. Best GFLOPs: 113778.7840
2023-05-01 17:53:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #223: GFLOPs: 110195.2668. Time: 79861.7603 us. Best GFLOPs: 113778.7840
2023-05-01 17:53:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #224: GFLOPs: 106772.1901. Time: 82422.0987 us. Best GFLOPs: 113778.7840
2023-05-01 17:53:29 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 17:53:30 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 17:53:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 404 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:53:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 806 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:53:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1207 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:53:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1605 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:53:48 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2009 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:53:52 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2408 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:53:52 [INFO] [evolutionary_search.cc:723] Sampled 52 candidate(s)
2023-05-01 17:53:59 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 139 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:54:08 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 148 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:54:16 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 108 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:54:24 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 114 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 17:54:26 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	1.0094  0.9958  0.9958  0.9958  0.9919  0.9919  0.9919  0.9919  0.9919  0.9919  0.9919  0.9919  0.9919  0.9872  0.9854  0.9854
2023-05-01 17:54:26 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 17:54:26 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 18:01:17 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #225: GFLOPs: 111644.4477. Time: 78825.1290 us. Best GFLOPs: 113778.7840
2023-05-01 18:01:17 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #226: GFLOPs: 113931.6298. Time: 77242.7113 us. Best GFLOPs: 113931.6298
2023-05-01 18:01:17 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #227: GFLOPs: 109816.9581. Time: 80136.8763 us. Best GFLOPs: 113931.6298
2023-05-01 18:01:17 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #228: GFLOPs: 110734.3377. Time: 79472.9817 us. Best GFLOPs: 113931.6298
2023-05-01 18:01:17 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #229: GFLOPs: 109980.9153. Time: 80017.4100 us. Best GFLOPs: 113931.6298
2023-05-01 18:01:17 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #230: GFLOPs: 109807.1385. Time: 80144.0427 us. Best GFLOPs: 113931.6298
2023-05-01 18:01:17 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #231: GFLOPs: 109894.6594. Time: 80080.2153 us. Best GFLOPs: 113931.6298
2023-05-01 18:01:17 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #232: GFLOPs: 109451.9275. Time: 80404.1390 us. Best GFLOPs: 113931.6298
2023-05-01 18:01:17 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #233: GFLOPs: 109328.4702. Time: 80494.9340 us. Best GFLOPs: 113931.6298
2023-05-01 18:01:17 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #234: GFLOPs: 109378.5637. Time: 80458.0687 us. Best GFLOPs: 113931.6298
2023-05-01 18:01:17 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #235: GFLOPs: 109800.1211. Time: 80149.1647 us. Best GFLOPs: 113931.6298
2023-05-01 18:01:17 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #236: GFLOPs: 110064.9605. Time: 79956.3090 us. Best GFLOPs: 113931.6298
2023-05-01 18:01:17 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #237: GFLOPs: 109969.7168. Time: 80025.5583 us. Best GFLOPs: 113931.6298
2023-05-01 18:01:17 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #238: GFLOPs: 63488.4018. Time: 138614.1050 us. Best GFLOPs: 113931.6298
2023-05-01 18:01:17 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #239: GFLOPs: 109520.2733. Time: 80353.9630 us. Best GFLOPs: 113931.6298
2023-05-01 18:01:17 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #240: GFLOPs: 110931.5862. Time: 79331.6700 us. Best GFLOPs: 113931.6298
2023-05-01 18:01:17 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 18:01:18 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 18:01:22 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 396 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:01:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 799 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:01:29 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1202 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:01:33 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1601 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:01:36 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1995 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:01:36 [INFO] [evolutionary_search.cc:723] Sampled 55 candidate(s)
2023-05-01 18:01:44 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 135 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:01:52 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 118 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:02:00 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 120 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:02:09 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 124 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:02:10 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9954  0.9954  0.9954  0.9954  0.9954  0.9954  0.9836  0.9836  0.9836  0.9836  0.9822  0.9822  0.9822  0.9822  0.9822  0.9822
2023-05-01 18:02:11 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 18:02:11 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 18:09:00 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #241: GFLOPs: 111115.6503. Time: 79200.2563 us. Best GFLOPs: 113931.6298
2023-05-01 18:09:00 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #242: GFLOPs: 110951.6395. Time: 79317.3317 us. Best GFLOPs: 113931.6298
2023-05-01 18:09:00 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #243: GFLOPs: 111053.9095. Time: 79244.2880 us. Best GFLOPs: 113931.6298
2023-05-01 18:09:00 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #244: GFLOPs: 110022.7506. Time: 79986.9840 us. Best GFLOPs: 113931.6298
2023-05-01 18:09:00 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #245: GFLOPs: 110524.0490. Time: 79624.1910 us. Best GFLOPs: 113931.6298
2023-05-01 18:09:00 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #246: GFLOPs: 110472.9010. Time: 79661.0563 us. Best GFLOPs: 113931.6298
2023-05-01 18:09:00 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #247: GFLOPs: 108604.5177. Time: 81031.5093 us. Best GFLOPs: 113931.6298
2023-05-01 18:09:00 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #248: GFLOPs: 110468.2388. Time: 79664.4183 us. Best GFLOPs: 113931.6298
2023-05-01 18:09:00 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #249: GFLOPs: 108920.1801. Time: 80796.6713 us. Best GFLOPs: 113931.6298
2023-05-01 18:09:00 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #250: GFLOPs: 108262.0319. Time: 81287.8517 us. Best GFLOPs: 113931.6298
2023-05-01 18:09:00 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #251: GFLOPs: 109178.4716. Time: 80605.5247 us. Best GFLOPs: 113931.6298
2023-05-01 18:09:00 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #252: GFLOPs: 109777.6819. Time: 80165.5477 us. Best GFLOPs: 113931.6298
2023-05-01 18:09:00 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #253: GFLOPs: 109449.1374. Time: 80406.1887 us. Best GFLOPs: 113931.6298
2023-05-01 18:09:00 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #254: GFLOPs: 108582.1080. Time: 81048.2330 us. Best GFLOPs: 113931.6298
2023-05-01 18:09:00 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #255: GFLOPs: 109036.7174. Time: 80710.3167 us. Best GFLOPs: 113931.6298
2023-05-01 18:09:00 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #256: GFLOPs: 109202.5759. Time: 80587.7327 us. Best GFLOPs: 113931.6298
2023-05-01 18:09:00 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 18:09:02 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 18:09:05 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 399 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:09:09 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 801 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:09:12 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1199 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:09:16 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1606 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:09:20 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2006 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:09:23 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2405 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:09:23 [INFO] [evolutionary_search.cc:723] Sampled 55 candidate(s)
2023-05-01 18:09:31 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 139 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:09:39 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 121 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:09:47 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 124 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:09:56 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 115 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:09:57 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9954  0.9836  0.9836  0.9836  0.9836  0.9836  0.9836  0.9836  0.9836  0.9822  0.9822  0.9822  0.9822  0.9822  0.9822  0.9822
2023-05-01 18:09:58 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 18:09:58 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 18:16:47 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #257: GFLOPs: 111140.5605. Time: 79182.5050 us. Best GFLOPs: 113931.6298
2023-05-01 18:16:47 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #258: GFLOPs: 110426.0572. Time: 79694.8493 us. Best GFLOPs: 113931.6298
2023-05-01 18:16:47 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #259: GFLOPs: 110092.2177. Time: 79936.5130 us. Best GFLOPs: 113931.6298
2023-05-01 18:16:47 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #260: GFLOPs: 112837.1498. Time: 77991.9380 us. Best GFLOPs: 113931.6298
2023-05-01 18:16:47 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #261: GFLOPs: 109496.0845. Time: 80371.7140 us. Best GFLOPs: 113931.6298
2023-05-01 18:16:47 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #262: GFLOPs: 108321.1608. Time: 81243.4793 us. Best GFLOPs: 113931.6298
2023-05-01 18:16:47 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #263: GFLOPs: 109571.0076. Time: 80316.7570 us. Best GFLOPs: 113931.6298
2023-05-01 18:16:47 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #264: GFLOPs: 110145.8673. Time: 79897.5777 us. Best GFLOPs: 113931.6298
2023-05-01 18:16:47 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #265: GFLOPs: 111821.1809. Time: 78700.5460 us. Best GFLOPs: 113931.6298
2023-05-01 18:16:47 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #266: GFLOPs: 108773.5899. Time: 80905.5580 us. Best GFLOPs: 113931.6298
2023-05-01 18:16:47 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #267: GFLOPs: 112060.2615. Time: 78532.6383 us. Best GFLOPs: 113931.6298
2023-05-01 18:16:47 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #268: GFLOPs: 109801.5285. Time: 80148.1373 us. Best GFLOPs: 113931.6298
2023-05-01 18:16:47 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #269: GFLOPs: 111835.7374. Time: 78690.3023 us. Best GFLOPs: 113931.6298
2023-05-01 18:16:47 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #270: GFLOPs: 112208.0784. Time: 78429.1837 us. Best GFLOPs: 113931.6298
2023-05-01 18:16:47 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #271: GFLOPs: 108510.3615. Time: 81101.8217 us. Best GFLOPs: 113931.6298
2023-05-01 18:16:47 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #272: GFLOPs: 108857.1764. Time: 80843.4343 us. Best GFLOPs: 113931.6298
2023-05-01 18:16:47 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 18:16:48 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 18:16:52 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 396 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:16:55 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 797 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:16:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1196 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:17:03 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1596 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:17:06 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1995 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:17:06 [INFO] [evolutionary_search.cc:723] Sampled 55 candidate(s)
2023-05-01 18:17:14 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 136 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:17:22 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 103 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:17:30 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 126 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:17:39 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 129 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:17:40 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9954  0.9954  0.9954  0.9836  0.9822  0.9822  0.9822  0.9822  0.9822  0.9822  0.9752  0.9687  0.9687  0.9687  0.9687  0.9687
2023-05-01 18:17:40 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 18:17:41 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 18:24:31 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #273: GFLOPs: 111451.3989. Time: 78961.6647 us. Best GFLOPs: 113931.6298
2023-05-01 18:24:31 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #274: GFLOPs: 110869.0976. Time: 79376.3833 us. Best GFLOPs: 113931.6298
2023-05-01 18:24:31 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #275: GFLOPs: 110501.3129. Time: 79640.5740 us. Best GFLOPs: 113931.6298
2023-05-01 18:24:31 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #276: GFLOPs: 110545.8479. Time: 79608.4897 us. Best GFLOPs: 113931.6298
2023-05-01 18:24:31 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #277: GFLOPs: 109464.0105. Time: 80395.2637 us. Best GFLOPs: 113931.6298
2023-05-01 18:24:31 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #278: GFLOPs: 108553.3464. Time: 81069.7070 us. Best GFLOPs: 113931.6298
2023-05-01 18:24:31 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #279: GFLOPs: 110008.1373. Time: 79997.6093 us. Best GFLOPs: 113931.6298
2023-05-01 18:24:31 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #280: GFLOPs: 112271.1096. Time: 78385.1520 us. Best GFLOPs: 113931.6298
2023-05-01 18:24:31 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #281: GFLOPs: 108688.7594. Time: 80968.7040 us. Best GFLOPs: 113931.6298
2023-05-01 18:24:31 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #282: GFLOPs: 108813.9434. Time: 80875.5543 us. Best GFLOPs: 113931.6298
2023-05-01 18:24:31 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #283: GFLOPs: 111711.6867. Time: 78777.6843 us. Best GFLOPs: 113931.6298
2023-05-01 18:24:31 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #284: GFLOPs: 110087.5173. Time: 79939.9260 us. Best GFLOPs: 113931.6298
2023-05-01 18:24:31 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #285: GFLOPs: 109990.7733. Time: 80010.2383 us. Best GFLOPs: 113931.6298
2023-05-01 18:24:31 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #286: GFLOPs: 108594.9137. Time: 81038.6757 us. Best GFLOPs: 113931.6298
2023-05-01 18:24:31 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #287: GFLOPs: 112552.4406. Time: 78189.2240 us. Best GFLOPs: 113931.6298
2023-05-01 18:24:31 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #288: GFLOPs: 108600.8571. Time: 81034.2407 us. Best GFLOPs: 113931.6298
2023-05-01 18:24:31 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 18:24:32 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 18:24:36 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 399 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:24:39 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 797 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:24:43 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1193 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:24:46 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1587 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:24:46 [INFO] [evolutionary_search.cc:723] Sampled 53 candidate(s)
2023-05-01 18:24:54 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 123 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:25:02 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 107 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:25:10 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 133 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:25:19 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 117 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:25:21 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9796  0.9796  0.9733  0.9733  0.9733  0.9733  0.9671  0.9671  0.9671  0.9671  0.9671  0.9671  0.9652  0.9652  0.9630  0.9630
2023-05-01 18:25:21 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 18:25:21 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 18:32:11 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #289: GFLOPs: 110500.3602. Time: 79641.2607 us. Best GFLOPs: 113931.6298
2023-05-01 18:32:11 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #290: GFLOPs: 110223.0658. Time: 79841.6187 us. Best GFLOPs: 113931.6298
2023-05-01 18:32:11 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #291: GFLOPs: 111828.9430. Time: 78695.0833 us. Best GFLOPs: 113931.6298
2023-05-01 18:32:11 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #292: GFLOPs: 110580.4594. Time: 79583.5723 us. Best GFLOPs: 113931.6298
2023-05-01 18:32:11 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #293: GFLOPs: 110032.5460. Time: 79979.8633 us. Best GFLOPs: 113931.6298
2023-05-01 18:32:11 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #294: GFLOPs: 109077.7751. Time: 80679.9367 us. Best GFLOPs: 113931.6298
2023-05-01 18:32:11 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #295: GFLOPs: 109031.1859. Time: 80714.4113 us. Best GFLOPs: 113931.6298
2023-05-01 18:32:11 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #296: GFLOPs: 109794.5124. Time: 80153.2590 us. Best GFLOPs: 113931.6298
2023-05-01 18:32:11 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #297: GFLOPs: 111503.4573. Time: 78924.7993 us. Best GFLOPs: 113931.6298
2023-05-01 18:32:11 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #298: GFLOPs: 109065.3302. Time: 80689.1427 us. Best GFLOPs: 113931.6298
2023-05-01 18:32:11 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #299: GFLOPs: 112405.7165. Time: 78291.2850 us. Best GFLOPs: 113931.6298
2023-05-01 18:32:11 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #300: GFLOPs: 112409.1490. Time: 78288.8943 us. Best GFLOPs: 113931.6298
2023-05-01 18:32:11 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #301: GFLOPs: 110862.8959. Time: 79380.8237 us. Best GFLOPs: 113931.6298
2023-05-01 18:32:11 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #302: GFLOPs: 98417.7009. Time: 89418.7520 us. Best GFLOPs: 113931.6298
2023-05-01 18:32:11 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #303: GFLOPs: 110044.2888. Time: 79971.3287 us. Best GFLOPs: 113931.6298
2023-05-01 18:32:11 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #304: GFLOPs: 112989.9536. Time: 77886.4643 us. Best GFLOPs: 113931.6298
2023-05-01 18:32:11 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 18:32:12 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 18:32:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 403 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:32:19 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 802 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:32:23 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1204 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:32:26 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1602 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:32:30 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2001 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:32:33 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2402 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:32:33 [INFO] [evolutionary_search.cc:723] Sampled 58 candidate(s)
2023-05-01 18:32:41 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 136 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:32:49 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 119 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:32:58 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 128 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:33:06 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 113 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:33:08 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9796  0.9733  0.9733  0.9671  0.9671  0.9671  0.9671  0.9671  0.9652  0.9652  0.9630  0.9630  0.9630  0.9630  0.9630  0.9630
2023-05-01 18:33:08 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 18:33:08 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 18:39:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #305: GFLOPs: 111343.5233. Time: 79038.1670 us. Best GFLOPs: 113931.6298
2023-05-01 18:39:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #306: GFLOPs: 111166.4382. Time: 79164.0727 us. Best GFLOPs: 113931.6298
2023-05-01 18:39:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #307: GFLOPs: 111050.5593. Time: 79246.6787 us. Best GFLOPs: 113931.6298
2023-05-01 18:39:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #308: GFLOPs: 110033.0220. Time: 79979.5173 us. Best GFLOPs: 113931.6298
2023-05-01 18:39:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #309: GFLOPs: 110648.7931. Time: 79534.4237 us. Best GFLOPs: 113931.6298
2023-05-01 18:39:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #310: GFLOPs: 109251.5671. Time: 80551.5950 us. Best GFLOPs: 113931.6298
2023-05-01 18:39:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #311: GFLOPs: 110087.5173. Time: 79939.9260 us. Best GFLOPs: 113931.6298
2023-05-01 18:39:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #312: GFLOPs: 109171.9963. Time: 80610.3057 us. Best GFLOPs: 113931.6298
2023-05-01 18:39:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #313: GFLOPs: 111652.2571. Time: 78819.6157 us. Best GFLOPs: 113931.6298
2023-05-01 18:39:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #314: GFLOPs: 107724.2006. Time: 81693.6950 us. Best GFLOPs: 113931.6298
2023-05-01 18:39:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #315: GFLOPs: 108861.3130. Time: 80840.3623 us. Best GFLOPs: 113931.6298
2023-05-01 18:39:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #316: GFLOPs: 109654.8931. Time: 80255.3150 us. Best GFLOPs: 113931.6298
2023-05-01 18:39:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #317: GFLOPs: 108998.4913. Time: 80738.6220 us. Best GFLOPs: 113931.6298
2023-05-01 18:39:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #318: GFLOPs: 112465.0443. Time: 78249.9847 us. Best GFLOPs: 113931.6298
2023-05-01 18:39:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #319: GFLOPs: 112308.2758. Time: 78359.2120 us. Best GFLOPs: 113931.6298
2023-05-01 18:39:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #320: GFLOPs: 109323.3722. Time: 80498.6877 us. Best GFLOPs: 113931.6298
2023-05-01 18:39:57 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 18:39:58 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 18:40:02 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 402 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:40:06 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 801 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:40:09 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1199 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:40:13 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1601 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:40:16 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1996 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:40:16 [INFO] [evolutionary_search.cc:723] Sampled 54 candidate(s)
2023-05-01 18:40:24 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 142 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:40:32 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 121 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:40:40 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 115 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:40:48 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 106 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:40:50 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9733  0.9671  0.9652  0.9630  0.9630  0.9630  0.9616  0.9616  0.9616  0.9616  0.9591  0.9588  0.9588  0.9576  0.9576  0.9576
2023-05-01 18:40:50 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 18:40:50 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 18:47:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #321: GFLOPs: 113340.1341. Time: 77645.8230 us. Best GFLOPs: 113931.6298
2023-05-01 18:47:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #322: GFLOPs: 111190.4065. Time: 79147.0080 us. Best GFLOPs: 113931.6298
2023-05-01 18:47:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #323: GFLOPs: 108677.8499. Time: 80976.8320 us. Best GFLOPs: 113931.6298
2023-05-01 18:47:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #324: GFLOPs: 113432.8818. Time: 77582.3363 us. Best GFLOPs: 113931.6298
2023-05-01 18:47:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #325: GFLOPs: 111163.5600. Time: 79166.1223 us. Best GFLOPs: 113931.6298
2023-05-01 18:47:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #326: GFLOPs: 110777.6351. Time: 79441.9197 us. Best GFLOPs: 113931.6298
2023-05-01 18:47:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #327: GFLOPs: 108546.9039. Time: 81074.5187 us. Best GFLOPs: 113931.6298
2023-05-01 18:47:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #328: GFLOPs: 108653.0354. Time: 80995.3257 us. Best GFLOPs: 113931.6298
2023-05-01 18:47:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #329: GFLOPs: 108637.0103. Time: 81007.2733 us. Best GFLOPs: 113931.6298
2023-05-01 18:47:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #330: GFLOPs: 89570.3312. Time: 98251.1493 us. Best GFLOPs: 113931.6298
2023-05-01 18:47:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #331: GFLOPs: 109751.9799. Time: 80184.3210 us. Best GFLOPs: 113931.6298
2023-05-01 18:47:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #332: GFLOPs: 110586.1492. Time: 79579.4777 us. Best GFLOPs: 113931.6298
2023-05-01 18:47:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #333: GFLOPs: 112031.1365. Time: 78553.0547 us. Best GFLOPs: 113931.6298
2023-05-01 18:47:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #334: GFLOPs: 111589.3574. Time: 78864.0440 us. Best GFLOPs: 113931.6298
2023-05-01 18:47:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #335: GFLOPs: 90778.6192. Time: 96943.4000 us. Best GFLOPs: 113931.6298
2023-05-01 18:47:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #336: GFLOPs: 109874.0864. Time: 80095.2097 us. Best GFLOPs: 113931.6298
2023-05-01 18:47:40 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 18:47:41 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 18:47:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 395 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:47:48 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 794 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:47:52 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1190 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:47:55 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1595 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:47:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1995 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:47:59 [INFO] [evolutionary_search.cc:723] Sampled 55 candidate(s)
2023-05-01 18:48:06 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 139 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:48:15 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 150 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:48:23 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 126 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:48:32 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 119 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:48:33 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9796  0.9796  0.9747  0.9652  0.9630  0.9630  0.9630  0.9630  0.9630  0.9616  0.9616  0.9616  0.9616  0.9591  0.9588  0.9588
2023-05-01 18:48:34 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 18:48:34 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 18:55:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #337: GFLOPs: 110732.9982. Time: 79473.9430 us. Best GFLOPs: 113931.6298
2023-05-01 18:55:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #338: GFLOPs: 110089.8851. Time: 79938.2067 us. Best GFLOPs: 113931.6298
2023-05-01 18:55:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #339: GFLOPs: 109437.9916. Time: 80414.3777 us. Best GFLOPs: 113931.6298
2023-05-01 18:55:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #340: GFLOPs: 112221.7532. Time: 78419.6267 us. Best GFLOPs: 113931.6298
2023-05-01 18:55:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #341: GFLOPs: 110240.9741. Time: 79828.6487 us. Best GFLOPs: 113931.6298
2023-05-01 18:55:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #342: GFLOPs: 112586.4304. Time: 78165.6187 us. Best GFLOPs: 113931.6298
2023-05-01 18:55:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #343: GFLOPs: 110166.0719. Time: 79882.9243 us. Best GFLOPs: 113931.6298
2023-05-01 18:55:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #344: GFLOPs: 109829.1224. Time: 80128.0007 us. Best GFLOPs: 113931.6298
2023-05-01 18:55:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #345: GFLOPs: 111207.3151. Time: 79134.9740 us. Best GFLOPs: 113931.6298
2023-05-01 18:55:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #346: GFLOPs: 111790.6416. Time: 78722.0457 us. Best GFLOPs: 113931.6298
2023-05-01 18:55:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #347: GFLOPs: 112110.4928. Time: 78497.4517 us. Best GFLOPs: 113931.6298
2023-05-01 18:55:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #348: GFLOPs: 90518.5069. Time: 97221.9747 us. Best GFLOPs: 113931.6298
2023-05-01 18:55:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #349: GFLOPs: 109941.0676. Time: 80046.4120 us. Best GFLOPs: 113931.6298
2023-05-01 18:55:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #350: GFLOPs: 97026.9392. Time: 90700.4597 us. Best GFLOPs: 113931.6298
2023-05-01 18:55:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #351: GFLOPs: 109159.9843. Time: 80619.1760 us. Best GFLOPs: 113931.6298
2023-05-01 18:55:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #352: GFLOPs: 111205.7571. Time: 79136.0827 us. Best GFLOPs: 113931.6298
2023-05-01 18:55:24 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 18:55:25 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 18:55:29 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 399 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:55:32 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 799 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:55:36 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1200 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:55:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1599 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:55:43 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1999 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:55:43 [INFO] [evolutionary_search.cc:723] Sampled 51 candidate(s)
2023-05-01 18:55:51 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 141 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:55:59 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 120 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:56:07 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 124 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:56:16 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 98 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 18:56:17 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9691  0.9645  0.9645  0.9645  0.9645  0.9645  0.9627  0.9627  0.9627  0.9627  0.9535  0.9514  0.9514  0.9514  0.9497  0.9497
2023-05-01 18:56:17 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 18:56:17 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 19:03:06 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #353: GFLOPs: 112230.5467. Time: 78413.4823 us. Best GFLOPs: 113931.6298
2023-05-01 19:03:06 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #354: GFLOPs: 111204.3130. Time: 79137.1103 us. Best GFLOPs: 113931.6298
2023-05-01 19:03:06 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #355: GFLOPs: 110608.9197. Time: 79563.0950 us. Best GFLOPs: 113931.6298
2023-05-01 19:03:06 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #356: GFLOPs: 109688.0106. Time: 80231.0840 us. Best GFLOPs: 113931.6298
2023-05-01 19:03:06 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #357: GFLOPs: 110131.3265. Time: 79908.1267 us. Best GFLOPs: 113931.6298
2023-05-01 19:03:06 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #358: GFLOPs: 109411.1131. Time: 80434.1327 us. Best GFLOPs: 113931.6298
2023-05-01 19:03:06 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #359: GFLOPs: 111525.6442. Time: 78909.0980 us. Best GFLOPs: 113931.6298
2023-05-01 19:03:06 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #360: GFLOPs: 109979.5239. Time: 80018.4223 us. Best GFLOPs: 113931.6298
2023-05-01 19:03:06 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #361: GFLOPs: 110439.7593. Time: 79684.9617 us. Best GFLOPs: 113931.6298
2023-05-01 19:03:06 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #362: GFLOPs: 110245.6871. Time: 79825.2360 us. Best GFLOPs: 113931.6298
2023-05-01 19:03:06 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #363: GFLOPs: 104145.5944. Time: 84500.8187 us. Best GFLOPs: 113931.6298
2023-05-01 19:03:06 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #364: GFLOPs: 108995.2370. Time: 80741.0327 us. Best GFLOPs: 113931.6298
2023-05-01 19:03:06 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #365: GFLOPs: 111998.9672. Time: 78575.6173 us. Best GFLOPs: 113931.6298
2023-05-01 19:03:06 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #366: GFLOPs: 111366.2484. Time: 79022.0387 us. Best GFLOPs: 113931.6298
2023-05-01 19:03:06 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #367: GFLOPs: 110985.5450. Time: 79293.1007 us. Best GFLOPs: 113931.6298
2023-05-01 19:03:06 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #368: GFLOPs: 96464.2556. Time: 91229.5227 us. Best GFLOPs: 113931.6298
2023-05-01 19:03:06 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 19:03:08 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 19:03:11 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 402 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:03:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 803 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:03:18 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1208 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:03:22 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1610 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:03:26 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2004 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:03:29 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2408 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:03:29 [INFO] [evolutionary_search.cc:723] Sampled 52 candidate(s)
2023-05-01 19:03:37 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 133 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:03:45 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 120 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:03:53 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 95 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:04:01 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 109 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:04:03 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9735  0.9691  0.9683  0.9645  0.9645  0.9627  0.9570  0.9535  0.9535  0.9535  0.9497  0.9497  0.9464  0.9464  0.9464  0.9464
2023-05-01 19:04:03 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 19:04:03 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 19:10:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #369: GFLOPs: 111975.6208. Time: 78592.0000 us. Best GFLOPs: 113931.6298
2023-05-01 19:10:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #370: GFLOPs: 111761.5628. Time: 78742.5280 us. Best GFLOPs: 113931.6298
2023-05-01 19:10:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #371: GFLOPs: 110785.7282. Time: 79436.1163 us. Best GFLOPs: 113931.6298
2023-05-01 19:10:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #372: GFLOPs: 110708.1859. Time: 79491.7550 us. Best GFLOPs: 113931.6298
2023-05-01 19:10:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #373: GFLOPs: 110008.6057. Time: 79997.2687 us. Best GFLOPs: 113931.6298
2023-05-01 19:10:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #374: GFLOPs: 112224.2132. Time: 78417.9077 us. Best GFLOPs: 113931.6298
2023-05-01 19:10:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #375: GFLOPs: 109794.5124. Time: 80153.2590 us. Best GFLOPs: 113931.6298
2023-05-01 19:10:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #376: GFLOPs: 103850.6863. Time: 84740.7783 us. Best GFLOPs: 113931.6298
2023-05-01 19:10:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #377: GFLOPs: 102571.5822. Time: 85797.5260 us. Best GFLOPs: 113931.6298
2023-05-01 19:10:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #378: GFLOPs: 101101.8473. Time: 87044.7793 us. Best GFLOPs: 113931.6298
2023-05-01 19:10:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #379: GFLOPs: 109975.7562. Time: 80021.1637 us. Best GFLOPs: 113931.6298
2023-05-01 19:10:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #380: GFLOPs: 112089.5540. Time: 78512.1153 us. Best GFLOPs: 113931.6298
2023-05-01 19:10:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #381: GFLOPs: 111954.7105. Time: 78606.6790 us. Best GFLOPs: 113931.6298
2023-05-01 19:10:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #382: GFLOPs: 111783.3684. Time: 78727.1677 us. Best GFLOPs: 113931.6298
2023-05-01 19:10:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #383: GFLOPs: 112166.5860. Time: 78458.1960 us. Best GFLOPs: 113931.6298
2023-05-01 19:10:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #384: GFLOPs: 88991.0154. Time: 98890.7470 us. Best GFLOPs: 113931.6298
2023-05-01 19:10:53 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 19:10:54 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 19:10:58 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 404 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:11:01 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 805 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:11:05 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1208 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:11:09 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1602 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:11:12 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1999 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:11:12 [INFO] [evolutionary_search.cc:723] Sampled 51 candidate(s)
2023-05-01 19:11:20 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 140 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:11:28 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 122 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:11:36 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 134 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:11:45 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 118 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:11:47 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9775  0.9735  0.9683  0.9645  0.9645  0.9622  0.9535  0.9535  0.9514  0.9497  0.9497  0.9497  0.9464  0.9450  0.9423  0.9423
2023-05-01 19:11:47 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 19:11:47 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 19:18:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #385: GFLOPs: 111529.0227. Time: 78906.7077 us. Best GFLOPs: 113931.6298
2023-05-01 19:18:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #386: GFLOPs: 93388.7327. Time: 94233.9373 us. Best GFLOPs: 113931.6298
2023-05-01 19:18:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #387: GFLOPs: 109594.2923. Time: 80299.6927 us. Best GFLOPs: 113931.6298
2023-05-01 19:18:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #388: GFLOPs: 110285.7702. Time: 79796.2237 us. Best GFLOPs: 113931.6298
2023-05-01 19:18:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #389: GFLOPs: 109353.0483. Time: 80476.8420 us. Best GFLOPs: 113931.6298
2023-05-01 19:18:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #390: GFLOPs: 104501.8628. Time: 84212.7380 us. Best GFLOPs: 113931.6298
2023-05-01 19:18:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #391: GFLOPs: 103908.0265. Time: 84694.0153 us. Best GFLOPs: 113931.6298
2023-05-01 19:18:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #392: GFLOPs: 102833.7679. Time: 85578.7760 us. Best GFLOPs: 113931.6298
2023-05-01 19:18:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #393: GFLOPs: 109508.1774. Time: 80362.8387 us. Best GFLOPs: 113931.6298
2023-05-01 19:18:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #394: GFLOPs: 110058.3795. Time: 79961.0900 us. Best GFLOPs: 113931.6298
2023-05-01 19:18:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #395: GFLOPs: 92045.7605. Time: 95608.8357 us. Best GFLOPs: 113931.6298
2023-05-01 19:18:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #396: GFLOPs: 112200.7656. Time: 78434.2953 us. Best GFLOPs: 113931.6298
2023-05-01 19:18:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #397: GFLOPs: 111626.0806. Time: 78838.0990 us. Best GFLOPs: 113931.6298
2023-05-01 19:18:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #398: GFLOPs: 69065.5766. Time: 127420.7560 us. Best GFLOPs: 113931.6298
2023-05-01 19:18:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #399: GFLOPs: 112357.7083. Time: 78324.7373 us. Best GFLOPs: 113931.6298
2023-05-01 19:18:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #400: GFLOPs: 112546.0492. Time: 78193.6643 us. Best GFLOPs: 113931.6298
2023-05-01 19:18:37 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 19:18:39 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 19:18:42 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 401 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:18:46 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 801 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:18:49 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1200 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:18:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1594 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:18:56 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2000 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:18:56 [INFO] [evolutionary_search.cc:723] Sampled 50 candidate(s)
2023-05-01 19:19:04 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 127 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:19:12 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 118 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:19:21 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 132 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:19:29 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 119 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:19:31 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9645  0.9645  0.9622  0.9570  0.9535  0.9514  0.9514  0.9514  0.9497  0.9497  0.9464  0.9464  0.9464  0.9464  0.9464  0.9464
2023-05-01 19:19:31 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 19:19:31 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 19:26:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #401: GFLOPs: 110882.4479. Time: 79366.8263 us. Best GFLOPs: 113931.6298
2023-05-01 19:26:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #402: GFLOPs: 111248.0716. Time: 79105.9823 us. Best GFLOPs: 113931.6298
2023-05-01 19:26:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #403: GFLOPs: 112264.7572. Time: 78389.5873 us. Best GFLOPs: 113931.6298
2023-05-01 19:26:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #404: GFLOPs: 109550.9856. Time: 80331.4360 us. Best GFLOPs: 113931.6298
2023-05-01 19:26:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #405: GFLOPs: 103532.4960. Time: 85001.2153 us. Best GFLOPs: 113931.6298
2023-05-01 19:26:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #406: GFLOPs: 91566.8498. Time: 96108.8867 us. Best GFLOPs: 113931.6298
2023-05-01 19:26:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #407: GFLOPs: 94091.8949. Time: 93529.7137 us. Best GFLOPs: 113931.6298
2023-05-01 19:26:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #408: GFLOPs: 111833.3375. Time: 78691.9910 us. Best GFLOPs: 113931.6298
2023-05-01 19:26:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #409: GFLOPs: 93079.8988. Time: 94546.6003 us. Best GFLOPs: 113931.6298
2023-05-01 19:26:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #410: GFLOPs: 106819.0777. Time: 82385.9200 us. Best GFLOPs: 113931.6298
2023-05-01 19:26:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #411: GFLOPs: 103957.7907. Time: 84653.4727 us. Best GFLOPs: 113931.6298
2023-05-01 19:26:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #412: GFLOPs: 90365.2683. Time: 97386.8407 us. Best GFLOPs: 113931.6298
2023-05-01 19:26:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #413: GFLOPs: 109186.3332. Time: 80599.7210 us. Best GFLOPs: 113931.6298
2023-05-01 19:26:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #414: GFLOPs: 107990.4986. Time: 81492.2433 us. Best GFLOPs: 113931.6298
2023-05-01 19:26:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #415: GFLOPs: 108401.7777. Time: 81183.0597 us. Best GFLOPs: 113931.6298
2023-05-01 19:26:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #416: GFLOPs: 111895.9193. Time: 78647.9797 us. Best GFLOPs: 113931.6298
2023-05-01 19:26:22 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 19:26:23 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 19:26:27 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 395 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:26:31 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 796 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:26:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1191 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:26:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1595 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:26:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1998 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:26:41 [INFO] [evolutionary_search.cc:723] Sampled 52 candidate(s)
2023-05-01 19:26:49 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 125 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:26:57 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 133 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:27:06 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 146 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:27:14 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 123 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:27:16 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9735  0.9691  0.9645  0.9645  0.9627  0.9627  0.9514  0.9464  0.9464  0.9423  0.9423  0.9423  0.9423  0.9423  0.9423  0.9423
2023-05-01 19:27:16 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 19:27:16 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 19:34:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #417: GFLOPs: 111413.8361. Time: 78988.2863 us. Best GFLOPs: 113931.6298
2023-05-01 19:34:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #418: GFLOPs: 110551.5971. Time: 79604.3497 us. Best GFLOPs: 113931.6298
2023-05-01 19:34:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #419: GFLOPs: 109553.8504. Time: 80329.3353 us. Best GFLOPs: 113931.6298
2023-05-01 19:34:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #420: GFLOPs: 110252.7546. Time: 79820.1190 us. Best GFLOPs: 113931.6298
2023-05-01 19:34:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #421: GFLOPs: 112306.3218. Time: 78360.5753 us. Best GFLOPs: 113931.6298
2023-05-01 19:34:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #422: GFLOPs: 112157.3161. Time: 78464.6807 us. Best GFLOPs: 113931.6298
2023-05-01 19:34:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #423: GFLOPs: 95137.2582. Time: 92502.0140 us. Best GFLOPs: 113931.6298
2023-05-01 19:34:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #424: GFLOPs: 94045.8455. Time: 93575.5103 us. Best GFLOPs: 113931.6298
2023-05-01 19:34:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #425: GFLOPs: 112065.6613. Time: 78528.8543 us. Best GFLOPs: 113931.6298
2023-05-01 19:34:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #426: GFLOPs: 112787.7942. Time: 78026.0670 us. Best GFLOPs: 113931.6298
2023-05-01 19:34:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #427: GFLOPs: 111245.0959. Time: 79108.0983 us. Best GFLOPs: 113931.6298
2023-05-01 19:34:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #428: GFLOPs: 108986.9432. Time: 80747.1770 us. Best GFLOPs: 113931.6298
2023-05-01 19:34:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #429: GFLOPs: 110344.2951. Time: 79753.9010 us. Best GFLOPs: 113931.6298
2023-05-01 19:34:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #430: GFLOPs: 109752.4467. Time: 80183.9800 us. Best GFLOPs: 113931.6298
2023-05-01 19:34:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #431: GFLOPs: 109762.6257. Time: 80176.5440 us. Best GFLOPs: 113931.6298
2023-05-01 19:34:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #432: GFLOPs: 109786.0965. Time: 80159.4033 us. Best GFLOPs: 113931.6298
2023-05-01 19:34:07 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 19:34:08 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 19:34:12 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 399 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:34:16 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 801 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:34:19 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1198 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:34:23 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1599 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:34:27 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1997 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:34:27 [INFO] [evolutionary_search.cc:723] Sampled 53 candidate(s)
2023-05-01 19:34:34 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 123 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:34:43 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 134 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:34:51 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 114 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:34:59 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 111 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:35:01 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9664  0.9664  0.9640  0.9622  0.9622  0.9622  0.9622  0.9600  0.9600  0.9600  0.9500  0.9500  0.9500  0.9500  0.9419  0.9393
2023-05-01 19:35:01 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 19:35:01 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 19:41:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #433: GFLOPs: 112703.9748. Time: 78084.0960 us. Best GFLOPs: 113931.6298
2023-05-01 19:41:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #434: GFLOPs: 111289.2948. Time: 79076.6803 us. Best GFLOPs: 113931.6298
2023-05-01 19:41:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #435: GFLOPs: 110139.3254. Time: 79902.3233 us. Best GFLOPs: 113931.6298
2023-05-01 19:41:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #436: GFLOPs: 111164.0388. Time: 79165.7813 us. Best GFLOPs: 113931.6298
2023-05-01 19:41:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #437: GFLOPs: 112919.1926. Time: 77935.2720 us. Best GFLOPs: 113931.6298
2023-05-01 19:41:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #438: GFLOPs: 111197.6021. Time: 79141.8863 us. Best GFLOPs: 113931.6298
2023-05-01 19:41:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #439: GFLOPs: 112430.7188. Time: 78273.8747 us. Best GFLOPs: 113931.6298
2023-05-01 19:41:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #440: GFLOPs: 112093.9257. Time: 78509.0533 us. Best GFLOPs: 113931.6298
2023-05-01 19:41:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #441: GFLOPs: 110864.3307. Time: 79379.7963 us. Best GFLOPs: 113931.6298
2023-05-01 19:41:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #442: GFLOPs: 98397.4735. Time: 89437.1337 us. Best GFLOPs: 113931.6298
2023-05-01 19:41:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #443: GFLOPs: 112076.3833. Time: 78521.3417 us. Best GFLOPs: 113931.6298
2023-05-01 19:41:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #444: GFLOPs: 110506.0487. Time: 79637.1610 us. Best GFLOPs: 113931.6298
2023-05-01 19:41:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #445: GFLOPs: 112571.1139. Time: 78176.2540 us. Best GFLOPs: 113931.6298
2023-05-01 19:41:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #446: GFLOPs: 112727.6260. Time: 78067.7133 us. Best GFLOPs: 113931.6298
2023-05-01 19:41:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #447: GFLOPs: 108115.8484. Time: 81397.7610 us. Best GFLOPs: 113931.6298
2023-05-01 19:41:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #448: GFLOPs: 111235.9772. Time: 79114.5833 us. Best GFLOPs: 113931.6298
2023-05-01 19:41:51 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 19:41:52 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 19:41:56 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 400 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:41:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 797 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:42:03 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1201 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:42:06 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1599 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:42:10 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2003 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:42:14 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2402 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:42:14 [INFO] [evolutionary_search.cc:723] Sampled 58 candidate(s)
2023-05-01 19:42:21 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 124 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:42:29 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 133 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:42:38 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 107 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:42:46 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 129 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:42:48 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9640  0.9622  0.9622  0.9600  0.9500  0.9500  0.9500  0.9500  0.9500  0.9500  0.9393  0.9274  0.9274  0.9274  0.9274  0.9274
2023-05-01 19:42:48 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 19:42:48 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 19:49:38 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #449: GFLOPs: 113136.7136. Time: 77785.4307 us. Best GFLOPs: 113931.6298
2023-05-01 19:49:38 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #450: GFLOPs: 111051.0372. Time: 79246.3377 us. Best GFLOPs: 113931.6298
2023-05-01 19:49:38 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #451: GFLOPs: 110199.0357. Time: 79859.0290 us. Best GFLOPs: 113931.6298
2023-05-01 19:49:38 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #452: GFLOPs: 86262.9659. Time: 102018.1477 us. Best GFLOPs: 113931.6298
2023-05-01 19:49:38 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #453: GFLOPs: 110453.9723. Time: 79674.7080 us. Best GFLOPs: 113931.6298
2023-05-01 19:49:38 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #454: GFLOPs: 109874.0585. Time: 80095.2300 us. Best GFLOPs: 113931.6298
2023-05-01 19:49:38 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #455: GFLOPs: 110360.3564. Time: 79742.2940 us. Best GFLOPs: 113931.6298
2023-05-01 19:49:38 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #456: GFLOPs: 109631.6036. Time: 80272.3640 us. Best GFLOPs: 113931.6298
2023-05-01 19:49:38 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #457: GFLOPs: 112499.8883. Time: 78225.7487 us. Best GFLOPs: 113931.6298
2023-05-01 19:49:38 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #458: GFLOPs: 108849.3487. Time: 80849.2480 us. Best GFLOPs: 113931.6298
2023-05-01 19:49:38 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #459: GFLOPs: 112115.2656. Time: 78494.1100 us. Best GFLOPs: 113931.6298
2023-05-01 19:49:38 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #460: GFLOPs: 107756.7122. Time: 81669.0470 us. Best GFLOPs: 113931.6298
2023-05-01 19:49:38 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #461: GFLOPs: 112494.5344. Time: 78229.4717 us. Best GFLOPs: 113931.6298
2023-05-01 19:49:38 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #462: GFLOPs: 112115.3675. Time: 78494.0387 us. Best GFLOPs: 113931.6298
2023-05-01 19:49:38 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #463: GFLOPs: 112431.2081. Time: 78273.5340 us. Best GFLOPs: 113931.6298
2023-05-01 19:49:38 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #464: GFLOPs: 111703.5008. Time: 78783.4573 us. Best GFLOPs: 113931.6298
2023-05-01 19:49:38 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 19:49:39 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 19:49:43 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 399 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:49:46 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 800 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:49:50 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1202 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:49:54 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1603 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:49:57 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2000 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:49:57 [INFO] [evolutionary_search.cc:723] Sampled 50 candidate(s)
2023-05-01 19:50:05 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 154 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:50:13 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 111 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:50:22 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 117 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:50:30 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 130 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:50:32 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9669  0.9640  0.9622  0.9600  0.9573  0.9500  0.9500  0.9427  0.9427  0.9393  0.9274  0.9274  0.9274  0.9274  0.9274  0.9274
2023-05-01 19:50:32 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 19:50:32 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 19:57:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #465: GFLOPs: 110691.5489. Time: 79503.7027 us. Best GFLOPs: 113931.6298
2023-05-01 19:57:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #466: GFLOPs: 93975.9166. Time: 93645.1413 us. Best GFLOPs: 113931.6298
2023-05-01 19:57:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #467: GFLOPs: 111178.8962. Time: 79155.2020 us. Best GFLOPs: 113931.6298
2023-05-01 19:57:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #468: GFLOPs: 86303.4722. Time: 101970.2657 us. Best GFLOPs: 113931.6298
2023-05-01 19:57:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #469: GFLOPs: 109186.3607. Time: 80599.7007 us. Best GFLOPs: 113931.6298
2023-05-01 19:57:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #470: GFLOPs: 113148.6328. Time: 77777.2367 us. Best GFLOPs: 113931.6298
2023-05-01 19:57:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #471: GFLOPs: 109929.3325. Time: 80054.9570 us. Best GFLOPs: 113931.6298
2023-05-01 19:57:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #472: GFLOPs: 92480.5961. Time: 95159.2913 us. Best GFLOPs: 113931.6298
2023-05-01 19:57:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #473: GFLOPs: 94971.8441. Time: 92663.1263 us. Best GFLOPs: 113931.6298
2023-05-01 19:57:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #474: GFLOPs: 110024.5695. Time: 79985.6617 us. Best GFLOPs: 113931.6298
2023-05-01 19:57:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #475: GFLOPs: 101080.8442. Time: 87062.8660 us. Best GFLOPs: 113931.6298
2023-05-01 19:57:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #476: GFLOPs: 111752.3592. Time: 78749.0130 us. Best GFLOPs: 113931.6298
2023-05-01 19:57:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #477: GFLOPs: 85207.6486. Time: 103281.6670 us. Best GFLOPs: 113931.6298
2023-05-01 19:57:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #478: GFLOPs: 112323.9367. Time: 78348.2867 us. Best GFLOPs: 113931.6298
2023-05-01 19:57:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #479: GFLOPs: 108802.9679. Time: 80883.7127 us. Best GFLOPs: 113931.6298
2023-05-01 19:57:24 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #480: GFLOPs: 112071.0182. Time: 78525.1007 us. Best GFLOPs: 113931.6298
2023-05-01 19:57:24 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 19:57:25 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 19:57:29 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 397 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:57:32 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 798 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:57:36 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1198 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:57:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1597 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:57:43 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2000 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:57:43 [INFO] [evolutionary_search.cc:723] Sampled 50 candidate(s)
2023-05-01 19:57:50 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 110 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:57:59 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 127 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:58:07 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 139 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:58:16 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 128 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 19:58:18 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9664  0.9622  0.9600  0.9500  0.9500  0.9500  0.9500  0.9427  0.9427  0.9393  0.9393  0.9274  0.9274  0.9274  0.9274  0.9248
2023-05-01 19:58:18 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 19:58:18 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 20:05:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #481: GFLOPs: 112051.5384. Time: 78538.7520 us. Best GFLOPs: 113931.6298
2023-05-01 20:05:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #482: GFLOPs: 110615.0792. Time: 79558.6647 us. Best GFLOPs: 113931.6298
2023-05-01 20:05:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #483: GFLOPs: 112976.5850. Time: 77895.6807 us. Best GFLOPs: 113931.6298
2023-05-01 20:05:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #484: GFLOPs: 110793.8224. Time: 79430.3130 us. Best GFLOPs: 113931.6298
2023-05-01 20:05:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #485: GFLOPs: 110954.4428. Time: 79315.3277 us. Best GFLOPs: 113931.6298
2023-05-01 20:05:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #486: GFLOPs: 110148.6581. Time: 79895.5533 us. Best GFLOPs: 113931.6298
2023-05-01 20:05:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #487: GFLOPs: 112613.3966. Time: 78146.9013 us. Best GFLOPs: 113931.6298
2023-05-01 20:05:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #488: GFLOPs: 112241.8314. Time: 78405.5987 us. Best GFLOPs: 113931.6298
2023-05-01 20:05:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #489: GFLOPs: 93792.3091. Time: 93828.4607 us. Best GFLOPs: 113931.6298
2023-05-01 20:05:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #490: GFLOPs: 90692.3609. Time: 97035.6037 us. Best GFLOPs: 113931.6298
2023-05-01 20:05:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #491: GFLOPs: 112288.7129. Time: 78372.8637 us. Best GFLOPs: 113931.6298
2023-05-01 20:05:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #492: GFLOPs: 111641.5447. Time: 78827.1787 us. Best GFLOPs: 113931.6298
2023-05-01 20:05:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #493: GFLOPs: 112090.5124. Time: 78511.4440 us. Best GFLOPs: 113931.6298
2023-05-01 20:05:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #494: GFLOPs: 107247.4191. Time: 82056.8743 us. Best GFLOPs: 113931.6298
2023-05-01 20:05:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #495: GFLOPs: 109944.8960. Time: 80043.6247 us. Best GFLOPs: 113931.6298
2023-05-01 20:05:07 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #496: GFLOPs: 111732.0155. Time: 78763.3513 us. Best GFLOPs: 113931.6298
2023-05-01 20:05:07 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 20:05:09 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 20:05:12 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 394 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:05:16 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 797 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:05:19 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1193 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:05:23 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1592 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:05:27 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1998 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:05:27 [INFO] [evolutionary_search.cc:723] Sampled 52 candidate(s)
2023-05-01 20:05:34 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 117 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:05:42 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 125 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:05:51 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 124 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:05:59 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 110 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:06:01 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9669  0.9640  0.9640  0.9500  0.9393  0.9393  0.9393  0.9274  0.9274  0.9248  0.9248  0.9248  0.9248  0.9248  0.9248  0.9248
2023-05-01 20:06:01 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 20:06:01 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 20:12:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #497: GFLOPs: 111008.9648. Time: 79276.3720 us. Best GFLOPs: 113931.6298
2023-05-01 20:12:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #498: GFLOPs: 94236.3394. Time: 93386.3523 us. Best GFLOPs: 113931.6298
2023-05-01 20:12:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #499: GFLOPs: 111298.4077. Time: 79070.2057 us. Best GFLOPs: 113931.6298
2023-05-01 20:12:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #500: GFLOPs: 110456.3346. Time: 79673.0040 us. Best GFLOPs: 113931.6298
2023-05-01 20:12:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #501: GFLOPs: 111758.6533. Time: 78744.5780 us. Best GFLOPs: 113931.6298
2023-05-01 20:12:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #502: GFLOPs: 110311.2513. Time: 79777.7913 us. Best GFLOPs: 113931.6298
2023-05-01 20:12:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #503: GFLOPs: 88808.6270. Time: 99093.8413 us. Best GFLOPs: 113931.6298
2023-05-01 20:12:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #504: GFLOPs: 112857.4484. Time: 77977.9103 us. Best GFLOPs: 113931.6298
2023-05-01 20:12:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #505: GFLOPs: 84472.8687. Time: 104180.0537 us. Best GFLOPs: 113931.6298
2023-05-01 20:12:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #506: GFLOPs: 109092.5480. Time: 80669.0113 us. Best GFLOPs: 113931.6298
2023-05-01 20:12:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #507: GFLOPs: 111354.6445. Time: 79030.2733 us. Best GFLOPs: 113931.6298
2023-05-01 20:12:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #508: GFLOPs: 111952.2836. Time: 78608.3830 us. Best GFLOPs: 113931.6298
2023-05-01 20:12:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #509: GFLOPs: 111412.9179. Time: 78988.9373 us. Best GFLOPs: 113931.6298
2023-05-01 20:12:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #510: GFLOPs: 108701.5898. Time: 80959.1470 us. Best GFLOPs: 113931.6298
2023-05-01 20:12:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #511: GFLOPs: 111751.3919. Time: 78749.6947 us. Best GFLOPs: 113931.6298
2023-05-01 20:12:51 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #512: GFLOPs: 91188.2329. Time: 96507.9343 us. Best GFLOPs: 113931.6298
2023-05-01 20:12:51 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 20:12:52 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 20:12:55 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 394 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:12:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 795 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:13:03 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1198 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:13:06 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1603 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:13:10 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2002 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:13:13 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2405 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:13:13 [INFO] [evolutionary_search.cc:723] Sampled 55 candidate(s)
2023-05-01 20:13:21 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 168 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:13:30 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 130 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:13:38 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 121 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:13:47 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 126 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:13:49 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9669  0.9582  0.9500  0.9427  0.9427  0.9427  0.9427  0.9419  0.9419  0.9393  0.9393  0.9393  0.9274  0.9274  0.9248  0.9248
2023-05-01 20:13:49 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 20:13:49 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 20:20:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #513: GFLOPs: 111218.7525. Time: 79126.8360 us. Best GFLOPs: 113931.6298
2023-05-01 20:20:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #514: GFLOPs: 101435.9745. Time: 86758.0563 us. Best GFLOPs: 113931.6298
2023-05-01 20:20:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #515: GFLOPs: 110488.6114. Time: 79649.7293 us. Best GFLOPs: 113931.6298
2023-05-01 20:20:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #516: GFLOPs: 113124.3088. Time: 77793.9603 us. Best GFLOPs: 113931.6298
2023-05-01 20:20:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #517: GFLOPs: 112838.1432. Time: 77991.2513 us. Best GFLOPs: 113931.6298
2023-05-01 20:20:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #518: GFLOPs: 112484.1788. Time: 78236.6737 us. Best GFLOPs: 113931.6298
2023-05-01 20:20:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #519: GFLOPs: 91090.0003. Time: 96612.0097 us. Best GFLOPs: 113931.6298
2023-05-01 20:20:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #520: GFLOPs: 110418.5375. Time: 79700.2767 us. Best GFLOPs: 113931.6298
2023-05-01 20:20:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #521: GFLOPs: 109853.9257. Time: 80109.9090 us. Best GFLOPs: 113931.6298
2023-05-01 20:20:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #522: GFLOPs: 112126.0986. Time: 78486.5263 us. Best GFLOPs: 113931.6298
2023-05-01 20:20:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #523: GFLOPs: 92320.3131. Time: 95324.5033 us. Best GFLOPs: 113931.6298
2023-05-01 20:20:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #524: GFLOPs: 92741.7332. Time: 94891.3470 us. Best GFLOPs: 113931.6298
2023-05-01 20:20:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #525: GFLOPs: 84571.2363. Time: 104058.8783 us. Best GFLOPs: 113931.6298
2023-05-01 20:20:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #526: GFLOPs: 94010.1783. Time: 93611.0127 us. Best GFLOPs: 113931.6298
2023-05-01 20:20:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #527: GFLOPs: 105150.5397. Time: 83693.2270 us. Best GFLOPs: 113931.6298
2023-05-01 20:20:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #528: GFLOPs: 108145.7784. Time: 81375.2337 us. Best GFLOPs: 113931.6298
2023-05-01 20:20:40 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 20:20:41 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 20:20:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 404 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:20:48 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 804 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:20:52 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1208 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:20:55 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1607 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:20:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2006 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:21:03 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2411 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:21:06 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2809 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:21:06 [INFO] [evolutionary_search.cc:723] Sampled 61 candidate(s)
2023-05-01 20:21:13 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 122 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:21:22 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 123 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:21:30 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 126 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:21:38 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 102 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:21:40 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9708  0.9702  0.9530  0.9530  0.9530  0.9530  0.9466  0.9466  0.9466  0.9466  0.9466  0.9431  0.9335  0.9110  0.9110  0.9110
2023-05-01 20:21:40 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 20:21:40 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 20:28:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #529: GFLOPs: 111685.6765. Time: 78796.0307 us. Best GFLOPs: 113931.6298
2023-05-01 20:28:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #530: GFLOPs: 110707.3215. Time: 79492.3757 us. Best GFLOPs: 113931.6298
2023-05-01 20:28:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #531: GFLOPs: 92659.7338. Time: 94975.3213 us. Best GFLOPs: 113931.6298
2023-05-01 20:28:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #532: GFLOPs: 110441.6133. Time: 79683.6240 us. Best GFLOPs: 113931.6298
2023-05-01 20:28:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #533: GFLOPs: 110505.6037. Time: 79637.4817 us. Best GFLOPs: 113931.6298
2023-05-01 20:28:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #534: GFLOPs: 101623.4890. Time: 86597.9713 us. Best GFLOPs: 113931.6298
2023-05-01 20:28:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #535: GFLOPs: 108697.9227. Time: 80961.8783 us. Best GFLOPs: 113931.6298
2023-05-01 20:28:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #536: GFLOPs: 107128.9683. Time: 82147.6033 us. Best GFLOPs: 113931.6298
2023-05-01 20:28:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #537: GFLOPs: 107691.8295. Time: 81718.2513 us. Best GFLOPs: 113931.6298
2023-05-01 20:28:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #538: GFLOPs: 110788.1047. Time: 79434.4123 us. Best GFLOPs: 113931.6298
2023-05-01 20:28:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #539: GFLOPs: 109247.4008. Time: 80554.6670 us. Best GFLOPs: 113931.6298
2023-05-01 20:28:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #540: GFLOPs: 84823.0418. Time: 103749.9693 us. Best GFLOPs: 113931.6298
2023-05-01 20:28:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #541: GFLOPs: 107284.4593. Time: 82028.5440 us. Best GFLOPs: 113931.6298
2023-05-01 20:28:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #542: GFLOPs: 111881.3542. Time: 78658.2183 us. Best GFLOPs: 113931.6298
2023-05-01 20:28:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #543: GFLOPs: 112080.7683. Time: 78518.2697 us. Best GFLOPs: 113931.6298
2023-05-01 20:28:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #544: GFLOPs: 112778.4136. Time: 78032.5570 us. Best GFLOPs: 113931.6298
2023-05-01 20:28:30 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 20:28:32 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 20:28:35 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 403 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:28:39 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 801 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:28:42 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1198 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:28:46 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1598 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:28:49 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1995 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:28:49 [INFO] [evolutionary_search.cc:723] Sampled 55 candidate(s)
2023-05-01 20:28:57 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 129 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:29:05 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 107 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:29:14 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 110 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:29:22 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 115 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:29:24 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9671  0.9530  0.9466  0.9466  0.9466  0.9466  0.9466  0.9431  0.9431  0.9431  0.9431  0.9426  0.9426  0.9426  0.9410  0.9335
2023-05-01 20:29:24 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 20:29:24 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 20:36:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #545: GFLOPs: 111227.8253. Time: 79120.3817 us. Best GFLOPs: 113931.6298
2023-05-01 20:36:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #546: GFLOPs: 92421.2480. Time: 95220.3977 us. Best GFLOPs: 113931.6298
2023-05-01 20:36:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #547: GFLOPs: 112423.8514. Time: 78278.6560 us. Best GFLOPs: 113931.6298
2023-05-01 20:36:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #548: GFLOPs: 109953.2451. Time: 80037.5467 us. Best GFLOPs: 113931.6298
2023-05-01 20:36:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #549: GFLOPs: 92375.8816. Time: 95267.1610 us. Best GFLOPs: 113931.6298
2023-05-01 20:36:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #550: GFLOPs: 75961.9511. Time: 115852.5797 us. Best GFLOPs: 113931.6298
2023-05-01 20:36:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #551: GFLOPs: 99189.7254. Time: 88722.7780 us. Best GFLOPs: 113931.6298
2023-05-01 20:36:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #552: GFLOPs: 87632.3002. Time: 100424.0213 us. Best GFLOPs: 113931.6298
2023-05-01 20:36:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #553: GFLOPs: 86861.7344. Time: 101314.9007 us. Best GFLOPs: 113931.6298
2023-05-01 20:36:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #554: GFLOPs: 85722.6941. Time: 102661.1223 us. Best GFLOPs: 113931.6298
2023-05-01 20:36:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #555: GFLOPs: 93713.5790. Time: 93907.2873 us. Best GFLOPs: 113931.6298
2023-05-01 20:36:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #556: GFLOPs: 87756.6804. Time: 100281.6873 us. Best GFLOPs: 113931.6298
2023-05-01 20:36:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #557: GFLOPs: 92325.2787. Time: 95319.3763 us. Best GFLOPs: 113931.6298
2023-05-01 20:36:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #558: GFLOPs: 111349.3558. Time: 79034.0270 us. Best GFLOPs: 113931.6298
2023-05-01 20:36:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #559: GFLOPs: 92598.1735. Time: 95038.4620 us. Best GFLOPs: 113931.6298
2023-05-01 20:36:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #560: GFLOPs: 110487.1017. Time: 79650.8177 us. Best GFLOPs: 113931.6298
2023-05-01 20:36:15 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 20:36:16 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 20:36:19 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 402 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:36:23 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 800 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:36:27 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1201 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:36:30 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1602 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:36:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2000 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:36:34 [INFO] [evolutionary_search.cc:723] Sampled 50 candidate(s)
2023-05-01 20:36:41 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 134 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:36:50 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 113 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:36:58 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 135 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:37:06 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 119 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:37:08 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9431  0.9431  0.9410  0.9335  0.9335  0.9110  0.9110  0.9110  0.9110  0.9110  0.9110  0.9110  0.9110  0.9052  0.8815  0.8815
2023-05-01 20:37:08 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 20:37:08 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 20:43:58 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #561: GFLOPs: 113221.6748. Time: 77727.0607 us. Best GFLOPs: 113931.6298
2023-05-01 20:43:58 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #562: GFLOPs: 110999.8847. Time: 79282.8570 us. Best GFLOPs: 113931.6298
2023-05-01 20:43:58 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #563: GFLOPs: 111647.2861. Time: 78823.1250 us. Best GFLOPs: 113931.6298
2023-05-01 20:43:58 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #564: GFLOPs: 110062.6084. Time: 79958.0177 us. Best GFLOPs: 113931.6298
2023-05-01 20:43:58 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #565: GFLOPs: 93010.0487. Time: 94617.6043 us. Best GFLOPs: 113931.6298
2023-05-01 20:43:58 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #566: GFLOPs: 111751.4207. Time: 78749.6743 us. Best GFLOPs: 113931.6298
2023-05-01 20:43:58 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #567: GFLOPs: 110107.7359. Time: 79925.2470 us. Best GFLOPs: 113931.6298
2023-05-01 20:43:58 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #568: GFLOPs: 111985.3467. Time: 78585.1743 us. Best GFLOPs: 113931.6298
2023-05-01 20:43:58 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #569: GFLOPs: 111917.2926. Time: 78632.9600 us. Best GFLOPs: 113931.6298
2023-05-01 20:43:58 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #570: GFLOPs: 112411.1061. Time: 78287.5313 us. Best GFLOPs: 113931.6298
2023-05-01 20:43:58 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #571: GFLOPs: 112598.6441. Time: 78157.1400 us. Best GFLOPs: 113931.6298
2023-05-01 20:43:58 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #572: GFLOPs: 112055.4354. Time: 78536.0207 us. Best GFLOPs: 113931.6298
2023-05-01 20:43:58 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #573: GFLOPs: 111899.8055. Time: 78645.2483 us. Best GFLOPs: 113931.6298
2023-05-01 20:43:58 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #574: GFLOPs: 81341.9706. Time: 108190.0023 us. Best GFLOPs: 113931.6298
2023-05-01 20:43:58 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #575: GFLOPs: 111496.7027. Time: 78929.5807 us. Best GFLOPs: 113931.6298
2023-05-01 20:43:58 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #576: GFLOPs: 111484.6549. Time: 78938.1103 us. Best GFLOPs: 113931.6298
2023-05-01 20:43:58 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 20:44:00 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 20:44:03 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 400 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:44:07 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 799 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:44:11 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1196 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:44:14 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1591 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:44:18 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1997 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:44:18 [INFO] [evolutionary_search.cc:723] Sampled 53 candidate(s)
2023-05-01 20:44:25 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 137 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:44:34 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 132 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:44:42 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 119 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:44:50 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 99 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:44:52 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9466  0.9466  0.9466  0.9466  0.9410  0.9124  0.9110  0.9110  0.9110  0.9110  0.9052  0.8815  0.8815  0.8815  0.8815  0.8815
2023-05-01 20:44:52 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 20:44:52 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 20:51:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #577: GFLOPs: 113778.2824. Time: 77346.8170 us. Best GFLOPs: 113931.6298
2023-05-01 20:51:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #578: GFLOPs: 92499.1758. Time: 95140.1773 us. Best GFLOPs: 113931.6298
2023-05-01 20:51:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #579: GFLOPs: 99865.5448. Time: 88122.3650 us. Best GFLOPs: 113931.6298
2023-05-01 20:51:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #580: GFLOPs: 106641.9024. Time: 82522.7963 us. Best GFLOPs: 113931.6298
2023-05-01 20:51:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #581: GFLOPs: 93757.2508. Time: 93863.5457 us. Best GFLOPs: 113931.6298
2023-05-01 20:51:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #582: GFLOPs: 109678.7421. Time: 80237.8640 us. Best GFLOPs: 113931.6298
2023-05-01 20:51:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #583: GFLOPs: 112961.7372. Time: 77905.9193 us. Best GFLOPs: 113931.6298
2023-05-01 20:51:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #584: GFLOPs: 112076.8696. Time: 78521.0010 us. Best GFLOPs: 113931.6298
2023-05-01 20:51:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #585: GFLOPs: 112691.6570. Time: 78092.6310 us. Best GFLOPs: 113931.6298
2023-05-01 20:51:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #586: GFLOPs: 110554.3802. Time: 79602.3457 us. Best GFLOPs: 113931.6298
2023-05-01 20:51:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #587: GFLOPs: 104204.5222. Time: 84453.0333 us. Best GFLOPs: 113931.6298
2023-05-01 20:51:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #588: GFLOPs: 109535.6307. Time: 80342.6970 us. Best GFLOPs: 113931.6298
2023-05-01 20:51:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #589: GFLOPs: 112077.8426. Time: 78520.3193 us. Best GFLOPs: 113931.6298
2023-05-01 20:51:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #590: GFLOPs: 111688.9428. Time: 78793.7263 us. Best GFLOPs: 113931.6298
2023-05-01 20:51:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #591: GFLOPs: 96676.5767. Time: 91029.1643 us. Best GFLOPs: 113931.6298
2023-05-01 20:51:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #592: GFLOPs: 112152.9975. Time: 78467.7020 us. Best GFLOPs: 113931.6298
2023-05-01 20:51:41 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 20:51:42 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 20:51:46 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 402 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:51:50 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 802 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:51:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1204 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:51:57 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1607 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:52:00 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2006 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:52:04 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2406 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:52:04 [INFO] [evolutionary_search.cc:723] Sampled 54 candidate(s)
2023-05-01 20:52:12 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 142 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:52:20 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 139 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:52:28 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 112 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:52:37 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 135 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:52:39 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9690  0.9410  0.9124  0.9110  0.9093  0.8815  0.8815  0.8815  0.8815  0.8815  0.8522  0.8522  0.8522  0.8522  0.8522  0.8522
2023-05-01 20:52:39 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 20:52:39 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 20:59:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #593: GFLOPs: 111533.8469. Time: 78903.2947 us. Best GFLOPs: 113931.6298
2023-05-01 20:59:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #594: GFLOPs: 92437.5124. Time: 95203.6437 us. Best GFLOPs: 113931.6298
2023-05-01 20:59:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #595: GFLOPs: 110151.0143. Time: 79893.8443 us. Best GFLOPs: 113931.6298
2023-05-01 20:59:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #596: GFLOPs: 100664.4782. Time: 87422.9733 us. Best GFLOPs: 113931.6298
2023-05-01 20:59:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #597: GFLOPs: 104649.0754. Time: 84094.2737 us. Best GFLOPs: 113931.6298
2023-05-01 20:59:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #598: GFLOPs: 84797.3757. Time: 103781.3720 us. Best GFLOPs: 113931.6298
2023-05-01 20:59:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #599: GFLOPs: 79177.9153. Time: 111147.0030 us. Best GFLOPs: 113931.6298
2023-05-01 20:59:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #600: GFLOPs: 111552.1837. Time: 78890.3247 us. Best GFLOPs: 113931.6298
2023-05-01 20:59:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #601: GFLOPs: 111348.8758. Time: 79034.3677 us. Best GFLOPs: 113931.6298
2023-05-01 20:59:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #602: GFLOPs: 111044.3733. Time: 79251.0933 us. Best GFLOPs: 113931.6298
2023-05-01 20:59:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #603: GFLOPs: 111814.8793. Time: 78704.9813 us. Best GFLOPs: 113931.6298
2023-05-01 20:59:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #604: GFLOPs: 110364.6081. Time: 79739.2220 us. Best GFLOPs: 113931.6298
2023-05-01 20:59:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #605: GFLOPs: 112095.8718. Time: 78507.6903 us. Best GFLOPs: 113931.6298
2023-05-01 20:59:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #606: GFLOPs: 111852.2283. Time: 78678.7007 us. Best GFLOPs: 113931.6298
2023-05-01 20:59:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #607: GFLOPs: 111542.5325. Time: 78897.1507 us. Best GFLOPs: 113931.6298
2023-05-01 20:59:29 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #608: GFLOPs: 111221.5839. Time: 79124.8217 us. Best GFLOPs: 113931.6298
2023-05-01 20:59:29 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 20:59:30 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 20:59:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 401 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:59:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 798 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:59:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1201 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:59:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1604 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:59:48 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1994 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 20:59:48 [INFO] [evolutionary_search.cc:723] Sampled 56 candidate(s)
2023-05-01 20:59:56 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 124 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:00:04 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 108 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:00:12 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 122 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:00:20 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 126 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:00:22 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9671  0.9530  0.9431  0.9353  0.9124  0.9110  0.8815  0.8815  0.8538  0.8522  0.8522  0.8522  0.8522  0.8522  0.8522  0.8443
2023-05-01 21:00:22 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 21:00:22 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 21:07:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #609: GFLOPs: 111321.9528. Time: 79053.4820 us. Best GFLOPs: 113931.6298
2023-05-01 21:07:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #610: GFLOPs: 112607.0054. Time: 78151.3367 us. Best GFLOPs: 113931.6298
2023-05-01 21:07:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #611: GFLOPs: 112717.8295. Time: 78074.4983 us. Best GFLOPs: 113931.6298
2023-05-01 21:07:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #612: GFLOPs: 93393.4609. Time: 94229.1667 us. Best GFLOPs: 113931.6298
2023-05-01 21:07:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #613: GFLOPs: 109077.3146. Time: 80680.2773 us. Best GFLOPs: 113931.6298
2023-05-01 21:07:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #614: GFLOPs: 112893.4349. Time: 77953.0537 us. Best GFLOPs: 113931.6298
2023-05-01 21:07:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #615: GFLOPs: 111235.4982. Time: 79114.9240 us. Best GFLOPs: 113931.6298
2023-05-01 21:07:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #616: GFLOPs: 106518.6073. Time: 82618.3163 us. Best GFLOPs: 113931.6298
2023-05-01 21:07:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #617: GFLOPs: 111044.8221. Time: 79250.7730 us. Best GFLOPs: 113931.6298
2023-05-01 21:07:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #618: GFLOPs: 108706.6300. Time: 80955.3933 us. Best GFLOPs: 113931.6298
2023-05-01 21:07:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #619: GFLOPs: 112217.3572. Time: 78422.6987 us. Best GFLOPs: 113931.6298
2023-05-01 21:07:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #620: GFLOPs: 112054.4628. Time: 78536.7023 us. Best GFLOPs: 113931.6298
2023-05-01 21:07:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #621: GFLOPs: 112005.7823. Time: 78570.8363 us. Best GFLOPs: 113931.6298
2023-05-01 21:07:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #622: GFLOPs: 111637.1936. Time: 78830.2510 us. Best GFLOPs: 113931.6298
2023-05-01 21:07:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #623: GFLOPs: 110689.6512. Time: 79505.0657 us. Best GFLOPs: 113931.6298
2023-05-01 21:07:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #624: GFLOPs: 60048.6922. Time: 146554.1990 us. Best GFLOPs: 113931.6298
2023-05-01 21:07:12 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 21:07:13 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 21:07:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 396 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:07:20 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 794 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:07:24 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1195 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:07:27 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1597 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:07:31 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1999 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:07:31 [INFO] [evolutionary_search.cc:723] Sampled 51 candidate(s)
2023-05-01 21:07:38 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 119 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:07:47 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 114 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:07:55 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 112 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:08:03 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 121 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:08:05 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9466  0.9431  0.9426  0.9426  0.9426  0.9124  0.9110  0.9052  0.8815  0.8815  0.8673  0.8673  0.8673  0.8538  0.8522  0.8522
2023-05-01 21:08:05 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 21:08:05 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 21:14:56 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #625: GFLOPs: 102297.2650. Time: 86027.5980 us. Best GFLOPs: 113931.6298
2023-05-01 21:14:56 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #626: GFLOPs: 85746.6457. Time: 102632.4460 us. Best GFLOPs: 113931.6298
2023-05-01 21:14:56 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #627: GFLOPs: 113797.9489. Time: 77333.4500 us. Best GFLOPs: 113931.6298
2023-05-01 21:14:56 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #628: GFLOPs: 113251.5112. Time: 77706.5833 us. Best GFLOPs: 113931.6298
2023-05-01 21:14:56 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #629: GFLOPs: 87105.6034. Time: 101031.2500 us. Best GFLOPs: 113931.6298
2023-05-01 21:14:56 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #630: GFLOPs: 109288.1550. Time: 80524.6277 us. Best GFLOPs: 113931.6298
2023-05-01 21:14:56 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #631: GFLOPs: 111430.2033. Time: 78976.6843 us. Best GFLOPs: 113931.6298
2023-05-01 21:14:56 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #632: GFLOPs: 81513.7354. Time: 107962.0257 us. Best GFLOPs: 113931.6298
2023-05-01 21:14:56 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #633: GFLOPs: 92099.3617. Time: 95553.1920 us. Best GFLOPs: 113931.6298
2023-05-01 21:14:56 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #634: GFLOPs: 103269.5811. Time: 85217.6207 us. Best GFLOPs: 113931.6298
2023-05-01 21:14:56 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #635: GFLOPs: 104344.1139. Time: 84340.0520 us. Best GFLOPs: 113931.6298
2023-05-01 21:14:56 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #636: GFLOPs: 81444.7231. Time: 108053.5073 us. Best GFLOPs: 113931.6298
2023-05-01 21:14:56 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #637: GFLOPs: 104033.3864. Time: 84591.9593 us. Best GFLOPs: 113931.6298
2023-05-01 21:14:56 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #638: GFLOPs: 112236.9458. Time: 78409.0117 us. Best GFLOPs: 113931.6298
2023-05-01 21:14:56 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #639: GFLOPs: 109633.9099. Time: 80270.6753 us. Best GFLOPs: 113931.6298
2023-05-01 21:14:56 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #640: GFLOPs: 112654.7285. Time: 78118.2300 us. Best GFLOPs: 113931.6298
2023-05-01 21:14:56 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 21:14:57 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 21:15:01 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 401 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:15:04 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 804 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:15:08 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1207 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:15:11 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1610 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:15:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2003 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:15:18 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2406 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:15:18 [INFO] [evolutionary_search.cc:723] Sampled 54 candidate(s)
2023-05-01 21:15:26 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 126 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:15:34 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 143 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:15:43 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 109 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:15:51 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 126 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:15:53 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9742  0.9739  0.9739  0.9722  0.9722  0.9660  0.9374  0.9351  0.9351  0.9278  0.9278  0.9278  0.9278  0.9260  0.8680  0.8414
2023-05-01 21:15:53 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 21:15:53 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 21:22:43 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #641: GFLOPs: 108779.0948. Time: 80901.4637 us. Best GFLOPs: 113931.6298
2023-05-01 21:22:43 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #642: GFLOPs: 111845.9237. Time: 78683.1357 us. Best GFLOPs: 113931.6298
2023-05-01 21:22:43 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #643: GFLOPs: 110534.4707. Time: 79616.6837 us. Best GFLOPs: 113931.6298
2023-05-01 21:22:43 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #644: GFLOPs: 108880.2341. Time: 80826.3140 us. Best GFLOPs: 113931.6298
2023-05-01 21:22:43 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #645: GFLOPs: 110522.6300. Time: 79625.2133 us. Best GFLOPs: 113931.6298
2023-05-01 21:22:43 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #646: GFLOPs: 109589.1695. Time: 80303.4463 us. Best GFLOPs: 113931.6298
2023-05-01 21:22:43 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #647: GFLOPs: 93755.1579. Time: 93865.6410 us. Best GFLOPs: 113931.6298
2023-05-01 21:22:43 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #648: GFLOPs: 109374.3876. Time: 80461.1407 us. Best GFLOPs: 113931.6298
2023-05-01 21:22:43 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #649: GFLOPs: 109098.0992. Time: 80664.9067 us. Best GFLOPs: 113931.6298
2023-05-01 21:22:43 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #650: GFLOPs: 111024.2580. Time: 79265.4520 us. Best GFLOPs: 113931.6298
2023-05-01 21:22:43 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #651: GFLOPs: 110315.9708. Time: 79774.3783 us. Best GFLOPs: 113931.6298
2023-05-01 21:22:43 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #652: GFLOPs: 85269.6462. Time: 103206.5733 us. Best GFLOPs: 113931.6298
2023-05-01 21:22:43 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #653: GFLOPs: 82977.6084. Time: 106057.3830 us. Best GFLOPs: 113931.6298
2023-05-01 21:22:43 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #654: GFLOPs: 100138.2240. Time: 87882.4053 us. Best GFLOPs: 113931.6298
2023-05-01 21:22:43 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #655: GFLOPs: 112045.2109. Time: 78543.1873 us. Best GFLOPs: 113931.6298
2023-05-01 21:22:43 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #656: GFLOPs: 61329.1020. Time: 143494.4863 us. Best GFLOPs: 113931.6298
2023-05-01 21:22:43 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 21:22:44 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 21:22:48 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 402 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:22:51 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 795 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:22:55 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1199 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:22:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1598 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:23:02 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2001 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:23:06 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2401 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:23:06 [INFO] [evolutionary_search.cc:723] Sampled 59 candidate(s)
2023-05-01 21:23:13 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 145 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:23:21 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 117 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:23:30 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 117 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:23:38 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 118 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:23:40 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9739  0.9739  0.9351  0.8694  0.8680  0.8414  0.8414  0.8414  0.8342  0.8342  0.8333  0.8333  0.8333  0.8327  0.8327  0.8327
2023-05-01 21:23:40 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 21:23:40 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 21:30:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #657: GFLOPs: 113819.9725. Time: 77318.4863 us. Best GFLOPs: 113931.6298
2023-05-01 21:30:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #658: GFLOPs: 111944.6131. Time: 78613.7693 us. Best GFLOPs: 113931.6298
2023-05-01 21:30:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #659: GFLOPs: 110578.1626. Time: 79585.2253 us. Best GFLOPs: 113931.6298
2023-05-01 21:30:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #660: GFLOPs: 109909.2284. Time: 80069.6003 us. Best GFLOPs: 113931.6298
2023-05-01 21:30:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #661: GFLOPs: 111874.0698. Time: 78663.3400 us. Best GFLOPs: 113931.6298
2023-05-01 21:30:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #662: GFLOPs: 111872.1309. Time: 78664.7033 us. Best GFLOPs: 113931.6298
2023-05-01 21:30:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #663: GFLOPs: 111529.0227. Time: 78906.7077 us. Best GFLOPs: 113931.6298
2023-05-01 21:30:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #664: GFLOPs: 112136.8246. Time: 78479.0190 us. Best GFLOPs: 113931.6298
2023-05-01 21:30:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #665: GFLOPs: 95853.8546. Time: 91810.4757 us. Best GFLOPs: 113931.6298
2023-05-01 21:30:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #666: GFLOPs: 93705.7425. Time: 93915.1407 us. Best GFLOPs: 113931.6298
2023-05-01 21:30:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #667: GFLOPs: 92532.7355. Time: 95105.6720 us. Best GFLOPs: 113931.6298
2023-05-01 21:30:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #668: GFLOPs: 94158.5222. Time: 93463.5313 us. Best GFLOPs: 113931.6298
2023-05-01 21:30:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #669: GFLOPs: 94033.1594. Time: 93588.1347 us. Best GFLOPs: 113931.6298
2023-05-01 21:30:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #670: GFLOPs: 92445.4444. Time: 95195.4750 us. Best GFLOPs: 113931.6298
2023-05-01 21:30:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #671: GFLOPs: 93826.1220. Time: 93794.6470 us. Best GFLOPs: 113931.6298
2023-05-01 21:30:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #672: GFLOPs: 92203.1056. Time: 95445.6787 us. Best GFLOPs: 113931.6298
2023-05-01 21:30:30 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 21:30:31 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 21:30:35 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 399 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:30:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 798 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:30:42 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1192 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:30:46 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1594 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:30:49 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1996 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:30:49 [INFO] [evolutionary_search.cc:723] Sampled 54 candidate(s)
2023-05-01 21:30:57 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 153 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:31:05 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 117 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:31:13 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 132 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:31:22 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 124 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:31:24 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9443  0.9299  0.8414  0.8414  0.8342  0.8342  0.8333  0.8333  0.8333  0.8327  0.8326  0.8326  0.8326  0.8325  0.8325  0.8325
2023-05-01 21:31:24 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 21:31:24 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 21:38:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #673: GFLOPs: 95777.2996. Time: 91883.8600 us. Best GFLOPs: 113931.6298
2023-05-01 21:38:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #674: GFLOPs: 112835.0525. Time: 77993.3877 us. Best GFLOPs: 113931.6298
2023-05-01 21:38:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #675: GFLOPs: 61093.5299. Time: 144047.7903 us. Best GFLOPs: 113931.6298
2023-05-01 21:38:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #676: GFLOPs: 111716.0431. Time: 78774.6123 us. Best GFLOPs: 113931.6298
2023-05-01 21:38:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #677: GFLOPs: 92374.2346. Time: 95268.8597 us. Best GFLOPs: 113931.6298
2023-05-01 21:38:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #678: GFLOPs: 94932.6795. Time: 92701.3547 us. Best GFLOPs: 113931.6298
2023-05-01 21:38:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #679: GFLOPs: 91726.8106. Time: 95941.2840 us. Best GFLOPs: 113931.6298
2023-05-01 21:38:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #680: GFLOPs: 92352.3920. Time: 95291.3920 us. Best GFLOPs: 113931.6298
2023-05-01 21:38:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #681: GFLOPs: 93551.3847. Time: 94070.0987 us. Best GFLOPs: 113931.6298
2023-05-01 21:38:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #682: GFLOPs: 92370.9205. Time: 95272.2777 us. Best GFLOPs: 113931.6298
2023-05-01 21:38:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #683: GFLOPs: 92913.1827. Time: 94716.2473 us. Best GFLOPs: 113931.6298
2023-05-01 21:38:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #684: GFLOPs: 92498.5134. Time: 95140.8587 us. Best GFLOPs: 113931.6298
2023-05-01 21:38:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #685: GFLOPs: 90948.6173. Time: 96762.1967 us. Best GFLOPs: 113931.6298
2023-05-01 21:38:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #686: GFLOPs: 92622.7898. Time: 95013.2037 us. Best GFLOPs: 113931.6298
2023-05-01 21:38:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #687: GFLOPs: 91366.9679. Time: 96319.1423 us. Best GFLOPs: 113931.6298
2023-05-01 21:38:15 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #688: GFLOPs: 92872.2772. Time: 94757.9650 us. Best GFLOPs: 113931.6298
2023-05-01 21:38:15 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 21:38:16 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 21:38:20 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 397 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:38:23 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 798 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:38:27 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1199 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:38:31 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1597 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:38:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2001 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:38:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2403 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:38:38 [INFO] [evolutionary_search.cc:723] Sampled 57 candidate(s)
2023-05-01 21:38:45 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 121 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:38:54 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 132 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:39:02 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 131 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:39:10 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 114 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:39:12 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9299  0.8414  0.8327  0.8326  0.8326  0.8326  0.8325  0.8325  0.8290  0.8290  0.8278  0.8278  0.8278  0.8262  0.8262  0.8262
2023-05-01 21:39:12 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 21:39:12 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 21:46:03 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #689: GFLOPs: 86774.9043. Time: 101416.2800 us. Best GFLOPs: 113931.6298
2023-05-01 21:46:03 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #690: GFLOPs: 112416.5617. Time: 78283.7320 us. Best GFLOPs: 113931.6298
2023-05-01 21:46:03 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #691: GFLOPs: 94242.1498. Time: 93380.5947 us. Best GFLOPs: 113931.6298
2023-05-01 21:46:03 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #692: GFLOPs: 93078.2167. Time: 94548.3090 us. Best GFLOPs: 113931.6298
2023-05-01 21:46:03 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #693: GFLOPs: 92020.4710. Time: 95635.1113 us. Best GFLOPs: 113931.6298
2023-05-01 21:46:03 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #694: GFLOPs: 92140.8351. Time: 95510.1827 us. Best GFLOPs: 113931.6298
2023-05-01 21:46:03 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #695: GFLOPs: 93706.4326. Time: 93914.4490 us. Best GFLOPs: 113931.6298
2023-05-01 21:46:03 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #696: GFLOPs: 91900.4696. Time: 95759.9893 us. Best GFLOPs: 113931.6298
2023-05-01 21:46:03 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #697: GFLOPs: 93728.9101. Time: 93891.9270 us. Best GFLOPs: 113931.6298
2023-05-01 21:46:03 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #698: GFLOPs: 94184.9083. Time: 93437.3473 us. Best GFLOPs: 113931.6298
2023-05-01 21:46:03 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #699: GFLOPs: 93069.8151. Time: 94556.8440 us. Best GFLOPs: 113931.6298
2023-05-01 21:46:03 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #700: GFLOPs: 93083.2540. Time: 94543.1923 us. Best GFLOPs: 113931.6298
2023-05-01 21:46:03 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #701: GFLOPs: 92826.8757. Time: 94804.3110 us. Best GFLOPs: 113931.6298
2023-05-01 21:46:03 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #702: GFLOPs: 93938.5990. Time: 93682.3423 us. Best GFLOPs: 113931.6298
2023-05-01 21:46:03 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #703: GFLOPs: 93606.7443. Time: 94014.4650 us. Best GFLOPs: 113931.6298
2023-05-01 21:46:03 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #704: GFLOPs: 94231.5151. Time: 93391.1333 us. Best GFLOPs: 113931.6298
2023-05-01 21:46:03 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 21:46:04 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 21:46:08 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 402 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:46:12 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 803 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:46:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1206 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:46:19 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1604 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:46:22 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2002 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:46:26 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2403 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:46:26 [INFO] [evolutionary_search.cc:723] Sampled 57 candidate(s)
2023-05-01 21:46:33 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 133 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:46:42 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 151 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:46:50 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 123 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:46:59 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 131 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:47:01 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9305  0.8680  0.8342  0.8333  0.8333  0.8333  0.8326  0.8326  0.8326  0.8325  0.8290  0.8290  0.8290  0.8278  0.8278  0.8278
2023-05-01 21:47:01 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 21:47:01 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 21:53:52 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #705: GFLOPs: 92799.1344. Time: 94832.6517 us. Best GFLOPs: 113931.6298
2023-05-01 21:53:52 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #706: GFLOPs: 103604.8872. Time: 84941.8230 us. Best GFLOPs: 113931.6298
2023-05-01 21:53:52 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #707: GFLOPs: 96136.9288. Time: 91540.1407 us. Best GFLOPs: 113931.6298
2023-05-01 21:53:52 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #708: GFLOPs: 94933.3772. Time: 92700.6733 us. Best GFLOPs: 113931.6298
2023-05-01 21:53:52 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #709: GFLOPs: 94341.4481. Time: 93282.3077 us. Best GFLOPs: 113931.6298
2023-05-01 21:53:52 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #710: GFLOPs: 93194.2873. Time: 94430.5520 us. Best GFLOPs: 113931.6298
2023-05-01 21:53:52 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #711: GFLOPs: 93340.0453. Time: 94283.0910 us. Best GFLOPs: 113931.6298
2023-05-01 21:53:52 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #712: GFLOPs: 91892.2307. Time: 95768.5750 us. Best GFLOPs: 113931.6298
2023-05-01 21:53:52 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #713: GFLOPs: 92211.0271. Time: 95437.4793 us. Best GFLOPs: 113931.6298
2023-05-01 21:53:52 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #714: GFLOPs: 92139.5105. Time: 95511.5557 us. Best GFLOPs: 113931.6298
2023-05-01 21:53:52 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #715: GFLOPs: 94429.5650. Time: 93195.2613 us. Best GFLOPs: 113931.6298
2023-05-01 21:53:52 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #716: GFLOPs: 93145.8023. Time: 94479.7057 us. Best GFLOPs: 113931.6298
2023-05-01 21:53:52 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #717: GFLOPs: 91300.3095. Time: 96389.4650 us. Best GFLOPs: 113931.6298
2023-05-01 21:53:52 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #718: GFLOPs: 92354.3740. Time: 95289.3470 us. Best GFLOPs: 113931.6298
2023-05-01 21:53:52 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #719: GFLOPs: 92273.7270. Time: 95372.6297 us. Best GFLOPs: 113931.6298
2023-05-01 21:53:52 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #720: GFLOPs: 92593.5151. Time: 95043.2433 us. Best GFLOPs: 113931.6298
2023-05-01 21:53:52 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 21:53:53 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 21:53:57 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 400 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:54:00 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 800 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:54:04 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1207 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:54:07 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1609 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:54:11 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2007 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:54:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2410 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:54:15 [INFO] [evolutionary_search.cc:723] Sampled 50 candidate(s)
2023-05-01 21:54:22 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 132 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:54:30 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 117 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:54:38 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 122 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:54:46 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 91 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 21:54:48 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9299  0.9278  0.9170  0.9019  0.8680  0.8414  0.8342  0.8333  0.8333  0.8327  0.8327  0.8327  0.8327  0.8327  0.8325  0.8325
2023-05-01 21:54:48 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 21:54:48 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 22:01:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #721: GFLOPs: 112919.1926. Time: 77935.2720 us. Best GFLOPs: 113931.6298
2023-05-01 22:01:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #722: GFLOPs: 92526.3917. Time: 95112.1927 us. Best GFLOPs: 113931.6298
2023-05-01 22:01:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #723: GFLOPs: 104533.6455. Time: 84187.1337 us. Best GFLOPs: 113931.6298
2023-05-01 22:01:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #724: GFLOPs: 104601.4995. Time: 84132.5223 us. Best GFLOPs: 113931.6298
2023-05-01 22:01:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #725: GFLOPs: 112599.6261. Time: 78156.4583 us. Best GFLOPs: 113931.6298
2023-05-01 22:01:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #726: GFLOPs: 112071.0182. Time: 78525.1007 us. Best GFLOPs: 113931.6298
2023-05-01 22:01:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #727: GFLOPs: 89572.9371. Time: 98248.2910 us. Best GFLOPs: 113931.6298
2023-05-01 22:01:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #728: GFLOPs: 92672.4488. Time: 94962.2903 us. Best GFLOPs: 113931.6298
2023-05-01 22:01:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #729: GFLOPs: 93188.8964. Time: 94436.0147 us. Best GFLOPs: 113931.6298
2023-05-01 22:01:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #730: GFLOPs: 91976.1915. Time: 95681.1523 us. Best GFLOPs: 113931.6298
2023-05-01 22:01:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #731: GFLOPs: 93175.1060. Time: 94449.9917 us. Best GFLOPs: 113931.6298
2023-05-01 22:01:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #732: GFLOPs: 92852.9494. Time: 94777.6893 us. Best GFLOPs: 113931.6298
2023-05-01 22:01:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #733: GFLOPs: 90659.2108. Time: 97071.0853 us. Best GFLOPs: 113931.6298
2023-05-01 22:01:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #734: GFLOPs: 91033.0746. Time: 96672.4240 us. Best GFLOPs: 113931.6298
2023-05-01 22:01:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #735: GFLOPs: 92815.1839. Time: 94816.2533 us. Best GFLOPs: 113931.6298
2023-05-01 22:01:40 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #736: GFLOPs: 92326.2638. Time: 95318.3593 us. Best GFLOPs: 113931.6298
2023-05-01 22:01:40 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 22:01:41 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 22:01:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 396 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:01:49 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 795 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:01:52 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1193 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:01:56 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1595 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:01:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1991 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:01:59 [INFO] [evolutionary_search.cc:723] Sampled 59 candidate(s)
2023-05-01 22:02:07 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 124 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:02:15 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 116 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:02:23 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 123 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:02:32 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 141 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:02:34 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9735  0.9628  0.9299  0.8694  0.8531  0.8414  0.8342  0.8342  0.8333  0.8327  0.8327  0.8326  0.8326  0.8325  0.8290  0.8290
2023-05-01 22:02:34 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 22:02:34 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 22:09:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #737: GFLOPs: 109990.7733. Time: 80010.2383 us. Best GFLOPs: 113931.6298
2023-05-01 22:09:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #738: GFLOPs: 110138.3090. Time: 79903.0607 us. Best GFLOPs: 113931.6298
2023-05-01 22:09:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #739: GFLOPs: 103847.3392. Time: 84743.5097 us. Best GFLOPs: 113931.6298
2023-05-01 22:09:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #740: GFLOPs: 109653.0514. Time: 80256.6630 us. Best GFLOPs: 113931.6298
2023-05-01 22:09:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #741: GFLOPs: 82006.6204. Time: 107313.1407 us. Best GFLOPs: 113931.6298
2023-05-01 22:09:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #742: GFLOPs: 61011.9937. Time: 144240.2953 us. Best GFLOPs: 113931.6298
2023-05-01 22:09:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #743: GFLOPs: 93815.1942. Time: 93805.5723 us. Best GFLOPs: 113931.6298
2023-05-01 22:09:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #744: GFLOPs: 90610.4418. Time: 97123.3317 us. Best GFLOPs: 113931.6298
2023-05-01 22:09:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #745: GFLOPs: 91116.0764. Time: 96584.3607 us. Best GFLOPs: 113931.6298
2023-05-01 22:09:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #746: GFLOPs: 92015.8709. Time: 95639.8923 us. Best GFLOPs: 113931.6298
2023-05-01 22:09:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #747: GFLOPs: 93106.7863. Time: 94519.2970 us. Best GFLOPs: 113931.6298
2023-05-01 22:09:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #748: GFLOPs: 91455.4431. Time: 96225.9620 us. Best GFLOPs: 113931.6298
2023-05-01 22:09:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #749: GFLOPs: 90158.6106. Time: 97610.0667 us. Best GFLOPs: 113931.6298
2023-05-01 22:09:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #750: GFLOPs: 94534.8161. Time: 93091.5017 us. Best GFLOPs: 113931.6298
2023-05-01 22:09:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #751: GFLOPs: 93776.2964. Time: 93844.4823 us. Best GFLOPs: 113931.6298
2023-05-01 22:09:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #752: GFLOPs: 94680.2828. Time: 92948.4760 us. Best GFLOPs: 113931.6298
2023-05-01 22:09:25 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 22:09:26 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 22:09:30 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 402 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:09:33 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 801 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:09:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1206 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:09:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1607 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:09:44 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2008 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:09:48 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2407 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:09:48 [INFO] [evolutionary_search.cc:723] Sampled 53 candidate(s)
2023-05-01 22:09:55 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 158 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:10:04 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 112 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:10:12 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 110 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:10:20 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 108 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:10:22 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9278  0.9211  0.8610  0.8414  0.8333  0.8333  0.8327  0.8290  0.8290  0.8290  0.8290  0.8278  0.8278  0.8278  0.8278  0.8262
2023-05-01 22:10:22 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 22:10:22 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 22:17:13 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #753: GFLOPs: 98983.3333. Time: 88907.7757 us. Best GFLOPs: 113931.6298
2023-05-01 22:17:13 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #754: GFLOPs: 104886.1818. Time: 83904.1697 us. Best GFLOPs: 113931.6298
2023-05-01 22:17:13 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #755: GFLOPs: 104838.4154. Time: 83942.3980 us. Best GFLOPs: 113931.6298
2023-05-01 22:17:13 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #756: GFLOPs: 60942.0492. Time: 144405.8430 us. Best GFLOPs: 113931.6298
2023-05-01 22:17:13 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #757: GFLOPs: 94004.7030. Time: 93616.4650 us. Best GFLOPs: 113931.6298
2023-05-01 22:17:13 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #758: GFLOPs: 91239.2521. Time: 96453.9690 us. Best GFLOPs: 113931.6298
2023-05-01 22:17:13 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #759: GFLOPs: 91688.3423. Time: 95981.5367 us. Best GFLOPs: 113931.6298
2023-05-01 22:17:13 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #760: GFLOPs: 91742.8025. Time: 95924.5603 us. Best GFLOPs: 113931.6298
2023-05-01 22:17:13 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #761: GFLOPs: 91583.5036. Time: 96091.4100 us. Best GFLOPs: 113931.6298
2023-05-01 22:17:13 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #762: GFLOPs: 91056.2235. Time: 96647.8473 us. Best GFLOPs: 113931.6298
2023-05-01 22:17:13 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #763: GFLOPs: 92502.1630. Time: 95137.1050 us. Best GFLOPs: 113931.6298
2023-05-01 22:17:13 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #764: GFLOPs: 92935.2812. Time: 94693.7253 us. Best GFLOPs: 113931.6298
2023-05-01 22:17:13 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #765: GFLOPs: 92220.6011. Time: 95427.5713 us. Best GFLOPs: 113931.6298
2023-05-01 22:17:13 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #766: GFLOPs: 92650.7430. Time: 94984.5377 us. Best GFLOPs: 113931.6298
2023-05-01 22:17:13 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #767: GFLOPs: 93442.8804. Time: 94179.3313 us. Best GFLOPs: 113931.6298
2023-05-01 22:17:13 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #768: GFLOPs: 90354.1881. Time: 97398.7833 us. Best GFLOPs: 113931.6298
2023-05-01 22:17:13 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 22:17:14 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 22:17:18 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 394 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:17:21 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 794 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:17:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1195 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:17:28 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1592 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:17:32 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1989 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:17:32 [INFO] [evolutionary_search.cc:723] Sampled 61 candidate(s)
2023-05-01 22:17:39 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 127 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:17:48 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 134 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:17:56 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 119 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:18:04 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 122 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:18:06 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9400  0.9286  0.9286  0.9284  0.9248  0.9136  0.9032  0.8670  0.8490  0.8490  0.8436  0.8402  0.8229  0.8187  0.8187  0.8187
2023-05-01 22:18:06 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 22:18:06 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 22:24:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #769: GFLOPs: 111038.1589. Time: 79255.5287 us. Best GFLOPs: 113931.6298
2023-05-01 22:24:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #770: GFLOPs: 106699.7746. Time: 82478.0373 us. Best GFLOPs: 113931.6298
2023-05-01 22:24:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #771: GFLOPs: 102495.7153. Time: 85861.0330 us. Best GFLOPs: 113931.6298
2023-05-01 22:24:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #772: GFLOPs: 85152.7729. Time: 103348.2257 us. Best GFLOPs: 113931.6298
2023-05-01 22:24:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #773: GFLOPs: 104262.6751. Time: 84405.9293 us. Best GFLOPs: 113931.6298
2023-05-01 22:24:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #774: GFLOPs: 110315.0281. Time: 79775.0600 us. Best GFLOPs: 113931.6298
2023-05-01 22:24:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #775: GFLOPs: 110441.6697. Time: 79683.5833 us. Best GFLOPs: 113931.6298
2023-05-01 22:24:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #776: GFLOPs: 110215.0548. Time: 79847.4220 us. Best GFLOPs: 113931.6298
2023-05-01 22:24:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #777: GFLOPs: 111783.8526. Time: 78726.8267 us. Best GFLOPs: 113931.6298
2023-05-01 22:24:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #778: GFLOPs: 111630.9132. Time: 78834.6860 us. Best GFLOPs: 113931.6298
2023-05-01 22:24:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #779: GFLOPs: 111130.9804. Time: 79189.3310 us. Best GFLOPs: 113931.6298
2023-05-01 22:24:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #780: GFLOPs: 111136.2484. Time: 79185.5773 us. Best GFLOPs: 113931.6298
2023-05-01 22:24:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #781: GFLOPs: 89524.9779. Time: 98300.9233 us. Best GFLOPs: 113931.6298
2023-05-01 22:24:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #782: GFLOPs: 90978.5253. Time: 96730.3873 us. Best GFLOPs: 113931.6298
2023-05-01 22:24:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #783: GFLOPs: 94111.7625. Time: 93509.9690 us. Best GFLOPs: 113931.6298
2023-05-01 22:24:57 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #784: GFLOPs: 90069.1560. Time: 97707.0107 us. Best GFLOPs: 113931.6298
2023-05-01 22:24:57 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 22:24:59 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 22:25:02 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 403 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:25:06 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 808 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:25:09 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1211 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:25:13 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1615 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:25:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2014 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:25:20 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2408 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:25:20 [INFO] [evolutionary_search.cc:723] Sampled 52 candidate(s)
2023-05-01 22:25:28 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 152 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:25:36 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 131 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:25:44 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 114 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:25:53 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 111 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:25:54 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9402  0.9402  0.9387  0.9387  0.9286  0.9284  0.9231  0.9218  0.9151  0.9136  0.9136  0.9032  0.9032  0.8490  0.8456  0.8187
2023-05-01 22:25:55 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 22:25:55 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 22:32:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #785: GFLOPs: 93909.1699. Time: 93711.7003 us. Best GFLOPs: 113931.6298
2023-05-01 22:32:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #786: GFLOPs: 93001.3296. Time: 94626.4750 us. Best GFLOPs: 113931.6298
2023-05-01 22:32:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #787: GFLOPs: 110351.8536. Time: 79748.4383 us. Best GFLOPs: 113931.6298
2023-05-01 22:32:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #788: GFLOPs: 110522.6300. Time: 79625.2133 us. Best GFLOPs: 113931.6298
2023-05-01 22:32:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #789: GFLOPs: 103785.4709. Time: 84794.0267 us. Best GFLOPs: 113931.6298
2023-05-01 22:32:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #790: GFLOPs: 95915.5467. Time: 91751.4240 us. Best GFLOPs: 113931.6298
2023-05-01 22:32:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #791: GFLOPs: 94741.5102. Time: 92888.4073 us. Best GFLOPs: 113931.6298
2023-05-01 22:32:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #792: GFLOPs: 109642.7674. Time: 80264.1907 us. Best GFLOPs: 113931.6298
2023-05-01 22:32:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #793: GFLOPs: 93532.7236. Time: 94088.8670 us. Best GFLOPs: 113931.6298
2023-05-01 22:32:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #794: GFLOPs: 109903.0920. Time: 80074.0710 us. Best GFLOPs: 113931.6298
2023-05-01 22:32:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #795: GFLOPs: 110048.5795. Time: 79968.2107 us. Best GFLOPs: 113931.6298
2023-05-01 22:32:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #796: GFLOPs: 111962.0054. Time: 78601.5573 us. Best GFLOPs: 113931.6298
2023-05-01 22:32:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #797: GFLOPs: 111054.8648. Time: 79243.6063 us. Best GFLOPs: 113931.6298
2023-05-01 22:32:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #798: GFLOPs: 109942.9328. Time: 80045.0540 us. Best GFLOPs: 113931.6298
2023-05-01 22:32:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #799: GFLOPs: 81361.9678. Time: 108163.4113 us. Best GFLOPs: 113931.6298
2023-05-01 22:32:45 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #800: GFLOPs: 94806.3080. Time: 92824.9203 us. Best GFLOPs: 113931.6298
2023-05-01 22:32:45 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 22:32:46 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 22:32:50 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 407 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:32:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 806 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:32:57 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1208 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:33:01 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1606 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:33:04 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2000 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:33:04 [INFO] [evolutionary_search.cc:723] Sampled 50 candidate(s)
2023-05-01 22:33:12 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 133 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:33:20 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 112 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:33:28 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 111 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:33:37 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 125 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:33:39 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9671  0.9671  0.9387  0.9387  0.9218  0.9136  0.8741  0.8670  0.8490  0.8456  0.8402  0.8187  0.8183  0.8181  0.8172  0.8152
2023-05-01 22:33:39 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 22:33:39 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 22:40:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #801: GFLOPs: 110739.0934. Time: 79469.5687 us. Best GFLOPs: 113931.6298
2023-05-01 22:40:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #802: GFLOPs: 110829.5413. Time: 79404.7137 us. Best GFLOPs: 113931.6298
2023-05-01 22:40:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #803: GFLOPs: 110637.4017. Time: 79542.6127 us. Best GFLOPs: 113931.6298
2023-05-01 22:40:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #804: GFLOPs: 110167.9590. Time: 79881.5560 us. Best GFLOPs: 113931.6298
2023-05-01 22:40:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #805: GFLOPs: 109993.5842. Time: 80008.1937 us. Best GFLOPs: 113931.6298
2023-05-01 22:40:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #806: GFLOPs: 109347.0218. Time: 80481.2773 us. Best GFLOPs: 113931.6298
2023-05-01 22:40:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #807: GFLOPs: 110001.0104. Time: 80002.7923 us. Best GFLOPs: 113931.6298
2023-05-01 22:40:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #808: GFLOPs: 110912.0238. Time: 79345.6623 us. Best GFLOPs: 113931.6298
2023-05-01 22:40:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #809: GFLOPs: 60256.5367. Time: 146048.6857 us. Best GFLOPs: 113931.6298
2023-05-01 22:40:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #810: GFLOPs: 103983.8812. Time: 84632.2323 us. Best GFLOPs: 113931.6298
2023-05-01 22:40:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #811: GFLOPs: 109602.2134. Time: 80293.8893 us. Best GFLOPs: 113931.6298
2023-05-01 22:40:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #812: GFLOPs: 89484.5755. Time: 98345.3063 us. Best GFLOPs: 113931.6298
2023-05-01 22:40:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #813: GFLOPs: 94000.9236. Time: 93620.2290 us. Best GFLOPs: 113931.6298
2023-05-01 22:40:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #814: GFLOPs: 90556.3790. Time: 97181.3150 us. Best GFLOPs: 113931.6298
2023-05-01 22:40:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #815: GFLOPs: 92118.7694. Time: 95533.0607 us. Best GFLOPs: 113931.6298
2023-05-01 22:40:30 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #816: GFLOPs: 94139.9356. Time: 93481.9843 us. Best GFLOPs: 113931.6298
2023-05-01 22:40:30 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 22:40:31 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 22:40:35 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 403 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:40:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 800 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:40:42 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1198 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:40:46 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1598 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:40:49 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2001 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:40:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2400 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:40:53 [INFO] [evolutionary_search.cc:723] Sampled 60 candidate(s)
2023-05-01 22:41:00 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 140 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:41:09 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 136 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:41:17 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 110 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:41:25 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 106 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:41:27 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9387  0.9151  0.8670  0.8490  0.8456  0.8183  0.8158  0.8152  0.8152  0.8152  0.8152  0.8152  0.8152  0.8140  0.8103  0.8103
2023-05-01 22:41:27 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 22:41:27 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 22:48:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #817: GFLOPs: 111515.9976. Time: 78915.9240 us. Best GFLOPs: 113931.6298
2023-05-01 22:48:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #818: GFLOPs: 96883.2914. Time: 90834.9403 us. Best GFLOPs: 113931.6298
2023-05-01 22:48:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #819: GFLOPs: 61064.0123. Time: 144117.4213 us. Best GFLOPs: 113931.6298
2023-05-01 22:48:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #820: GFLOPs: 112545.6025. Time: 78193.9747 us. Best GFLOPs: 113931.6298
2023-05-01 22:48:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #821: GFLOPs: 103950.3394. Time: 84659.5407 us. Best GFLOPs: 113931.6298
2023-05-01 22:48:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #822: GFLOPs: 93869.8480. Time: 93750.9560 us. Best GFLOPs: 113931.6298
2023-05-01 22:48:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #823: GFLOPs: 94674.0244. Time: 92954.6203 us. Best GFLOPs: 113931.6298
2023-05-01 22:48:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #824: GFLOPs: 90812.4670. Time: 96907.2670 us. Best GFLOPs: 113931.6298
2023-05-01 22:48:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #825: GFLOPs: 90775.3806. Time: 96946.8587 us. Best GFLOPs: 113931.6298
2023-05-01 22:48:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #826: GFLOPs: 91356.8948. Time: 96329.7627 us. Best GFLOPs: 113931.6298
2023-05-01 22:48:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #827: GFLOPs: 89921.2001. Time: 97867.7773 us. Best GFLOPs: 113931.6298
2023-05-01 22:48:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #828: GFLOPs: 93218.2170. Time: 94406.3110 us. Best GFLOPs: 113931.6298
2023-05-01 22:48:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #829: GFLOPs: 94703.2299. Time: 92925.9540 us. Best GFLOPs: 113931.6298
2023-05-01 22:48:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #830: GFLOPs: 91621.1949. Time: 96051.8797 us. Best GFLOPs: 113931.6298
2023-05-01 22:48:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #831: GFLOPs: 112120.2421. Time: 78490.6260 us. Best GFLOPs: 113931.6298
2023-05-01 22:48:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #832: GFLOPs: 113254.4985. Time: 77704.5337 us. Best GFLOPs: 113931.6298
2023-05-01 22:48:18 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 22:48:19 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 22:48:23 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 404 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:48:27 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 804 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:48:30 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1206 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:48:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1609 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:48:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2009 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:48:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2405 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:48:41 [INFO] [evolutionary_search.cc:723] Sampled 55 candidate(s)
2023-05-01 22:48:48 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 117 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:48:57 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 146 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:49:05 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 126 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:49:13 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 98 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:49:15 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9387  0.9218  0.9136  0.9136  0.8403  0.8317  0.8187  0.8172  0.8172  0.8152  0.8152  0.8152  0.8142  0.8140  0.8103  0.8103
2023-05-01 22:49:15 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 22:49:15 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 22:56:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #833: GFLOPs: 109646.9781. Time: 80261.1083 us. Best GFLOPs: 113931.6298
2023-05-01 22:56:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #834: GFLOPs: 110304.2192. Time: 79782.8773 us. Best GFLOPs: 113931.6298
2023-05-01 22:56:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #835: GFLOPs: 110109.6417. Time: 79923.8637 us. Best GFLOPs: 113931.6298
2023-05-01 22:56:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #836: GFLOPs: 109021.9939. Time: 80721.2167 us. Best GFLOPs: 113931.6298
2023-05-01 22:56:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #837: GFLOPs: 104363.5429. Time: 84324.3507 us. Best GFLOPs: 113931.6298
2023-05-01 22:56:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #838: GFLOPs: 97533.1012. Time: 90229.7567 us. Best GFLOPs: 113931.6298
2023-05-01 22:56:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #839: GFLOPs: 90321.2186. Time: 97434.3363 us. Best GFLOPs: 113931.6298
2023-05-01 22:56:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #840: GFLOPs: 88620.2842. Time: 99304.4433 us. Best GFLOPs: 113931.6298
2023-05-01 22:56:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #841: GFLOPs: 87911.9474. Time: 100104.5733 us. Best GFLOPs: 113931.6298
2023-05-01 22:56:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #842: GFLOPs: 93798.8178. Time: 93821.9500 us. Best GFLOPs: 113931.6298
2023-05-01 22:56:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #843: GFLOPs: 91698.0998. Time: 95971.3233 us. Best GFLOPs: 113931.6298
2023-05-01 22:56:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #844: GFLOPs: 89867.9191. Time: 97925.8013 us. Best GFLOPs: 113931.6298
2023-05-01 22:56:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #845: GFLOPs: 94857.2341. Time: 92775.0853 us. Best GFLOPs: 113931.6298
2023-05-01 22:56:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #846: GFLOPs: 91289.6443. Time: 96400.7260 us. Best GFLOPs: 113931.6298
2023-05-01 22:56:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #847: GFLOPs: 112516.0856. Time: 78214.4877 us. Best GFLOPs: 113931.6298
2023-05-01 22:56:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #848: GFLOPs: 111960.0640. Time: 78602.9203 us. Best GFLOPs: 113931.6298
2023-05-01 22:56:05 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 22:56:07 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 22:56:10 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 403 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:56:14 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 804 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:56:18 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1203 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:56:21 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1607 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:56:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2007 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:56:28 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2407 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:56:28 [INFO] [evolutionary_search.cc:723] Sampled 53 candidate(s)
2023-05-01 22:56:36 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 128 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:56:44 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 145 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:56:53 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 136 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:57:01 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 102 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 22:57:03 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9387  0.9231  0.9136  0.9032  0.9032  0.8886  0.8706  0.8456  0.8403  0.8308  0.8308  0.8250  0.8181  0.8172  0.8159  0.8152
2023-05-01 22:57:03 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 22:57:03 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 23:03:54 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #849: GFLOPs: 111646.3782. Time: 78823.7660 us. Best GFLOPs: 113931.6298
2023-05-01 23:03:54 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #850: GFLOPs: 85911.2186. Time: 102435.8417 us. Best GFLOPs: 113931.6298
2023-05-01 23:03:54 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #851: GFLOPs: 110127.0156. Time: 79911.2547 us. Best GFLOPs: 113931.6298
2023-05-01 23:03:54 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #852: GFLOPs: 108067.0063. Time: 81434.5497 us. Best GFLOPs: 113931.6298
2023-05-01 23:03:54 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #853: GFLOPs: 110603.7016. Time: 79566.8487 us. Best GFLOPs: 113931.6298
2023-05-01 23:03:54 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #854: GFLOPs: 81603.5422. Time: 107843.2107 us. Best GFLOPs: 113931.6298
2023-05-01 23:03:54 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #855: GFLOPs: 81907.8896. Time: 107442.4947 us. Best GFLOPs: 113931.6298
2023-05-01 23:03:54 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #856: GFLOPs: 103966.7234. Time: 84646.1993 us. Best GFLOPs: 113931.6298
2023-05-01 23:03:54 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #857: GFLOPs: 104238.6739. Time: 84425.3640 us. Best GFLOPs: 113931.6298
2023-05-01 23:03:54 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #858: GFLOPs: 69316.8079. Time: 126958.9333 us. Best GFLOPs: 113931.6298
2023-05-01 23:03:54 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #859: GFLOPs: 88975.9595. Time: 98907.4807 us. Best GFLOPs: 113931.6298
2023-05-01 23:03:54 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #860: GFLOPs: 88782.3239. Time: 99123.1993 us. Best GFLOPs: 113931.6298
2023-05-01 23:03:54 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #861: GFLOPs: 92516.8134. Time: 95122.0397 us. Best GFLOPs: 113931.6298
2023-05-01 23:03:54 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #862: GFLOPs: 97290.2036. Time: 90455.0270 us. Best GFLOPs: 113931.6298
2023-05-01 23:03:54 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #863: GFLOPs: 88684.9037. Time: 99232.0860 us. Best GFLOPs: 113931.6298
2023-05-01 23:03:54 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #864: GFLOPs: 91394.1682. Time: 96290.4763 us. Best GFLOPs: 113931.6298
2023-05-01 23:03:54 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 23:03:55 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 23:03:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 403 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:04:03 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 804 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:04:06 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1206 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:04:10 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1608 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:04:13 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2008 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:04:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2407 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:04:17 [INFO] [evolutionary_search.cc:723] Sampled 53 candidate(s)
2023-05-01 23:04:24 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 101 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:04:32 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 121 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:04:41 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 135 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:04:49 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 120 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:04:51 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9400  0.9191  0.9139  0.8741  0.8379  0.8181  0.8142  0.8140  0.8140  0.8103  0.8103  0.8103  0.8099  0.8099  0.8099  0.8099
2023-05-01 23:04:51 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 23:04:51 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 23:11:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #865: GFLOPs: 111325.8137. Time: 79050.7403 us. Best GFLOPs: 113931.6298
2023-05-01 23:11:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #866: GFLOPs: 104723.8608. Time: 84034.2203 us. Best GFLOPs: 113931.6298
2023-05-01 23:11:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #867: GFLOPs: 104335.2984. Time: 84347.1780 us. Best GFLOPs: 113931.6298
2023-05-01 23:11:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #868: GFLOPs: 109565.8869. Time: 80320.5107 us. Best GFLOPs: 113931.6298
2023-05-01 23:11:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #869: GFLOPs: 78720.0345. Time: 111793.4977 us. Best GFLOPs: 113931.6298
2023-05-01 23:11:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #870: GFLOPs: 91923.3586. Time: 95736.1450 us. Best GFLOPs: 113931.6298
2023-05-01 23:11:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #871: GFLOPs: 89914.9570. Time: 97874.5727 us. Best GFLOPs: 113931.6298
2023-05-01 23:11:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #872: GFLOPs: 91768.9226. Time: 95897.2573 us. Best GFLOPs: 113931.6298
2023-05-01 23:11:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #873: GFLOPs: 92544.6634. Time: 95093.4140 us. Best GFLOPs: 113931.6298
2023-05-01 23:11:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #874: GFLOPs: 112461.6232. Time: 78252.3650 us. Best GFLOPs: 113931.6298
2023-05-01 23:11:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #875: GFLOPs: 112694.1675. Time: 78090.8913 us. Best GFLOPs: 113931.6298
2023-05-01 23:11:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #876: GFLOPs: 112873.2112. Time: 77967.0207 us. Best GFLOPs: 113931.6298
2023-05-01 23:11:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #877: GFLOPs: 111663.3035. Time: 78811.8183 us. Best GFLOPs: 113931.6298
2023-05-01 23:11:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #878: GFLOPs: 112455.7245. Time: 78256.4697 us. Best GFLOPs: 113931.6298
2023-05-01 23:11:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #879: GFLOPs: 112304.3612. Time: 78361.9433 us. Best GFLOPs: 113931.6298
2023-05-01 23:11:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #880: GFLOPs: 112681.3166. Time: 78099.7973 us. Best GFLOPs: 113931.6298
2023-05-01 23:11:41 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 23:11:42 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 23:11:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 396 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:11:49 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 792 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:11:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1191 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:11:56 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1588 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:11:56 [INFO] [evolutionary_search.cc:723] Sampled 52 candidate(s)
2023-05-01 23:12:04 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 138 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:12:12 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 117 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:12:20 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 130 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:12:29 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 123 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:12:31 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9722  0.9695  0.9218  0.8813  0.8456  0.8159  0.8142  0.8142  0.8103  0.8103  0.8099  0.8099  0.8099  0.8099  0.8097  0.8088
2023-05-01 23:12:31 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 23:12:31 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 23:19:21 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #881: GFLOPs: 110584.7285. Time: 79580.5000 us. Best GFLOPs: 113931.6298
2023-05-01 23:19:21 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #882: GFLOPs: 111031.9098. Time: 79259.9893 us. Best GFLOPs: 113931.6298
2023-05-01 23:19:21 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #883: GFLOPs: 110161.9408. Time: 79885.9200 us. Best GFLOPs: 113931.6298
2023-05-01 23:19:21 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #884: GFLOPs: 101022.6171. Time: 87113.0470 us. Best GFLOPs: 113931.6298
2023-05-01 23:19:21 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #885: GFLOPs: 104144.7481. Time: 84501.5053 us. Best GFLOPs: 113931.6298
2023-05-01 23:19:21 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #886: GFLOPs: 88842.6268. Time: 99055.9183 us. Best GFLOPs: 113931.6298
2023-05-01 23:19:21 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #887: GFLOPs: 94410.5415. Time: 93214.0400 us. Best GFLOPs: 113931.6298
2023-05-01 23:19:21 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #888: GFLOPs: 91650.1779. Time: 96021.5047 us. Best GFLOPs: 113931.6298
2023-05-01 23:19:21 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #889: GFLOPs: 111809.0629. Time: 78709.0757 us. Best GFLOPs: 113931.6298
2023-05-01 23:19:21 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #890: GFLOPs: 112091.0283. Time: 78511.0827 us. Best GFLOPs: 113931.6298
2023-05-01 23:19:21 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #891: GFLOPs: 112801.6107. Time: 78016.5100 us. Best GFLOPs: 113931.6298
2023-05-01 23:19:21 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #892: GFLOPs: 110940.7190. Time: 79325.1393 us. Best GFLOPs: 113931.6298
2023-05-01 23:19:21 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #893: GFLOPs: 112583.3976. Time: 78167.7243 us. Best GFLOPs: 113931.6298
2023-05-01 23:19:21 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #894: GFLOPs: 112055.9215. Time: 78535.6800 us. Best GFLOPs: 113931.6298
2023-05-01 23:19:21 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #895: GFLOPs: 113104.9859. Time: 77807.2507 us. Best GFLOPs: 113931.6298
2023-05-01 23:19:21 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #896: GFLOPs: 110128.9009. Time: 79909.8867 us. Best GFLOPs: 113931.6298
2023-05-01 23:19:21 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 23:19:23 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 23:19:26 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 403 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:19:30 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 797 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:19:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1194 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:19:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1596 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:19:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1992 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:19:41 [INFO] [evolutionary_search.cc:723] Sampled 58 candidate(s)
2023-05-01 23:19:48 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 134 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:19:56 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 108 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:20:05 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 102 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:20:13 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 113 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:20:15 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9151  0.9151  0.9032  0.8490  0.8490  0.8436  0.8436  0.8181  0.8172  0.8142  0.8099  0.8099  0.8099  0.8097  0.8097  0.8097
2023-05-01 23:20:15 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 23:20:15 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 23:27:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #897: GFLOPs: 79608.9661. Time: 110545.1863 us. Best GFLOPs: 113931.6298
2023-05-01 23:27:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #898: GFLOPs: 110261.2417. Time: 79813.9750 us. Best GFLOPs: 113931.6298
2023-05-01 23:27:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #899: GFLOPs: 110445.9276. Time: 79680.5113 us. Best GFLOPs: 113931.6298
2023-05-01 23:27:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #900: GFLOPs: 112667.5296. Time: 78109.3543 us. Best GFLOPs: 113931.6298
2023-05-01 23:27:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #901: GFLOPs: 112297.0283. Time: 78367.0603 us. Best GFLOPs: 113931.6298
2023-05-01 23:27:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #902: GFLOPs: 110882.9244. Time: 79366.4853 us. Best GFLOPs: 113931.6298
2023-05-01 23:27:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #903: GFLOPs: 109972.0026. Time: 80023.8950 us. Best GFLOPs: 113931.6298
2023-05-01 23:27:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #904: GFLOPs: 89765.2900. Time: 98037.7603 us. Best GFLOPs: 113931.6298
2023-05-01 23:27:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #905: GFLOPs: 92188.9671. Time: 95460.3167 us. Best GFLOPs: 113931.6298
2023-05-01 23:27:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #906: GFLOPs: 90125.5584. Time: 97645.8637 us. Best GFLOPs: 113931.6298
2023-05-01 23:27:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #907: GFLOPs: 111849.3216. Time: 78680.7453 us. Best GFLOPs: 113931.6298
2023-05-01 23:27:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #908: GFLOPs: 112000.4316. Time: 78574.5900 us. Best GFLOPs: 113931.6298
2023-05-01 23:27:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #909: GFLOPs: 112385.6308. Time: 78305.2773 us. Best GFLOPs: 113931.6298
2023-05-01 23:27:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #910: GFLOPs: 113203.2812. Time: 77739.6900 us. Best GFLOPs: 113931.6298
2023-05-01 23:27:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #911: GFLOPs: 111457.1782. Time: 78957.5703 us. Best GFLOPs: 113931.6298
2023-05-01 23:27:05 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #912: GFLOPs: 112600.6740. Time: 78155.7310 us. Best GFLOPs: 113931.6298
2023-05-01 23:27:05 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 23:27:07 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 23:27:10 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 403 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:27:14 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 801 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:27:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1205 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:27:21 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1606 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:27:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2006 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:27:28 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2402 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:27:28 [INFO] [evolutionary_search.cc:723] Sampled 58 candidate(s)
2023-05-01 23:27:36 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 121 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:27:44 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 117 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:27:52 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 137 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:28:01 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 120 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:28:03 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9683  0.9671  0.9402  0.9400  0.9218  0.9136  0.8741  0.8490  0.8158  0.8152  0.8152  0.8103  0.8103  0.8099  0.8099  0.8097
2023-05-01 23:28:03 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 23:28:03 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 23:34:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #913: GFLOPs: 110840.4962. Time: 79396.8657 us. Best GFLOPs: 113931.6298
2023-05-01 23:34:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #914: GFLOPs: 110835.2562. Time: 79400.6193 us. Best GFLOPs: 113931.6298
2023-05-01 23:34:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #915: GFLOPs: 92577.8396. Time: 95059.3363 us. Best GFLOPs: 113931.6298
2023-05-01 23:34:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #916: GFLOPs: 110288.1323. Time: 79794.5147 us. Best GFLOPs: 113931.6298
2023-05-01 23:34:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #917: GFLOPs: 110093.1000. Time: 79935.8723 us. Best GFLOPs: 113931.6298
2023-05-01 23:34:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #918: GFLOPs: 109740.2994. Time: 80192.8557 us. Best GFLOPs: 113931.6298
2023-05-01 23:34:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #919: GFLOPs: 111714.5862. Time: 78775.6397 us. Best GFLOPs: 113931.6298
2023-05-01 23:34:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #920: GFLOPs: 60257.8043. Time: 146045.6133 us. Best GFLOPs: 113931.6298
2023-05-01 23:34:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #921: GFLOPs: 94315.3031. Time: 93308.1663 us. Best GFLOPs: 113931.6298
2023-05-01 23:34:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #922: GFLOPs: 93425.9575. Time: 94196.3907 us. Best GFLOPs: 113931.6298
2023-05-01 23:34:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #923: GFLOPs: 90406.7816. Time: 97342.1223 us. Best GFLOPs: 113931.6298
2023-05-01 23:34:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #924: GFLOPs: 112400.7874. Time: 78294.7183 us. Best GFLOPs: 113931.6298
2023-05-01 23:34:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #925: GFLOPs: 113427.8924. Time: 77585.7490 us. Best GFLOPs: 113931.6298
2023-05-01 23:34:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #926: GFLOPs: 112198.8011. Time: 78435.6687 us. Best GFLOPs: 113931.6298
2023-05-01 23:34:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #927: GFLOPs: 112228.6975. Time: 78414.7743 us. Best GFLOPs: 113931.6298
2023-05-01 23:34:53 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #928: GFLOPs: 113076.7043. Time: 77826.7110 us. Best GFLOPs: 113931.6298
2023-05-01 23:34:53 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 23:34:54 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 23:34:58 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 403 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:35:02 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 803 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:35:05 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1198 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:35:09 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1595 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:35:12 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1997 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:35:12 [INFO] [evolutionary_search.cc:723] Sampled 53 candidate(s)
2023-05-01 23:35:20 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 142 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:35:28 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 96 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:35:36 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 139 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:35:45 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 94 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:35:46 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9846  0.9835  0.9835  0.9835  0.9800  0.9800  0.9800  0.9800  0.9800  0.9800  0.9800  0.9800  0.9800  0.9800  0.9800  0.9800
2023-05-01 23:35:47 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 23:35:47 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 23:42:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #929: GFLOPs: 113716.5598. Time: 77388.7990 us. Best GFLOPs: 113931.6298
2023-05-01 23:42:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #930: GFLOPs: 114246.1531. Time: 77030.0597 us. Best GFLOPs: 114246.1531
2023-05-01 23:42:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #931: GFLOPs: 113882.8194. Time: 77275.8177 us. Best GFLOPs: 114246.1531
2023-05-01 23:42:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #932: GFLOPs: 112922.6488. Time: 77932.8867 us. Best GFLOPs: 114246.1531
2023-05-01 23:42:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #933: GFLOPs: 113396.5730. Time: 77607.1777 us. Best GFLOPs: 114246.1531
2023-05-01 23:42:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #934: GFLOPs: 112976.0909. Time: 77896.0213 us. Best GFLOPs: 114246.1531
2023-05-01 23:42:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #935: GFLOPs: 111960.5492. Time: 78602.5797 us. Best GFLOPs: 114246.1531
2023-05-01 23:42:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #936: GFLOPs: 112998.3731. Time: 77880.6610 us. Best GFLOPs: 114246.1531
2023-05-01 23:42:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #937: GFLOPs: 112422.3831. Time: 78279.6783 us. Best GFLOPs: 114246.1531
2023-05-01 23:42:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #938: GFLOPs: 112558.3346. Time: 78185.1297 us. Best GFLOPs: 114246.1531
2023-05-01 23:42:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #939: GFLOPs: 111976.5915. Time: 78591.3187 us. Best GFLOPs: 114246.1531
2023-05-01 23:42:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #940: GFLOPs: 110719.1243. Time: 79483.9017 us. Best GFLOPs: 114246.1531
2023-05-01 23:42:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #941: GFLOPs: 113257.9825. Time: 77702.1433 us. Best GFLOPs: 114246.1531
2023-05-01 23:42:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #942: GFLOPs: 112770.0485. Time: 78038.3453 us. Best GFLOPs: 114246.1531
2023-05-01 23:42:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #943: GFLOPs: 111055.3567. Time: 79243.2553 us. Best GFLOPs: 114246.1531
2023-05-01 23:42:37 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #944: GFLOPs: 113465.3297. Time: 77560.1500 us. Best GFLOPs: 114246.1531
2023-05-01 23:42:37 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 23:42:38 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 23:42:42 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 395 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:42:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 792 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:42:49 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1190 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:42:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1592 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:42:56 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1996 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:42:56 [INFO] [evolutionary_search.cc:723] Sampled 54 candidate(s)
2023-05-01 23:43:04 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 136 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:43:12 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 143 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:43:20 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 127 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:43:29 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 136 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:43:31 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9846  0.9846  0.9835  0.9835  0.9835  0.9825  0.9800  0.9800  0.9800  0.9800  0.9800  0.9800  0.9800  0.9800  0.9800  0.9800
2023-05-01 23:43:31 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 23:43:31 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 23:50:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #945: GFLOPs: 115425.6037. Time: 76242.9453 us. Best GFLOPs: 115425.6037
2023-05-01 23:50:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #946: GFLOPs: 113433.3804. Time: 77581.9953 us. Best GFLOPs: 115425.6037
2023-05-01 23:50:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #947: GFLOPs: 111355.6266. Time: 79029.5763 us. Best GFLOPs: 115425.6037
2023-05-01 23:50:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #948: GFLOPs: 112232.4975. Time: 78412.1193 us. Best GFLOPs: 115425.6037
2023-05-01 23:50:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #949: GFLOPs: 112538.1872. Time: 78199.1270 us. Best GFLOPs: 115425.6037
2023-05-01 23:50:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #950: GFLOPs: 112633.5638. Time: 78132.9090 us. Best GFLOPs: 115425.6037
2023-05-01 23:50:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #951: GFLOPs: 112371.4196. Time: 78315.1803 us. Best GFLOPs: 115425.6037
2023-05-01 23:50:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #952: GFLOPs: 111488.5700. Time: 78935.3383 us. Best GFLOPs: 115425.6037
2023-05-01 23:50:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #953: GFLOPs: 112944.0329. Time: 77918.1313 us. Best GFLOPs: 115425.6037
2023-05-01 23:50:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #954: GFLOPs: 112215.9959. Time: 78423.6500 us. Best GFLOPs: 115425.6037
2023-05-01 23:50:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #955: GFLOPs: 112652.7629. Time: 78119.5930 us. Best GFLOPs: 115425.6037
2023-05-01 23:50:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #956: GFLOPs: 111385.5268. Time: 79008.3617 us. Best GFLOPs: 115425.6037
2023-05-01 23:50:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #957: GFLOPs: 112014.0563. Time: 78565.0327 us. Best GFLOPs: 115425.6037
2023-05-01 23:50:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #958: GFLOPs: 111860.8772. Time: 78672.6173 us. Best GFLOPs: 115425.6037
2023-05-01 23:50:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #959: GFLOPs: 112678.8581. Time: 78101.5013 us. Best GFLOPs: 115425.6037
2023-05-01 23:50:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #960: GFLOPs: 113319.2082. Time: 77660.1613 us. Best GFLOPs: 115425.6037
2023-05-01 23:50:22 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 23:50:24 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 23:50:27 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 404 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:50:31 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 801 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:50:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1203 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:50:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1601 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:50:42 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2000 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:50:42 [INFO] [evolutionary_search.cc:723] Sampled 50 candidate(s)
2023-05-01 23:50:49 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 113 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:50:57 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 122 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:51:05 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 112 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:51:14 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 113 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:51:16 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9846  0.9835  0.9835  0.9835  0.9835  0.9835  0.9835  0.9800  0.9800  0.9792  0.9792  0.9792  0.9792  0.9792  0.9792  0.9792
2023-05-01 23:51:16 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 23:51:16 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-01 23:58:04 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #961: GFLOPs: 115270.2695. Time: 76345.6877 us. Best GFLOPs: 115425.6037
2023-05-01 23:58:04 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #962: GFLOPs: 111704.9073. Time: 78782.4653 us. Best GFLOPs: 115425.6037
2023-05-01 23:58:04 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #963: GFLOPs: 114436.8191. Time: 76901.7180 us. Best GFLOPs: 115425.6037
2023-05-01 23:58:04 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #964: GFLOPs: 112748.8703. Time: 78053.0037 us. Best GFLOPs: 115425.6037
2023-05-01 23:58:04 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #965: GFLOPs: 114108.6249. Time: 77122.8993 us. Best GFLOPs: 115425.6037
2023-05-01 23:58:04 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #966: GFLOPs: 112544.5777. Time: 78194.6867 us. Best GFLOPs: 115425.6037
2023-05-01 23:58:04 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #967: GFLOPs: 111697.6525. Time: 78787.5823 us. Best GFLOPs: 115425.6037
2023-05-01 23:58:04 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #968: GFLOPs: 113973.4323. Time: 77214.3807 us. Best GFLOPs: 115425.6037
2023-05-01 23:58:04 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #969: GFLOPs: 111469.7086. Time: 78948.6947 us. Best GFLOPs: 115425.6037
2023-05-01 23:58:04 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #970: GFLOPs: 111650.7300. Time: 78820.6937 us. Best GFLOPs: 115425.6037
2023-05-01 23:58:04 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #971: GFLOPs: 112557.8442. Time: 78185.4703 us. Best GFLOPs: 115425.6037
2023-05-01 23:58:04 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #972: GFLOPs: 111484.1738. Time: 78938.4510 us. Best GFLOPs: 115425.6037
2023-05-01 23:58:04 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #973: GFLOPs: 112622.2515. Time: 78140.7570 us. Best GFLOPs: 115425.6037
2023-05-01 23:58:04 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #974: GFLOPs: 113225.6536. Time: 77724.3293 us. Best GFLOPs: 115425.6037
2023-05-01 23:58:04 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #975: GFLOPs: 112052.5105. Time: 78538.0707 us. Best GFLOPs: 115425.6037
2023-05-01 23:58:04 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #976: GFLOPs: 112616.9003. Time: 78144.4700 us. Best GFLOPs: 115425.6037
2023-05-01 23:58:04 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-01 23:58:05 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-01 23:58:09 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 400 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:58:13 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 798 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:58:16 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1200 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:58:20 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1597 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:58:24 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1999 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:58:24 [INFO] [evolutionary_search.cc:723] Sampled 51 candidate(s)
2023-05-01 23:58:31 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 116 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:58:39 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 109 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:58:47 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 137 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:58:56 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 131 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-01 23:58:58 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9846  0.9835  0.9825  0.9825  0.9825  0.9800  0.9800  0.9800  0.9800  0.9800  0.9800  0.9800  0.9800  0.9792  0.9792  0.9792
2023-05-01 23:58:58 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-01 23:58:58 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-02 00:05:48 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #977: GFLOPs: 114934.2075. Time: 76568.9187 us. Best GFLOPs: 115425.6037
2023-05-02 00:05:48 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #978: GFLOPs: 111536.2557. Time: 78901.5907 us. Best GFLOPs: 115425.6037
2023-05-02 00:05:48 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #979: GFLOPs: 112662.1154. Time: 78113.1080 us. Best GFLOPs: 115425.6037
2023-05-02 00:05:48 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #980: GFLOPs: 112138.2125. Time: 78478.0477 us. Best GFLOPs: 115425.6037
2023-05-02 00:05:48 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #981: GFLOPs: 112555.8744. Time: 78186.8387 us. Best GFLOPs: 115425.6037
2023-05-02 00:05:48 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #982: GFLOPs: 111064.4314. Time: 79236.7807 us. Best GFLOPs: 115425.6037
2023-05-02 00:05:48 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #983: GFLOPs: 111458.1475. Time: 78956.8837 us. Best GFLOPs: 115425.6037
2023-05-02 00:05:48 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #984: GFLOPs: 111397.4672. Time: 78999.8930 us. Best GFLOPs: 115425.6037
2023-05-02 00:05:48 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #985: GFLOPs: 112996.3955. Time: 77882.0240 us. Best GFLOPs: 115425.6037
2023-05-02 00:05:48 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #986: GFLOPs: 113424.3974. Time: 77588.1397 us. Best GFLOPs: 115425.6037
2023-05-02 00:05:48 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #987: GFLOPs: 111395.1505. Time: 79001.5360 us. Best GFLOPs: 115425.6037
2023-05-02 00:05:48 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #988: GFLOPs: 112393.9533. Time: 78299.4790 us. Best GFLOPs: 115425.6037
2023-05-02 00:05:48 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #989: GFLOPs: 112944.9766. Time: 77917.4803 us. Best GFLOPs: 115425.6037
2023-05-02 00:05:48 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #990: GFLOPs: 112364.5671. Time: 78319.9563 us. Best GFLOPs: 115425.6037
2023-05-02 00:05:48 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #991: GFLOPs: 111094.5822. Time: 79215.2760 us. Best GFLOPs: 115425.6037
2023-05-02 00:05:48 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #992: GFLOPs: 113327.6773. Time: 77654.3577 us. Best GFLOPs: 115425.6037
2023-05-02 00:05:48 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-02 00:05:49 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-02 00:05:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 400 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-02 00:05:57 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 804 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-02 00:06:00 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1206 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-02 00:06:04 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 1609 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-02 00:06:07 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2010 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-02 00:06:11 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 2409 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-02 00:06:11 [INFO] [evolutionary_search.cc:723] Sampled 51 candidate(s)
2023-05-02 00:06:18 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 118 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-02 00:06:26 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 123 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-02 00:06:35 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 135 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-02 00:06:43 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x19f20a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1934128)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1a3d3d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x18d0a38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x16efbc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x1a2db48)]: 110 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1a3ba88)]: 0 failure(s)
2023-05-02 00:06:45 [INFO] [evolutionary_search.cc:649] Scores of the best 8 candidates:
[1 : 8]:	0.9825  0.9800  0.9792  0.9792  0.9792  0.9792  0.9792  0.9792
2023-05-02 00:06:45 [INFO] [evolutionary_search.cc:727] Got 8 candidate(s) with evolutionary search
2023-05-02 00:06:45 [INFO] [evolutionary_search.cc:730] Sending 8 candidates(s) for measurement
2023-05-02 00:10:10 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #993: GFLOPs: 114030.4591. Time: 77175.7657 us. Best GFLOPs: 115425.6037
2023-05-02 00:10:10 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #994: GFLOPs: 113998.1303. Time: 77197.6520 us. Best GFLOPs: 115425.6037
2023-05-02 00:10:10 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #995: GFLOPs: 113276.8906. Time: 77689.1733 us. Best GFLOPs: 115425.6037
2023-05-02 00:10:10 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #996: GFLOPs: 114888.1196. Time: 76599.6347 us. Best GFLOPs: 115425.6037
2023-05-02 00:10:10 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #997: GFLOPs: 112225.1744. Time: 78417.2360 us. Best GFLOPs: 115425.6037
2023-05-02 00:10:10 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #998: GFLOPs: 111137.6832. Time: 79184.5550 us. Best GFLOPs: 115425.6037
2023-05-02 00:10:10 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #999: GFLOPs: 112488.1054. Time: 78233.9427 us. Best GFLOPs: 115425.6037
2023-05-02 00:10:10 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #1000: GFLOPs: 112103.1856. Time: 78502.5683 us. Best GFLOPs: 115425.6037
2023-05-02 05:57:35 [INFO] [task_scheduler.cc:160] Initializing Task #0: "main"
2023-05-02 05:57:35 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 8192), "int8"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        B_decompress = T.alloc_buffer((16384, 16384), "float16")
        for i, j in T.grid(16384, 16384):
            with T.block("B_decompress"):
                vi, vj = T.axis.remap("SS", [i, j])
                T.reads(B[vi, vj // 2:vj // 2 + 2])
                T.writes(B_decompress[vi, vj])
                B_decompress[vi, vj] = T.Select(vj % 32 * 4 % 8 <= 5, T.Cast("float16", T.bitwise_and(T.shift_right(T.Cast("int32", B[vi, vj // 32 * 16 + vj % 32 * 4 // 8]), vj % 32 * 4 % 8), 15)), T.Cast("float16", T.bitwise_or(T.Cast("int8", T.bitwise_and(T.shift_right(T.Cast("int32", B[vi, vj // 32 * 16 + vj % 32 * 4 // 8]), vj % 32 * 4 % 8), T.shift_left(1, 8 - vj % 32 * 4 % 8) - 1)), T.Cast("int8", T.bitwise_and(T.bitwise_and(T.shift_left(T.Cast("int32", B[vi, vj // 32 * 16 + vj % 32 * 4 // 8 + 1]), 8 - vj % 32 * 4 % 8), T.shift_left(15, 8 - vj % 32 * 4 % 8)), 15)))))
        for i, j, k in T.grid(16384, 16384, 16384):
            with T.block("B"):
                vi, vj, vk = T.axis.remap("SSR", [i, j, k])
                T.reads(A[vi, vk], B_decompress[vj, vk])
                T.writes(C[vi, vj])
                with T.init():
                    C[vi, vj] = T.float16(0)
                C[vi, vj] = C[vi, vj] + A[vi, vk] * B_decompress[vj, vk]
2023-05-02 05:57:35 [INFO] [multi_level_tiling_tensor_core.cc:216] Sketch 0: tensorizing with wmma_sync_16x16x16_f16f16f16_trans
2023-05-02 05:57:35 [INFO] [multi_level_tiling_tensor_core.cc:216] Sketch 1: tensorizing with wmma_sync_16x16x16_f16f16f16
2023-05-02 05:57:35 [INFO] [task_scheduler.cc:164] Total 2 design space(s) generated
2023-05-02 05:57:35 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 8192), "int8"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 512})
            C_reindex_shared_dyn = T.alloc_buffer((4, 256, 256, 4, 16, 16), "float16", scope="shared.dyn")
            C_reindex_shared_dyn_wmma_accumulator = T.alloc_buffer((4, 256, 256, 4, 16, 16), "float16", scope="wmma.accumulator")
            A_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            B_decompress_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            A_reindex_shared_dyn_wmma_matrix_a = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_a")
            B_decompress_reindex_shared_dyn_wmma_matrix_b = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_b")
            for ax0_0_0_ax1_0_0_fused in T.thread_binding(1, thread="blockIdx.y"):
                for ax0_0_1_ax1_0_1_fused in T.thread_binding(32, thread="blockIdx.x"):
                    for ax0_0_2_ax1_0_2_fused in T.thread_binding(32, thread="threadIdx.y"):
                        for ax2_0_0 in range(128):
                            for ax0_ax1_fused in range(524288):
                                with T.block("A_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(16384, ax0_0_1_ax1_0_1_fused // 8 * 4096 + ax0_ax1_fused // 128)
                                    v1 = T.axis.spatial(16384, ax2_0_0 * 128 + ax0_ax1_fused % 128)
                                    T.reads(A[v0, v1])
                                    T.writes(A_reindex_shared_dyn[v0, v1])
                                    T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]], "meta_schedule.cooperative_fetch": 8})
                                    A_reindex_shared_dyn[v0, v1] = A[v0, v1]
                            for ax0_ax1_fused in range(262144):
                                with T.block("B_decompress_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(16384, ax2_0_0 * 128 + ax0_ax1_fused // 2048)
                                    v1 = T.axis.spatial(16384, ax0_0_1_ax1_0_1_fused % 8 * 2048 + ax0_ax1_fused % 2048)
                                    T.reads(B[v1, v0 // 2:v0 // 2 + 2])
                                    T.writes(B_decompress_reindex_shared_dyn[v0, v1])
                                    T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]], "meta_schedule.cooperative_fetch": 1})
                                    B_decompress_reindex_shared_dyn[v0, v1] = T.Select(v0 % 32 * 4 % 8 <= 5, T.Cast("float16", T.bitwise_and(T.shift_right(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8]), v0 % 32 * 4 % 8), 15)), T.Cast("float16", T.bitwise_or(T.Cast("int8", T.bitwise_and(T.shift_right(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8]), v0 % 32 * 4 % 8), T.shift_left(1, 8 - v0 % 32 * 4 % 8) - 1)), T.Cast("int8", T.bitwise_and(T.bitwise_and(T.shift_left(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8 + 1]), 8 - v0 % 32 * 4 % 8), T.shift_left(15, 8 - v0 % 32 * 4 % 8)), 15)))))
                            for ax2_0_1 in range(2):
                                for ax0_0, ax1_0 in T.grid(256, 4):
                                    with T.block("A_reindex_shared.dyn_wmma.matrix_a_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_1_ax1_0_1_fused // 8 * 256 + ax0_0)
                                        v1_o = T.axis.spatial(1024, ax2_0_0 * 8 + ax2_0_1 * 4 + ax1_0)
                                        T.reads(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_load_16x16x16_f16_a_shared_dyn"})
                                        for ax0_1, ax1_1 in T.grid(16, 16):
                                            with T.block("A_reindex_shared.dyn_wmma.matrix_a"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(A_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = A_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                                for ax0_0, ax1_0 in T.grid(4, 4):
                                    with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b_o"):
                                        v0_o = T.axis.spatial(1024, ax2_0_0 * 8 + ax2_0_1 * 4 + ax0_0)
                                        v1_o = T.axis.spatial(1024, ax0_0_1_ax1_0_1_fused % 8 * 128 + ax0_0_2_ax1_0_2_fused * 4 + ax1_0)
                                        T.reads(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_load_16x16x16_f16_b_shared_dyn"})
                                        for ax0_1, ax1_1 in T.grid(16, 16):
                                            with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(B_decompress_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = B_decompress_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                                for ax0_0_3, ax1_0_3, ax2_0_2, ax0_0_4, ax1_0_4 in T.grid(64, 1, 4, 4, 4):
                                    with T.block("B_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_1_ax1_0_1_fused // 8 * 256 + ax0_0_3 * 4 + ax0_0_4)
                                        v1_o = T.axis.spatial(1024, ax0_0_1_ax1_0_1_fused % 8 * 128 + ax0_0_2_ax1_0_2_fused * 4 + ax1_0_3 * 4 + ax1_0_4)
                                        v2_o = T.axis.reduce(1024, ax2_0_0 * 8 + ax2_0_1 * 4 + ax2_0_2)
                                        T.reads(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], B_decompress_reindex_shared_dyn_wmma_matrix_b[v2_o * 16:v2_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 256, v1_o // 4, v0_o % 256, v1_o % 4, 0:16, 0:16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_sync_16x16x16_f16f16f16", "meta_schedule.auto_tensorize_init": "wmma_fill_16x16x16_f16", "meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                                        with T.init():
                                            for ax0_1, ax1_1 in T.grid(16, 16):
                                                with T.block("B_init"):
                                                    v0_i_init, v1_i_init = T.axis.remap("SS", [ax0_1, ax1_1])
                                                    T.reads()
                                                    T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 256, v1_o // 4, v0_o % 256, v1_o % 4, v0_i_init, v1_i_init])
                                                    C_reindex_shared_dyn_wmma_accumulator[v0_o // 256, v1_o // 4, v0_o % 256, v1_o % 4, v0_i_init, v1_i_init] = T.float16(0)
                                        for ax0_1, ax1_1, ax2_1 in T.grid(16, 16, 16):
                                            with T.block("B"):
                                                v0_i, v1_i, v2_i = T.axis.remap("SSR", [ax0_1, ax1_1, ax2_1])
                                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o // 256, v1_o // 4, v0_o % 256, v1_o % 4, v0_i, v1_i], A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v2_o * 16 + v2_i], B_decompress_reindex_shared_dyn_wmma_matrix_b[v2_o * 16 + v2_i, v1_o * 16 + v1_i])
                                                T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 256, v1_o // 4, v0_o % 256, v1_o % 4, v0_i, v1_i])
                                                T.block_attr({"meta_schedule.tiling_structure": "SSSRRSRS"})
                                                C_reindex_shared_dyn_wmma_accumulator[v0_o // 256, v1_o // 4, v0_o % 256, v1_o % 4, v0_i, v1_i] = C_reindex_shared_dyn_wmma_accumulator[v0_o // 256, v1_o // 4, v0_o % 256, v1_o % 4, v0_i, v1_i] + A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v2_o * 16 + v2_i] * B_decompress_reindex_shared_dyn_wmma_matrix_b[v2_o * 16 + v2_i, v1_o * 16 + v1_i]
                    for ax2 in range(256):
                        for ax0_ax1_fused in T.thread_binding(32, thread="threadIdx.y"):
                            for ax2_1, ax3 in T.grid(1, 4):
                                with T.block("C_reindex_shared.dyn_wmma.accumulator_o"):
                                    v0 = T.axis.spatial(4, ax0_0_1_ax1_0_1_fused // 8)
                                    v1 = T.axis.spatial(256, ax0_0_1_ax1_0_1_fused % 8 * 32 + ax0_ax1_fused)
                                    v2 = T.axis.spatial(256, ax2 + ax2_1)
                                    v3 = T.axis.spatial(4, ax3)
                                    v4_o = T.axis.spatial(1, 0)
                                    v5_o = T.axis.spatial(1, 0)
                                    T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16])
                                    T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16])
                                    T.block_attr({"meta_schedule.auto_tensorize": "wmma_store_16x16x16_f16_shared_dyn"})
                                    for ax4, ax5 in T.grid(16, 16):
                                        with T.block("C_reindex_shared.dyn_wmma.accumulator"):
                                            v4_i, v5_i = T.axis.remap("SS", [ax4, ax5])
                                            T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, v4_i, v5_i])
                                            T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, v4_i, v5_i])
                                            C_reindex_shared_dyn[v0, v1, v2, v3, v4_i, v5_i] = C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, v4_i, v5_i]
                        for ax0_ax1_ax3_ax4_ax5_fused in range(32768):
                            with T.block("C_reindex_shared.dyn"):
                                v0 = T.axis.spatial(4, ax0_0_1_ax1_0_1_fused // 8)
                                v1 = T.axis.spatial(256, ax0_0_1_ax1_0_1_fused % 8 * 32 + ax0_ax1_ax3_ax4_ax5_fused // 1024)
                                v2 = T.axis.spatial(256, ax2)
                                v3 = T.axis.spatial(4, ax0_ax1_ax3_ax4_ax5_fused % 1024 // 256)
                                v4 = T.axis.spatial(16, ax0_ax1_ax3_ax4_ax5_fused % 256 // 16)
                                v5 = T.axis.spatial(16, ax0_ax1_ax3_ax4_ax5_fused % 16)
                                T.reads(C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5])
                                T.writes(C[v4 + v2 * 16 + v0 * 4096, v5 + v3 * 16 + v1 * 64])
                                T.block_attr({"meta_schedule.cooperative_fetch": 1})
                                C[v4 + v2 * 16 + v0 * 4096, v5 + v3 * 16 + v1 * 64] = C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5]
b0 = sch.get_block(name="B_decompress", func_name="main")
b1 = sch.get_block(name="B", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
b3 = sch.reindex(block=b1, buffer=("write", 0))
b4 = sch.reindex(block=b1, buffer=("read", 0))
b5 = sch.reindex(block=b1, buffer=("read", 1))
sch.transform_layout(block=b1, buffer=("read", 0), index_map=lambda vi, vk: (vi, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("read", 1), index_map=lambda vj, vk: (vk, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("write", 0), index_map=lambda vi, vj: (vi, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_block_layout(block=b3, index_map=lambda vi, vj: (vi, vj,))
sch.transform_block_layout(block=b4, index_map=lambda vi, vk: (vi, vk,))
sch.transform_block_layout(block=b5, index_map=lambda vj, vk: (vk, vj,))
sch.transform_block_layout(block=b1, index_map=lambda vi, vj, vk: (vi, vj, vk,))
l6, l7, l8 = sch.get_loops(block=b1)
l9, l10 = sch.split(loop=l8, factors=[None, 16], preserve_unit_iters=True)
l11, l12 = sch.split(loop=l7, factors=[None, 16], preserve_unit_iters=True)
l13, l14 = sch.split(loop=l6, factors=[None, 16], preserve_unit_iters=True)
l15, l16, l17, l18, l19, l20 = sch.get_loops(block=b1)
sch.reorder(l17, l19, l14, l12, l10)
b21 = sch.blockize(loop=l14, preserve_unit_iters=True)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_sync_16x16x16_f16f16f16")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize_init", ann_val="wmma_fill_16x16x16_f16")
sch.annotate(block_or_loop=b21, ann_key="warp_execution", ann_val=1)
l22, l23, l24 = sch.get_loops(block=b21)
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l22, n=5, max_innermost_factor=4, decision=[1, 4, 1, 64, 4])
l30, l31, l32, l33, l34 = sch.split(loop=l22, factors=[v25, v26, v27, v28, v29], preserve_unit_iters=True)
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l23, n=5, max_innermost_factor=4, decision=[1, 8, 32, 1, 4])
l40, l41, l42, l43, l44 = sch.split(loop=l23, factors=[v35, v36, v37, v38, v39], preserve_unit_iters=True)
v45, v46, v47 = sch.sample_perfect_tile(loop=l24, n=3, max_innermost_factor=4, decision=[128, 2, 4])
l48, l49, l50 = sch.split(loop=l24, factors=[v45, v46, v47], preserve_unit_iters=True)
sch.reorder(l30, l40, l31, l41, l32, l42, l48, l49, l33, l43, l50, l34, l44)
l51 = sch.fuse(l30, l40, preserve_unit_iters=True)
sch.bind(loop=l51, thread_axis="blockIdx.y")
l52 = sch.fuse(l31, l41, preserve_unit_iters=True)
sch.bind(loop=l52, thread_axis="blockIdx.x")
l53 = sch.fuse(l32, l42, preserve_unit_iters=True)
sch.bind(loop=l53, thread_axis="threadIdx.y")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
sch.transform_layout(block=b21, buffer=("write", 0), index_map=lambda i0, i1: (i0 // 16 // (v28 * v29), i1 // 16 // (v38 * v39), i0 // 16 % (v28 * v29), i1 // 16 % (v38 * v39), i0 % 16, i1 % 16,), pad_value=None, assume_injective_transform=True)
b54 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="shared.dyn")
sch.reverse_compute_at(block=b54, loop=l52, preserve_unit_loops=True, index=-1)
b55 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="wmma.accumulator")
l56, l57, l58, l59, l60, l61, l62, l63 = sch.get_loops(block=b54)
sch.reorder(l60, l58, l59, l61)
sch.compute_at(block=b55, loop=l60, preserve_unit_loops=True, index=-1)
l64, l65, l66, l67, l68, l69, l70, l71, l72 = sch.get_loops(block=b55)
l73 = sch.fuse(l67, l68, preserve_unit_iters=True)
sch.bind(loop=l73, thread_axis="threadIdx.y")
sch.reverse_compute_inline(block=b3)
l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b55)
b82 = sch.blockize(loop=l80, preserve_unit_iters=True)
sch.annotate(block_or_loop=b82, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_store_16x16x16_f16_shared_dyn")
l83, l84, l85, l86, l87, l88, l89, l90 = sch.get_loops(block=b54)
l91 = sch.fuse(l86, l87, l88, l89, l90, preserve_unit_iters=True)
v92 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch", ann_val=v92)
b93 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b93, loop=l48, preserve_unit_loops=True, index=-1)
l94, l95, l96, l97, l98, l99 = sch.get_loops(block=b93)
l100 = sch.fuse(l98, l99, preserve_unit_iters=True)
v101 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch", ann_val=v101)
b102 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b102, loop=l48, preserve_unit_loops=True, index=-1)
l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b102)
l109 = sch.fuse(l107, l108, preserve_unit_iters=True)
v110 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch", ann_val=v110)
b111 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="wmma.matrix_a")
sch.compute_at(block=b111, loop=l49, preserve_unit_loops=True, index=-1)
l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b111)
l119, l120 = sch.split(loop=l118, factors=[None, 16], preserve_unit_iters=True)
l121, l122 = sch.split(loop=l117, factors=[None, 16], preserve_unit_iters=True)
l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b111)
sch.reorder(l130, l122, l120)
b132 = sch.blockize(loop=l122, preserve_unit_iters=True)
sch.annotate(block_or_loop=b132, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_a_shared_dyn")
b133 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="wmma.matrix_b")
sch.compute_at(block=b133, loop=l49, preserve_unit_loops=True, index=-1)
l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b133)
l141, l142 = sch.split(loop=l140, factors=[None, 16], preserve_unit_iters=True)
l143, l144 = sch.split(loop=l139, factors=[None, 16], preserve_unit_iters=True)
l145, l146, l147, l148, l149, l150, l151, l152, l153 = sch.get_loops(block=b133)
sch.reorder(l152, l144, l142)
b154 = sch.blockize(loop=l144, preserve_unit_iters=True)
sch.annotate(block_or_loop=b154, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_b_shared_dyn")
sch.compute_inline(block=b4)
sch.compute_inline(block=b5)
sch.storage_align(block=b93, buffer_index=0, axis=-2, factor=32, offset=8)
sch.storage_align(block=b102, buffer_index=0, axis=-2, factor=32, offset=8)
sch.compute_inline(block=b0)
v155 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v155)
2023-05-02 05:57:35 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 8192), "int8"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 64})
            C_reindex_shared_dyn = T.alloc_buffer((512, 256, 2, 4, 16, 16), "float16", scope="shared.dyn")
            C_reindex_shared_dyn_wmma_accumulator = T.alloc_buffer((512, 256, 2, 4, 16, 16), "float16", scope="wmma.accumulator")
            A_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            B_decompress_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            A_reindex_shared_dyn_wmma_matrix_a = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_a")
            B_decompress_reindex_shared_dyn_wmma_matrix_b = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_b")
            for ax0_0_0_ax1_0_0_fused in T.thread_binding(32, thread="blockIdx.y"):
                for ax0_0_1_ax1_0_1_fused in T.thread_binding(1024, thread="blockIdx.x"):
                    for ax0_0_2_ax1_0_2_fused in T.thread_binding(4, thread="threadIdx.y"):
                        for ax2_0_0 in range(8):
                            for ax0_ax1_fused in range(131072):
                                with T.block("A_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused * 512 + ax0_0_1_ax1_0_1_fused // 128 * 64 + ax0_ax1_fused // 2048)
                                    v1 = T.axis.spatial(16384, ax2_0_0 * 2048 + ax0_ax1_fused % 2048)
                                    T.reads(A[v0, v1])
                                    T.writes(A_reindex_shared_dyn[v0, v1])
                                    T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]], "meta_schedule.cooperative_fetch": 8})
                                    A_reindex_shared_dyn[v0, v1] = A[v0, v1]
                            for ax0_ax1_fused in range(262144):
                                with T.block("B_decompress_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(16384, ax0_0_1_ax1_0_1_fused % 128 * 128 + ax0_ax1_fused // 2048)
                                    v1 = T.axis.spatial(16384, ax2_0_0 * 2048 + ax0_ax1_fused % 2048)
                                    T.reads(B[v0, v1 // 2:v1 // 2 + 2])
                                    T.writes(B_decompress_reindex_shared_dyn[v0, v1])
                                    T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]], "meta_schedule.cooperative_fetch": 1})
                                    B_decompress_reindex_shared_dyn[v0, v1] = T.Select(v1 % 32 * 4 % 8 <= 5, T.Cast("float16", T.bitwise_and(T.shift_right(T.Cast("int32", B[v0, v1 // 32 * 16 + v1 % 32 * 4 // 8]), v1 % 32 * 4 % 8), 15)), T.Cast("float16", T.bitwise_or(T.Cast("int8", T.bitwise_and(T.shift_right(T.Cast("int32", B[v0, v1 // 32 * 16 + v1 % 32 * 4 // 8]), v1 % 32 * 4 % 8), T.shift_left(1, 8 - v1 % 32 * 4 % 8) - 1)), T.Cast("int8", T.bitwise_and(T.bitwise_and(T.shift_left(T.Cast("int32", B[v0, v1 // 32 * 16 + v1 % 32 * 4 // 8 + 1]), 8 - v1 % 32 * 4 % 8), T.shift_left(15, 8 - v1 % 32 * 4 % 8)), 15)))))
                            for ax2_0_1 in range(64):
                                for ax0_0, ax1_0 in T.grid(2, 2):
                                    with T.block("A_reindex_shared.dyn_wmma.matrix_a_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused * 32 + ax0_0_1_ax1_0_1_fused // 128 * 4 + ax0_0_2_ax1_0_2_fused // 2 * 2 + ax0_0)
                                        v1_o = T.axis.spatial(1024, ax2_0_0 * 128 + ax2_0_1 * 2 + ax1_0)
                                        T.reads(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_load_16x16x16_f16_a_shared_dyn"})
                                        for ax0_1, ax1_1 in T.grid(16, 16):
                                            with T.block("A_reindex_shared.dyn_wmma.matrix_a"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(A_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = A_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                                for ax0_0, ax1_0 in T.grid(4, 2):
                                    with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_1_ax1_0_1_fused % 128 * 8 + ax0_0_2_ax1_0_2_fused % 2 * 4 + ax0_0)
                                        v1_o = T.axis.spatial(1024, ax2_0_0 * 128 + ax2_0_1 * 2 + ax1_0)
                                        T.reads(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_load_16x16x16_f16_b_trans_shared_dyn"})
                                        for ax0_1, ax1_1 in T.grid(16, 16):
                                            with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(B_decompress_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = B_decompress_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                                for ax0_0_3, ax1_0_3, ax2_0_2, ax0_0_4, ax1_0_4 in T.grid(1, 4, 2, 2, 1):
                                    with T.block("B_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused * 32 + ax0_0_1_ax1_0_1_fused // 128 * 4 + ax0_0_2_ax1_0_2_fused // 2 * 2 + ax0_0_3 * 2 + ax0_0_4)
                                        v1_o = T.axis.spatial(1024, ax1_0_4 + ax0_0_1_ax1_0_1_fused % 128 * 8 + ax0_0_2_ax1_0_2_fused % 2 * 4 + ax1_0_3)
                                        v2_o = T.axis.reduce(1024, ax2_0_0 * 128 + ax2_0_1 * 2 + ax2_0_2)
                                        T.reads(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], B_decompress_reindex_shared_dyn_wmma_matrix_b[v1_o * 16:v1_o * 16 + 16, v2_o * 16:v2_o * 16 + 16])
                                        T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 2, v1_o // 4, v0_o % 2, v1_o % 4, 0:16, 0:16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_sync_16x16x16_f16f16f16_trans", "meta_schedule.auto_tensorize_init": "wmma_fill_16x16x16_f16", "meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                                        with T.init():
                                            for ax0_1, ax1_1 in T.grid(16, 16):
                                                with T.block("B_init"):
                                                    v0_i_init, v1_i_init = T.axis.remap("SS", [ax0_1, ax1_1])
                                                    T.reads()
                                                    T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 2, v1_o // 4, v0_o % 2, v1_o % 4, v0_i_init, v1_i_init])
                                                    C_reindex_shared_dyn_wmma_accumulator[v0_o // 2, v1_o // 4, v0_o % 2, v1_o % 4, v0_i_init, v1_i_init] = T.float16(0)
                                        for ax0_1, ax1_1, ax2_1 in T.grid(16, 16, 16):
                                            with T.block("B"):
                                                v0_i, v1_i, v2_i = T.axis.remap("SSR", [ax0_1, ax1_1, ax2_1])
                                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o // 2, v1_o // 4, v0_o % 2, v1_o % 4, v0_i, v1_i], A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v2_o * 16 + v2_i], B_decompress_reindex_shared_dyn_wmma_matrix_b[v1_o * 16 + v1_i, v2_o * 16 + v2_i])
                                                T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 2, v1_o // 4, v0_o % 2, v1_o % 4, v0_i, v1_i])
                                                T.block_attr({"meta_schedule.tiling_structure": "SSSRRSRS"})
                                                C_reindex_shared_dyn_wmma_accumulator[v0_o // 2, v1_o // 4, v0_o % 2, v1_o % 4, v0_i, v1_i] = C_reindex_shared_dyn_wmma_accumulator[v0_o // 2, v1_o // 4, v0_o % 2, v1_o % 4, v0_i, v1_i] + A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v2_o * 16 + v2_i] * B_decompress_reindex_shared_dyn_wmma_matrix_b[v1_o * 16 + v1_i, v2_o * 16 + v2_i]
                    for ax2 in range(2):
                        for ax0_ax1_fused in T.thread_binding(4, thread="threadIdx.y"):
                            for ax2_1, ax3 in T.grid(1, 4):
                                with T.block("C_reindex_shared.dyn_wmma.accumulator_o"):
                                    v0 = T.axis.spatial(512, ax0_0_0_ax1_0_0_fused * 16 + ax0_0_1_ax1_0_1_fused // 128 * 2 + ax0_ax1_fused // 2)
                                    v1 = T.axis.spatial(256, ax0_0_1_ax1_0_1_fused % 128 * 2 + ax0_ax1_fused % 2)
                                    v2 = T.axis.spatial(2, ax2 + ax2_1)
                                    v3 = T.axis.spatial(4, ax3)
                                    v4_o = T.axis.spatial(1, 0)
                                    v5_o = T.axis.spatial(1, 0)
                                    T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16])
                                    T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16])
                                    T.block_attr({"meta_schedule.auto_tensorize": "wmma_store_16x16x16_f16_shared_dyn"})
                                    for ax4, ax5 in T.grid(16, 16):
                                        with T.block("C_reindex_shared.dyn_wmma.accumulator"):
                                            v4_i, v5_i = T.axis.remap("SS", [ax4, ax5])
                                            T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, v4_i, v5_i])
                                            T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, v4_i, v5_i])
                                            C_reindex_shared_dyn[v0, v1, v2, v3, v4_i, v5_i] = C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, v4_i, v5_i]
                        for ax0_ax1_ax3_ax4_ax5_fused in range(4096):
                            with T.block("C_reindex_shared.dyn"):
                                v0 = T.axis.spatial(512, ax0_0_0_ax1_0_0_fused * 16 + ax0_0_1_ax1_0_1_fused // 128 * 2 + ax0_ax1_ax3_ax4_ax5_fused // 2048)
                                v1 = T.axis.spatial(256, ax0_0_1_ax1_0_1_fused % 128 * 2 + ax0_ax1_ax3_ax4_ax5_fused % 2048 // 1024)
                                v2 = T.axis.spatial(2, ax2)
                                v3 = T.axis.spatial(4, ax0_ax1_ax3_ax4_ax5_fused % 1024 // 256)
                                v4 = T.axis.spatial(16, ax0_ax1_ax3_ax4_ax5_fused % 256 // 16)
                                v5 = T.axis.spatial(16, ax0_ax1_ax3_ax4_ax5_fused % 16)
                                T.reads(C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5])
                                T.writes(C[v4 + v2 * 16 + v0 * 32, v5 + v3 * 16 + v1 * 64])
                                T.block_attr({"meta_schedule.cooperative_fetch": 2})
                                C[v4 + v2 * 16 + v0 * 32, v5 + v3 * 16 + v1 * 64] = C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5]
b0 = sch.get_block(name="B_decompress", func_name="main")
b1 = sch.get_block(name="B", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
b3 = sch.reindex(block=b1, buffer=("write", 0))
b4 = sch.reindex(block=b1, buffer=("read", 0))
b5 = sch.reindex(block=b1, buffer=("read", 1))
sch.transform_layout(block=b1, buffer=("read", 0), index_map=lambda vi, vk: (vi, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("read", 1), index_map=lambda vj, vk: (vj, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("write", 0), index_map=lambda vi, vj: (vi, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_block_layout(block=b3, index_map=lambda vi, vj: (vi, vj,))
sch.transform_block_layout(block=b4, index_map=lambda vi, vk: (vi, vk,))
sch.transform_block_layout(block=b5, index_map=lambda vj, vk: (vj, vk,))
sch.transform_block_layout(block=b1, index_map=lambda vi, vj, vk: (vi, vj, vk,))
l6, l7, l8 = sch.get_loops(block=b1)
l9, l10 = sch.split(loop=l8, factors=[None, 16], preserve_unit_iters=True)
l11, l12 = sch.split(loop=l7, factors=[None, 16], preserve_unit_iters=True)
l13, l14 = sch.split(loop=l6, factors=[None, 16], preserve_unit_iters=True)
l15, l16, l17, l18, l19, l20 = sch.get_loops(block=b1)
sch.reorder(l17, l19, l14, l12, l10)
b21 = sch.blockize(loop=l14, preserve_unit_iters=True)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_sync_16x16x16_f16f16f16_trans")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize_init", ann_val="wmma_fill_16x16x16_f16")
sch.annotate(block_or_loop=b21, ann_key="warp_execution", ann_val=1)
l22, l23, l24 = sch.get_loops(block=b21)
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l22, n=5, max_innermost_factor=4, decision=[32, 8, 2, 1, 2])
l30, l31, l32, l33, l34 = sch.split(loop=l22, factors=[v25, v26, v27, v28, v29], preserve_unit_iters=True)
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l23, n=5, max_innermost_factor=4, decision=[1, 128, 2, 4, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l23, factors=[v35, v36, v37, v38, v39], preserve_unit_iters=True)
v45, v46, v47 = sch.sample_perfect_tile(loop=l24, n=3, max_innermost_factor=4, decision=[8, 64, 2])
l48, l49, l50 = sch.split(loop=l24, factors=[v45, v46, v47], preserve_unit_iters=True)
sch.reorder(l30, l40, l31, l41, l32, l42, l48, l49, l33, l43, l50, l34, l44)
l51 = sch.fuse(l30, l40, preserve_unit_iters=True)
sch.bind(loop=l51, thread_axis="blockIdx.y")
l52 = sch.fuse(l31, l41, preserve_unit_iters=True)
sch.bind(loop=l52, thread_axis="blockIdx.x")
l53 = sch.fuse(l32, l42, preserve_unit_iters=True)
sch.bind(loop=l53, thread_axis="threadIdx.y")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
sch.transform_layout(block=b21, buffer=("write", 0), index_map=lambda i0, i1: (i0 // 16 // (v28 * v29), i1 // 16 // (v38 * v39), i0 // 16 % (v28 * v29), i1 // 16 % (v38 * v39), i0 % 16, i1 % 16,), pad_value=None, assume_injective_transform=True)
b54 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="shared.dyn")
sch.reverse_compute_at(block=b54, loop=l52, preserve_unit_loops=True, index=-1)
b55 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="wmma.accumulator")
l56, l57, l58, l59, l60, l61, l62, l63 = sch.get_loops(block=b54)
sch.reorder(l60, l58, l59, l61)
sch.compute_at(block=b55, loop=l60, preserve_unit_loops=True, index=-1)
l64, l65, l66, l67, l68, l69, l70, l71, l72 = sch.get_loops(block=b55)
l73 = sch.fuse(l67, l68, preserve_unit_iters=True)
sch.bind(loop=l73, thread_axis="threadIdx.y")
sch.reverse_compute_inline(block=b3)
l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b55)
b82 = sch.blockize(loop=l80, preserve_unit_iters=True)
sch.annotate(block_or_loop=b82, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_store_16x16x16_f16_shared_dyn")
l83, l84, l85, l86, l87, l88, l89, l90 = sch.get_loops(block=b54)
l91 = sch.fuse(l86, l87, l88, l89, l90, preserve_unit_iters=True)
v92 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch", ann_val=v92)
b93 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b93, loop=l48, preserve_unit_loops=True, index=-1)
l94, l95, l96, l97, l98, l99 = sch.get_loops(block=b93)
l100 = sch.fuse(l98, l99, preserve_unit_iters=True)
v101 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch", ann_val=v101)
b102 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b102, loop=l48, preserve_unit_loops=True, index=-1)
l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b102)
l109 = sch.fuse(l107, l108, preserve_unit_iters=True)
v110 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch", ann_val=v110)
b111 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="wmma.matrix_a")
sch.compute_at(block=b111, loop=l49, preserve_unit_loops=True, index=-1)
l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b111)
l119, l120 = sch.split(loop=l118, factors=[None, 16], preserve_unit_iters=True)
l121, l122 = sch.split(loop=l117, factors=[None, 16], preserve_unit_iters=True)
l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b111)
sch.reorder(l130, l122, l120)
b132 = sch.blockize(loop=l122, preserve_unit_iters=True)
sch.annotate(block_or_loop=b132, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_a_shared_dyn")
b133 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="wmma.matrix_b")
sch.compute_at(block=b133, loop=l49, preserve_unit_loops=True, index=-1)
l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b133)
l141, l142 = sch.split(loop=l140, factors=[None, 16], preserve_unit_iters=True)
l143, l144 = sch.split(loop=l139, factors=[None, 16], preserve_unit_iters=True)
l145, l146, l147, l148, l149, l150, l151, l152, l153 = sch.get_loops(block=b133)
sch.reorder(l152, l144, l142)
b154 = sch.blockize(loop=l144, preserve_unit_iters=True)
sch.annotate(block_or_loop=b154, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_b_trans_shared_dyn")
sch.compute_inline(block=b4)
sch.compute_inline(block=b5)
sch.storage_align(block=b93, buffer_index=0, axis=-2, factor=32, offset=8)
sch.storage_align(block=b102, buffer_index=0, axis=-2, factor=32, offset=8)
sch.compute_inline(block=b0)
v155 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v155)
2023-05-02 05:57:35 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-02 05:57:37 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-02 05:57:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 397 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 05:57:44 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 798 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 05:57:48 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 1185 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 05:57:51 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 1583 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 05:57:51 [INFO] [evolutionary_search.cc:723] Sampled 57 candidate(s)
2023-05-02 05:57:58 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 118 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 05:58:05 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 115 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 05:58:12 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 111 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 05:58:18 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 105 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 05:58:19 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9998  0.9995  0.9985  0.9981  0.9980  0.9976  0.9969  0.9963  0.9962  0.9959  0.9956  0.9947  0.9945  0.9937  0.9935  0.9927
2023-05-02 05:58:19 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-02 05:58:19 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-02 06:05:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #1: GFLOPs: 125543.5987. Time: 70098.2613 us. Best GFLOPs: 125543.5987
2023-05-02 06:05:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #2: GFLOPs: 95795.0955. Time: 91866.7907 us. Best GFLOPs: 125543.5987
2023-05-02 06:05:25 [INFO] [task_scheduler.cc:121] [Task #0: main] Trial #3: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 8192), "int8"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        C_reindex_shared_dyn = T.alloc_buffer((512, 64, 2, 16, 16, 16), "float16", scope="shared.dyn")
        C_reindex_shared_dyn_wmma_accumulator = T.alloc_buffer((512, 64, 2, 16, 16, 16), "float16", scope="wmma.accumulator")
        A_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
        B_decompress_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
        A_reindex_shared_dyn_wmma_matrix_a = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_a")
        B_decompress_reindex_shared_dyn_wmma_matrix_b = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_b")
        for ax0_0_0_ax1_0_0_fused in T.thread_binding(512, thread="blockIdx.y", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ax0_0_1_ax1_0_1_fused in T.thread_binding(32, thread="blockIdx.x"):
                for ax0_0_2_ax1_0_2_fused in T.thread_binding(2, thread="threadIdx.y"):
                    for ax0_0_3_init, ax1_0_3_init, ax0_0_4_init, ax1_0_4_init in T.grid(1, 4, 2, 4):
                        with T.block("B_o_init"):
                            v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 4 * 8 + ax0_0_1_ax1_0_1_fused // 8 * 2 + ax0_0_3_init * 2 + ax0_0_4_init)
                            v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 4 * 256 + ax0_0_1_ax1_0_1_fused % 8 * 32 + ax0_0_2_ax1_0_2_fused * 16 + ax1_0_3_init * 4 + ax1_0_4_init)
                            T.reads()
                            T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 2, v1_o // 16, v0_o % 2, v1_o % 16, 0:16, 0:16])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                            C_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0_o // 2, v1_o // 16, v0_o % 2, v1_o % 16, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.accumulator", offset_factor=16)
                            T.tvm_fill_fragment(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.float32(0))
                    for ax2_0_0 in range(1024):
                        for ax0_ax1_fused_0 in range(2):
                            for ax0_ax1_fused_1 in T.thread_binding(2, thread="threadIdx.y"):
                                for ax0_ax1_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                    for ax0_ax1_fused_3 in T.vectorized(4):
                                        with T.block("A_reindex_shared.dyn"):
                                            v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused // 4 * 128 + ax0_0_1_ax1_0_1_fused // 8 * 32 + (ax0_ax1_fused_0 * 256 + ax0_ax1_fused_1 * 128 + ax0_ax1_fused_2 * 4 + ax0_ax1_fused_3) // 16)
                                            v1 = T.axis.spatial(16384, ax2_0_0 * 16 + (ax0_ax1_fused_0 * 256 + ax0_ax1_fused_1 * 128 + ax0_ax1_fused_2 * 4 + ax0_ax1_fused_3) % 16)
                                            T.reads(A[v0, v1])
                                            T.writes(A_reindex_shared_dyn[v0, v1])
                                            T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]]})
                                            A_reindex_shared_dyn[v0, v1] = A[v0, v1]
                        for ax0_ax1_fused_0 in range(64):
                            for ax0_ax1_fused_1 in T.thread_binding(2, thread="threadIdx.y"):
                                for ax0_ax1_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                    for ax0_ax1_fused_3 in T.vectorized(2):
                                        with T.block("B_decompress_reindex_shared.dyn"):
                                            v0 = T.axis.spatial(16384, ax2_0_0 * 16 + (ax0_ax1_fused_0 * 128 + ax0_ax1_fused_1 * 64 + ax0_ax1_fused_2 * 2 + ax0_ax1_fused_3) // 512)
                                            v1 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused % 4 * 4096 + ax0_0_1_ax1_0_1_fused % 8 * 512 + (ax0_ax1_fused_0 * 128 + ax0_ax1_fused_1 * 64 + ax0_ax1_fused_2 * 2 + ax0_ax1_fused_3) % 512)
                                            T.reads(B[v1, v0 // 2:v0 // 2 + 2])
                                            T.writes(B_decompress_reindex_shared_dyn[v0, v1])
                                            T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]]})
                                            B_decompress_reindex_shared_dyn[v0, v1] = T.Select(v0 % 32 * 4 % 8 <= 5, T.Cast("float16", T.bitwise_and(T.shift_right(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8]), v0 % 32 * 4 % 8), 15)), T.Cast("float16", T.bitwise_or(T.Cast("int8", T.bitwise_and(T.shift_right(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8]), v0 % 32 * 4 % 8), T.shift_left(1, 8 - v0 % 32 * 4 % 8) - 1)), T.Cast("int8", T.bitwise_and(T.bitwise_and(T.shift_left(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8 + 1]), 8 - v0 % 32 * 4 % 8), T.shift_left(15, 8 - v0 % 32 * 4 % 8)), 15)))))
                        for ax2_0_1 in range(1):
                            for ax0_0, ax1_0 in T.grid(2, 1):
                                with T.block("A_reindex_shared.dyn_wmma.matrix_a_o"):
                                    v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 4 * 8 + ax0_0_1_ax1_0_1_fused // 8 * 2 + ax0_0)
                                    v1_o = T.axis.spatial(1024, ax2_0_0 + ax1_0)
                                    T.reads(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    A_1 = T.match_buffer(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="shared.dyn", offset_factor=16)
                                    C_1 = T.match_buffer(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.matrix_a", offset_factor=16)
                                    T.tvm_load_matrix_sync(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), A_1.data, A_1.elem_offset, A_1.strides[0] * 16, 1), A_1.strides[0], "row_major")
                            for ax0_0, ax1_0 in T.grid(1, 16):
                                with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b_o"):
                                    v0_o = T.axis.spatial(1024, ax2_0_0 + ax0_0)
                                    v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 4 * 256 + ax0_0_1_ax1_0_1_fused % 8 * 32 + ax0_0_2_ax1_0_2_fused * 16 + ax1_0)
                                    T.reads(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    A_1 = T.match_buffer(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="shared.dyn", offset_factor=16)
                                    C_1 = T.match_buffer(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.matrix_b", offset_factor=16)
                                    T.tvm_load_matrix_sync(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), A_1.data, A_1.elem_offset, A_1.strides[0] * 16, 1), A_1.strides[0], "row_major")
                            for ax0_0_3, ax1_0_3, ax2_0_2, ax0_0_4, ax1_0_4 in T.grid(1, 4, 1, 2, 4):
                                with T.block("B_o_update"):
                                    v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 4 * 8 + ax0_0_1_ax1_0_1_fused // 8 * 2 + ax0_0_3 * 2 + ax0_0_4)
                                    v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 4 * 256 + ax0_0_1_ax1_0_1_fused % 8 * 32 + ax0_0_2_ax1_0_2_fused * 16 + ax1_0_3 * 4 + ax1_0_4)
                                    v2_o = T.axis.reduce(1024, ax2_0_1 + ax2_0_2 + ax2_0_0)
                                    T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o // 2, v1_o // 16, v0_o % 2, v1_o % 16, 0:16, 0:16], A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], B_decompress_reindex_shared_dyn_wmma_matrix_b[v2_o * 16:v2_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 2, v1_o // 16, v0_o % 2, v1_o % 16, 0:16, 0:16])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                                    A_1 = T.match_buffer(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="wmma.matrix_a", offset_factor=16)
                                    B_1 = T.match_buffer(B_decompress_reindex_shared_dyn_wmma_matrix_b[v2_o * 16:v2_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("B_s0", "B_s1"), scope="wmma.matrix_b", offset_factor=16)
                                    C_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0_o // 2, v1_o // 16, v0_o % 2, v1_o % 16, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.accumulator", offset_factor=16)
                                    T.tvm_mma_sync(C_1.data, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, A_1.data, A_1.elem_offset // A_1.strides[0] // 16 * (A_1.strides[0] // 16) + A_1.elem_offset % A_1.strides[0] // 16, B_1.data, B_1.elem_offset // B_1.strides[0] // 16 * (B_1.strides[0] // 16) + B_1.elem_offset % B_1.strides[0] // 16, C_1.data, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16)
                for ax2 in range(2):
                    for ax0_ax1_fused in T.thread_binding(2, thread="threadIdx.y"):
                        for ax2_1, ax3 in T.grid(1, 16):
                            with T.block("C_reindex_shared.dyn_wmma.accumulator_o"):
                                v0 = T.axis.spatial(512, ax0_0_0_ax1_0_0_fused // 4 * 4 + ax0_0_1_ax1_0_1_fused // 8)
                                v1 = T.axis.spatial(64, ax0_0_0_ax1_0_0_fused % 4 * 16 + ax0_0_1_ax1_0_1_fused % 8 * 2 + ax0_ax1_fused)
                                v2 = T.axis.spatial(2, ax2 + ax2_1)
                                v3 = T.axis.spatial(16, ax3)
                                v4_o = T.axis.spatial(1, 0)
                                v5_o = T.axis.spatial(1, 0)
                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16])
                                T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16])
                                A_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="wmma.accumulator", offset_factor=16)
                                C_1 = T.match_buffer(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="shared.dyn", offset_factor=16)
                                T.tvm_store_matrix_sync(A_1.data, 16, 16, 16, A_1.elem_offset // A_1.strides[0] // 16 * (A_1.strides[0] // 16) + A_1.elem_offset % A_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), C_1.data, C_1.elem_offset, C_1.strides[0] * 16, 2), C_1.strides[0], "row_major")
                    for ax0_ax1_ax3_ax4_ax5_fused_0 in range(32):
                        for ax0_ax1_ax3_ax4_ax5_fused_1 in T.thread_binding(2, thread="threadIdx.y"):
                            for ax0_ax1_ax3_ax4_ax5_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax3_ax4_ax5_fused_3 in T.vectorized(4):
                                    with T.block("C_reindex_shared.dyn"):
                                        v0 = T.axis.spatial(512, ax0_0_0_ax1_0_0_fused // 4 * 4 + ax0_0_1_ax1_0_1_fused // 8)
                                        v1 = T.axis.spatial(64, ax0_0_0_ax1_0_0_fused % 4 * 16 + ax0_0_1_ax1_0_1_fused % 8 * 2 + (ax0_ax1_ax3_ax4_ax5_fused_0 * 256 + ax0_ax1_ax3_ax4_ax5_fused_1 * 128 + ax0_ax1_ax3_ax4_ax5_fused_2 * 4 + ax0_ax1_ax3_ax4_ax5_fused_3) // 4096)
                                        v2 = T.axis.spatial(2, ax2)
                                        v3 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 256 + ax0_ax1_ax3_ax4_ax5_fused_1 * 128 + ax0_ax1_ax3_ax4_ax5_fused_2 * 4 + ax0_ax1_ax3_ax4_ax5_fused_3) % 4096 // 256)
                                        v4 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 256 + ax0_ax1_ax3_ax4_ax5_fused_1 * 128 + ax0_ax1_ax3_ax4_ax5_fused_2 * 4 + ax0_ax1_ax3_ax4_ax5_fused_3) % 256 // 16)
                                        v5 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 256 + ax0_ax1_ax3_ax4_ax5_fused_1 * 128 + ax0_ax1_ax3_ax4_ax5_fused_2 * 4 + ax0_ax1_ax3_ax4_ax5_fused_3) % 16)
                                        T.reads(C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5])
                                        T.writes(C[v4 + v2 * 16 + v0 * 32, v5 + v3 * 16 + v1 * 256])
                                        C[v4 + v2 * 16 + v0 * 32, v5 + v3 * 16 + v1 * 256] = C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5]
b0 = sch.get_block(name="B_decompress", func_name="main")
b1 = sch.get_block(name="B", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
b3 = sch.reindex(block=b1, buffer=("write", 0))
b4 = sch.reindex(block=b1, buffer=("read", 0))
b5 = sch.reindex(block=b1, buffer=("read", 1))
sch.transform_layout(block=b1, buffer=("read", 0), index_map=lambda vi, vk: (vi, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("read", 1), index_map=lambda vj, vk: (vk, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("write", 0), index_map=lambda vi, vj: (vi, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_block_layout(block=b3, index_map=lambda vi, vj: (vi, vj,))
sch.transform_block_layout(block=b4, index_map=lambda vi, vk: (vi, vk,))
sch.transform_block_layout(block=b5, index_map=lambda vj, vk: (vk, vj,))
sch.transform_block_layout(block=b1, index_map=lambda vi, vj, vk: (vi, vj, vk,))
l6, l7, l8 = sch.get_loops(block=b1)
l9, l10 = sch.split(loop=l8, factors=[None, 16], preserve_unit_iters=True)
l11, l12 = sch.split(loop=l7, factors=[None, 16], preserve_unit_iters=True)
l13, l14 = sch.split(loop=l6, factors=[None, 16], preserve_unit_iters=True)
l15, l16, l17, l18, l19, l20 = sch.get_loops(block=b1)
sch.reorder(l17, l19, l14, l12, l10)
b21 = sch.blockize(loop=l14, preserve_unit_iters=True)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_sync_16x16x16_f16f16f16")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize_init", ann_val="wmma_fill_16x16x16_f16")
sch.annotate(block_or_loop=b21, ann_key="warp_execution", ann_val=1)
l22, l23, l24 = sch.get_loops(block=b21)
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l22, n=5, max_innermost_factor=4, decision=[128, 4, 1, 1, 2])
l30, l31, l32, l33, l34 = sch.split(loop=l22, factors=[v25, v26, v27, v28, v29], preserve_unit_iters=True)
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l23, n=5, max_innermost_factor=4, decision=[4, 8, 2, 4, 4])
l40, l41, l42, l43, l44 = sch.split(loop=l23, factors=[v35, v36, v37, v38, v39], preserve_unit_iters=True)
v45, v46, v47 = sch.sample_perfect_tile(loop=l24, n=3, max_innermost_factor=4, decision=[1024, 1, 1])
l48, l49, l50 = sch.split(loop=l24, factors=[v45, v46, v47], preserve_unit_iters=True)
sch.reorder(l30, l40, l31, l41, l32, l42, l48, l49, l33, l43, l50, l34, l44)
l51 = sch.fuse(l30, l40, preserve_unit_iters=True)
sch.bind(loop=l51, thread_axis="blockIdx.y")
l52 = sch.fuse(l31, l41, preserve_unit_iters=True)
sch.bind(loop=l52, thread_axis="blockIdx.x")
l53 = sch.fuse(l32, l42, preserve_unit_iters=True)
sch.bind(loop=l53, thread_axis="threadIdx.y")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
sch.transform_layout(block=b21, buffer=("write", 0), index_map=lambda i0, i1: (i0 // 16 // (v28 * v29), i1 // 16 // (v38 * v39), i0 // 16 % (v28 * v29), i1 // 16 % (v38 * v39), i0 % 16, i1 % 16,), pad_value=None, assume_injective_transform=True)
b54 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="shared.dyn")
sch.reverse_compute_at(block=b54, loop=l52, preserve_unit_loops=True, index=-1)
b55 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="wmma.accumulator")
l56, l57, l58, l59, l60, l61, l62, l63 = sch.get_loops(block=b54)
sch.reorder(l60, l58, l59, l61)
sch.compute_at(block=b55, loop=l60, preserve_unit_loops=True, index=-1)
l64, l65, l66, l67, l68, l69, l70, l71, l72 = sch.get_loops(block=b55)
l73 = sch.fuse(l67, l68, preserve_unit_iters=True)
sch.bind(loop=l73, thread_axis="threadIdx.y")
sch.reverse_compute_inline(block=b3)
l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b55)
b82 = sch.blockize(loop=l80, preserve_unit_iters=True)
sch.annotate(block_or_loop=b82, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_store_16x16x16_f16_shared_dyn")
l83, l84, l85, l86, l87, l88, l89, l90 = sch.get_loops(block=b54)
l91 = sch.fuse(l86, l87, l88, l89, l90, preserve_unit_iters=True)
v92 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch", ann_val=v92)
b93 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b93, loop=l48, preserve_unit_loops=True, index=-1)
l94, l95, l96, l97, l98, l99 = sch.get_loops(block=b93)
l100 = sch.fuse(l98, l99, preserve_unit_iters=True)
v101 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch", ann_val=v101)
b102 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b102, loop=l48, preserve_unit_loops=True, index=-1)
l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b102)
l109 = sch.fuse(l107, l108, preserve_unit_iters=True)
v110 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch", ann_val=v110)
b111 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="wmma.matrix_a")
sch.compute_at(block=b111, loop=l49, preserve_unit_loops=True, index=-1)
l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b111)
l119, l120 = sch.split(loop=l118, factors=[None, 16], preserve_unit_iters=True)
l121, l122 = sch.split(loop=l117, factors=[None, 16], preserve_unit_iters=True)
l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b111)
sch.reorder(l130, l122, l120)
b132 = sch.blockize(loop=l122, preserve_unit_iters=True)
sch.annotate(block_or_loop=b132, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_a_shared_dyn")
b133 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="wmma.matrix_b")
sch.compute_at(block=b133, loop=l49, preserve_unit_loops=True, index=-1)
l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b133)
l141, l142 = sch.split(loop=l140, factors=[None, 16], preserve_unit_iters=True)
l143, l144 = sch.split(loop=l139, factors=[None, 16], preserve_unit_iters=True)
l145, l146, l147, l148, l149, l150, l151, l152, l153 = sch.get_loops(block=b133)
sch.reorder(l152, l144, l142)
b154 = sch.blockize(loop=l144, preserve_unit_iters=True)
sch.annotate(block_or_loop=b154, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_b_shared_dyn")
sch.compute_inline(block=b4)
sch.compute_inline(block=b5)
sch.storage_align(block=b93, buffer_index=0, axis=-2, factor=32, offset=8)
sch.storage_align(block=b102, buffer_index=0, axis=-2, factor=32, offset=8)
sch.compute_inline(block=b0)
v155 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v155)
sch.enter_postproc()
sch.unannotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch")
l156, l157, l158, l159 = sch.get_loops(block=b54)
l160, l161, l162, l163 = sch.split(loop=l159, factors=[None, 2, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l163)
sch.bind(loop=l162, thread_axis="threadIdx.x")
sch.bind(loop=l161, thread_axis="threadIdx.y")
sch.unannotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch")
l164, l165, l166, l167, l168 = sch.get_loops(block=b93)
l169, l170, l171, l172 = sch.split(loop=l168, factors=[None, 2, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l172)
sch.bind(loop=l171, thread_axis="threadIdx.x")
sch.bind(loop=l170, thread_axis="threadIdx.y")
sch.unannotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch")
l173, l174, l175, l176, l177 = sch.get_loops(block=b102)
l178, l179, l180, l181 = sch.split(loop=l177, factors=[None, 2, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l181)
sch.bind(loop=l180, thread_axis="threadIdx.x")
sch.bind(loop=l179, thread_axis="threadIdx.y")
b182 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b182, ann_key="meta_schedule.unroll_explicit")
b183, b184, b185, b186, b187, b188, b189 = sch.get_child_blocks(b182)
l190, l191, l192, l193, l194, l195, l196, l197 = sch.get_loops(block=b183)
sch.annotate(block_or_loop=l190, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l190, ann_key="pragma_unroll_explicit", ann_val=1)
l198, l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b184)
sch.annotate(block_or_loop=l198, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l198, ann_key="pragma_unroll_explicit", ann_val=1)
l206, l207, l208, l209, l210, l211, l212 = sch.get_loops(block=b185)
sch.annotate(block_or_loop=l206, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l206, ann_key="pragma_unroll_explicit", ann_val=1)
l213, l214, l215, l216, l217, l218, l219 = sch.get_loops(block=b186)
sch.annotate(block_or_loop=l213, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l213, ann_key="pragma_unroll_explicit", ann_val=1)
l220, l221, l222, l223, l224, l225, l226, l227, l228, l229 = sch.get_loops(block=b187)
sch.annotate(block_or_loop=l220, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l220, ann_key="pragma_unroll_explicit", ann_val=1)
l230, l231, l232, l233, l234, l235 = sch.get_loops(block=b188)
sch.annotate(block_or_loop=l230, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l230, ann_key="pragma_unroll_explicit", ann_val=1)
l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b189)
sch.annotate(block_or_loop=l236, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l236, ann_key="pragma_unroll_explicit", ann_val=1)
b243 = sch.get_block(name="B_o", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b243)
b254 = sch.decompose_reduction(block=b243, loop=l247)
sch.unannotate(block_or_loop=b254, ann_key="meta_schedule.auto_tensorize")
sch.annotate(block_or_loop=b254, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_fill_16x16x16_f16")
sch.unannotate(block_or_loop=b243, ann_key="meta_schedule.auto_tensorize_init")
sch.unannotate(block_or_loop=b254, ann_key="meta_schedule.auto_tensorize_init")
b255 = sch.get_block(name="B_o_init", func_name="main")
sch.unannotate(block_or_loop=b255, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b255, tensor_intrin="wmma_fill_16x16x16_f16", preserve_unit_iters=True)
b256 = sch.get_block(name="A_reindex_shared.dyn_wmma.matrix_a_o", func_name="main")
sch.unannotate(block_or_loop=b256, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b256, tensor_intrin="wmma_load_16x16x16_f16_a_shared_dyn", preserve_unit_iters=True)
b257 = sch.get_block(name="B_decompress_reindex_shared.dyn_wmma.matrix_b_o", func_name="main")
sch.unannotate(block_or_loop=b257, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b257, tensor_intrin="wmma_load_16x16x16_f16_b_shared_dyn", preserve_unit_iters=True)
b258 = sch.get_block(name="B_o_update", func_name="main")
sch.unannotate(block_or_loop=b258, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b258, tensor_intrin="wmma_sync_16x16x16_f16f16f16", preserve_unit_iters=True)
b259 = sch.get_block(name="C_reindex_shared.dyn_wmma.accumulator_o", func_name="main")
sch.unannotate(block_or_loop=b259, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b259, tensor_intrin="wmma_store_16x16x16_f16_shared_dyn", preserve_unit_iters=True)
2023-05-02 06:05:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #4: GFLOPs: 96729.9003. Time: 90978.9833 us. Best GFLOPs: 125543.5987
2023-05-02 06:05:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #5: GFLOPs: 101427.1978. Time: 86765.5637 us. Best GFLOPs: 125543.5987
2023-05-02 06:05:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #6: GFLOPs: 78741.9166. Time: 111762.4307 us. Best GFLOPs: 125543.5987
2023-05-02 06:05:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #7: GFLOPs: 83578.5220. Time: 105294.8507 us. Best GFLOPs: 125543.5987
2023-05-02 06:05:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #8: GFLOPs: 25291.4551. Time: 347958.9437 us. Best GFLOPs: 125543.5987
2023-05-02 06:05:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #9: GFLOPs: 16227.6461. Time: 542308.3493 us. Best GFLOPs: 125543.5987
2023-05-02 06:05:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #10: GFLOPs: 23358.3510. Time: 376755.5337 us. Best GFLOPs: 125543.5987
2023-05-02 06:05:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #11: GFLOPs: 113647.3869. Time: 77435.9027 us. Best GFLOPs: 125543.5987
2023-05-02 06:05:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #12: GFLOPs: 79706.8850. Time: 110409.3830 us. Best GFLOPs: 125543.5987
2023-05-02 06:05:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #13: GFLOPs: 88840.4466. Time: 99058.3493 us. Best GFLOPs: 125543.5987
2023-05-02 06:05:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #14: GFLOPs: 90336.1392. Time: 97418.2433 us. Best GFLOPs: 125543.5987
2023-05-02 06:05:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #15: GFLOPs: 66065.4865. Time: 133207.0413 us. Best GFLOPs: 125543.5987
2023-05-02 06:05:25 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #16: GFLOPs: 88976.8836. Time: 98906.4533 us. Best GFLOPs: 125543.5987
2023-05-02 06:05:25 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-02 06:05:27 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-02 06:05:30 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 402 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:05:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 805 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:05:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 1208 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:05:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 1613 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:05:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 2009 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:05:48 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 2406 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:05:48 [INFO] [evolutionary_search.cc:723] Sampled 54 candidate(s)
2023-05-02 06:05:55 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 138 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:06:02 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 120 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:06:08 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 109 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:06:14 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 88 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:06:15 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	1.0000  0.9992  0.9983  0.9980  0.9976  0.9974  0.9960  0.9959  0.9944  0.9940  0.9940  0.9940  0.9937  0.9932  0.9910  0.9908
2023-05-02 06:06:15 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-02 06:06:15 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-02 06:13:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #17: GFLOPs: 59609.0080. Time: 147635.2030 us. Best GFLOPs: 125543.5987
2023-05-02 06:13:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #18: GFLOPs: 112215.4064. Time: 78424.0620 us. Best GFLOPs: 125543.5987
2023-05-02 06:13:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #19: GFLOPs: 41485.1315. Time: 212133.5447 us. Best GFLOPs: 125543.5987
2023-05-02 06:13:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #20: GFLOPs: 54376.9325. Time: 161840.4640 us. Best GFLOPs: 125543.5987
2023-05-02 06:13:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #21: GFLOPs: 81290.9206. Time: 108257.9447 us. Best GFLOPs: 125543.5987
2023-05-02 06:13:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #22: GFLOPs: 78317.8322. Time: 112367.6147 us. Best GFLOPs: 125543.5987
2023-05-02 06:13:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #23: GFLOPs: 78102.1747. Time: 112677.8867 us. Best GFLOPs: 125543.5987
2023-05-02 06:13:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #24: GFLOPs: 102060.7605. Time: 86226.9490 us. Best GFLOPs: 125543.5987
2023-05-02 06:13:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #25: GFLOPs: 68350.0547. Time: 128754.6590 us. Best GFLOPs: 125543.5987
2023-05-02 06:13:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #26: GFLOPs: 93499.4758. Time: 94122.3243 us. Best GFLOPs: 125543.5987
2023-05-02 06:13:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #27: GFLOPs: 110762.4094. Time: 79452.8400 us. Best GFLOPs: 125543.5987
2023-05-02 06:13:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #28: GFLOPs: 10614.6834. Time: 829076.8227 us. Best GFLOPs: 125543.5987
2023-05-02 06:13:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #29: GFLOPs: 22528.4699. Time: 390634.0737 us. Best GFLOPs: 125543.5987
2023-05-02 06:13:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #30: GFLOPs: 49718.7347. Time: 177003.4583 us. Best GFLOPs: 125543.5987
2023-05-02 06:13:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #31: GFLOPs: 92724.0496. Time: 94909.4440 us. Best GFLOPs: 125543.5987
2023-05-02 06:13:18 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #32: GFLOPs: 42606.3631. Time: 206551.0253 us. Best GFLOPs: 125543.5987
2023-05-02 06:13:18 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-02 06:13:19 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-02 06:13:23 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 397 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:13:26 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 800 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:13:30 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 1207 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:13:33 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 1608 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:13:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 2008 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:13:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 2406 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:13:41 [INFO] [evolutionary_search.cc:723] Sampled 54 candidate(s)
2023-05-02 06:13:47 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 113 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:13:54 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 110 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:14:01 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 128 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:14:07 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 124 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:14:08 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9993  0.9986  0.9984  0.9964  0.9950  0.9945  0.9936  0.9932  0.9930  0.9928  0.9909  0.9907  0.9889  0.9886  0.9885  0.9877
2023-05-02 06:14:08 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-02 06:14:08 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-02 06:21:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #33: GFLOPs: 114562.9259. Time: 76817.0673 us. Best GFLOPs: 125543.5987
2023-05-02 06:21:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #34: GFLOPs: 111537.3126. Time: 78900.8430 us. Best GFLOPs: 125543.5987
2023-05-02 06:21:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #35: GFLOPs: 27799.6989. Time: 316564.1477 us. Best GFLOPs: 125543.5987
2023-05-02 06:21:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #36: GFLOPs: 82127.0318. Time: 107155.8023 us. Best GFLOPs: 125543.5987
2023-05-02 06:21:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #37: GFLOPs: 58163.0170. Time: 151305.5623 us. Best GFLOPs: 125543.5987
2023-05-02 06:21:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #38: GFLOPs: 62904.2773. Time: 139901.2653 us. Best GFLOPs: 125543.5987
2023-05-02 06:21:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #39: GFLOPs: 76499.6964. Time: 115038.2080 us. Best GFLOPs: 125543.5987
2023-05-02 06:21:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #40: GFLOPs: 29920.7222. Time: 294123.5147 us. Best GFLOPs: 125543.5987
2023-05-02 06:21:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #41: GFLOPs: 107615.4440. Time: 81776.2550 us. Best GFLOPs: 125543.5987
2023-05-02 06:21:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #42: GFLOPs: 113127.7775. Time: 77791.5750 us. Best GFLOPs: 125543.5987
2023-05-02 06:21:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #43: GFLOPs: 26463.3943. Time: 332549.4790 us. Best GFLOPs: 125543.5987
2023-05-02 06:21:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #44: GFLOPs: 71985.2685. Time: 122252.6243 us. Best GFLOPs: 125543.5987
2023-05-02 06:21:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #45: GFLOPs: 13951.1458. Time: 630800.3743 us. Best GFLOPs: 125543.5987
2023-05-02 06:21:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #46: GFLOPs: 73382.5501. Time: 119924.8047 us. Best GFLOPs: 125543.5987
2023-05-02 06:21:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #47: GFLOPs: 24883.5671. Time: 353662.6383 us. Best GFLOPs: 125543.5987
2023-05-02 06:21:12 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #48: GFLOPs: 56618.5325. Time: 155432.9933 us. Best GFLOPs: 125543.5987
2023-05-02 06:21:12 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-02 06:21:13 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-02 06:21:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 395 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:21:20 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 795 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:21:24 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 1196 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:21:28 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 1595 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:21:31 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 2000 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:21:31 [INFO] [evolutionary_search.cc:723] Sampled 50 candidate(s)
2023-05-02 06:21:38 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 122 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:21:44 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 99 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:21:51 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 100 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:21:57 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 107 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:21:58 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9994  0.9984  0.9983  0.9976  0.9959  0.9946  0.9940  0.9937  0.9933  0.9923  0.9917  0.9913  0.9897  0.9879  0.9875  0.9869
2023-05-02 06:21:58 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-02 06:21:58 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-02 06:29:02 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #49: GFLOPs: 75568.7259. Time: 116455.4237 us. Best GFLOPs: 125543.5987
2023-05-02 06:29:02 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #50: GFLOPs: 41841.4916. Time: 210326.8227 us. Best GFLOPs: 125543.5987
2023-05-02 06:29:02 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #51: GFLOPs: 91303.2194. Time: 96386.3930 us. Best GFLOPs: 125543.5987
2023-05-02 06:29:02 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #52: GFLOPs: 106382.7289. Time: 82723.8413 us. Best GFLOPs: 125543.5987
2023-05-02 06:29:02 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #53: GFLOPs: 111339.7401. Time: 79040.8527 us. Best GFLOPs: 125543.5987
2023-05-02 06:29:02 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #54: GFLOPs: 85298.1388. Time: 103172.0987 us. Best GFLOPs: 125543.5987
2023-05-02 06:29:02 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #55: GFLOPs: 30244.7631. Time: 290972.2900 us. Best GFLOPs: 125543.5987
2023-05-02 06:29:02 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #56: GFLOPs: 96923.7130. Time: 90797.0580 us. Best GFLOPs: 125543.5987
2023-05-02 06:29:02 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #57: GFLOPs: 28436.4139. Time: 309476.0130 us. Best GFLOPs: 125543.5987
2023-05-02 06:29:02 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #58: GFLOPs: 75221.0398. Time: 116993.7030 us. Best GFLOPs: 125543.5987
2023-05-02 06:29:02 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #59: GFLOPs: 9882.1641. Time: 890532.4707 us. Best GFLOPs: 125543.5987
2023-05-02 06:29:02 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #60: GFLOPs: 91036.6095. Time: 96668.6703 us. Best GFLOPs: 125543.5987
2023-05-02 06:29:02 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #61: GFLOPs: 45764.9840. Time: 192295.2270 us. Best GFLOPs: 125543.5987
2023-05-02 06:29:02 [INFO] [task_scheduler.cc:121] [Task #0: main] Trial #62: Error in running:
LocalRunner: Timeout, killed after 30 seconds

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 8192), "int8"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        C_reindex_shared_dyn = T.alloc_buffer((1024, 256, 1, 4, 16, 16), "float16", scope="shared.dyn")
        C_reindex_shared_dyn_wmma_accumulator = T.alloc_buffer((1024, 256, 1, 4, 16, 16), "float16", scope="wmma.accumulator")
        A_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
        B_decompress_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
        A_reindex_shared_dyn_wmma_matrix_a = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_a")
        B_decompress_reindex_shared_dyn_wmma_matrix_b = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_b")
        for ax0_0_0_ax1_0_0_fused in T.thread_binding(512, thread="blockIdx.y", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ax0_0_1_ax1_0_1_fused in T.thread_binding(256, thread="blockIdx.x"):
                for ax0_0_2_ax1_0_2_fused in T.thread_binding(2, thread="threadIdx.y"):
                    for ax0_0_3_init, ax1_0_3_init, ax0_0_4_init, ax1_0_4_init in T.grid(1, 2, 1, 2):
                        with T.block("B_o_init"):
                            v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 4 * 8 + ax0_0_1_ax1_0_1_fused // 64 * 2 + ax0_0_2_ax1_0_2_fused + ax0_0_3_init + ax0_0_4_init)
                            v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 4 * 256 + ax0_0_1_ax1_0_1_fused % 64 * 4 + ax1_0_3_init * 2 + ax1_0_4_init)
                            T.reads()
                            T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 4, 0, v1_o % 4, 0:16, 0:16])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                            C_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 4, 0, v1_o % 4, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.accumulator", offset_factor=16)
                            T.tvm_fill_fragment(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.float32(0))
                    for ax2_0_0 in range(512):
                        for ax0_ax1_fused_0 in range(2):
                            for ax0_ax1_fused_1 in T.thread_binding(2, thread="threadIdx.y"):
                                for ax0_ax1_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                    for ax0_ax1_fused_3 in T.vectorized(8):
                                        with T.block("A_reindex_shared.dyn"):
                                            v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused // 4 * 128 + ax0_0_1_ax1_0_1_fused // 64 * 32 + (ax0_ax1_fused_0 * 512 + ax0_ax1_fused_1 * 256 + ax0_ax1_fused_2 * 8 + ax0_ax1_fused_3) // 32)
                                            v1 = T.axis.spatial(16384, ax2_0_0 * 32 + (ax0_ax1_fused_0 * 512 + ax0_ax1_fused_1 * 256 + ax0_ax1_fused_2 * 8 + ax0_ax1_fused_3) % 32)
                                            T.reads(A[v0, v1])
                                            T.writes(A_reindex_shared_dyn[v0, v1])
                                            T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]]})
                                            A_reindex_shared_dyn[v0, v1] = A[v0, v1]
                        for ax0_ax1_fused_0 in range(8):
                            for ax0_ax1_fused_1 in T.thread_binding(2, thread="threadIdx.y"):
                                for ax0_ax1_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                    for ax0_ax1_fused_3 in T.vectorized(4):
                                        with T.block("B_decompress_reindex_shared.dyn"):
                                            v0 = T.axis.spatial(16384, ax2_0_0 * 32 + (ax0_ax1_fused_0 * 256 + ax0_ax1_fused_1 * 128 + ax0_ax1_fused_2 * 4 + ax0_ax1_fused_3) // 64)
                                            v1 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused % 4 * 4096 + ax0_0_1_ax1_0_1_fused % 64 * 64 + (ax0_ax1_fused_0 * 256 + ax0_ax1_fused_1 * 128 + ax0_ax1_fused_2 * 4 + ax0_ax1_fused_3) % 64)
                                            T.reads(B[v1, v0 // 2:v0 // 2 + 2])
                                            T.writes(B_decompress_reindex_shared_dyn[v0, v1])
                                            T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]]})
                                            B_decompress_reindex_shared_dyn[v0, v1] = T.Select(v0 % 32 * 4 % 8 <= 5, T.Cast("float16", T.bitwise_and(T.shift_right(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8]), v0 % 32 * 4 % 8), 15)), T.Cast("float16", T.bitwise_or(T.Cast("int8", T.bitwise_and(T.shift_right(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8]), v0 % 32 * 4 % 8), T.shift_left(1, 8 - v0 % 32 * 4 % 8) - 1)), T.Cast("int8", T.bitwise_and(T.bitwise_and(T.shift_left(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8 + 1]), 8 - v0 % 32 * 4 % 8), T.shift_left(15, 8 - v0 % 32 * 4 % 8)), 15)))))
                        for ax2_0_1 in range(2):
                            for ax0_0, ax1_0 in T.grid(1, 1):
                                with T.block("A_reindex_shared.dyn_wmma.matrix_a_o"):
                                    v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 4 * 8 + ax0_0_1_ax1_0_1_fused // 64 * 2 + ax0_0_2_ax1_0_2_fused + ax0_0)
                                    v1_o = T.axis.spatial(1024, ax2_0_0 * 2 + ax2_0_1 + ax1_0)
                                    T.reads(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    A_1 = T.match_buffer(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="shared.dyn", offset_factor=16)
                                    C_1 = T.match_buffer(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.matrix_a", offset_factor=16)
                                    T.tvm_load_matrix_sync(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), A_1.data, A_1.elem_offset, A_1.strides[0] * 16, 1), A_1.strides[0], "row_major")
                            for ax0_0, ax1_0 in T.grid(1, 4):
                                with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b_o"):
                                    v0_o = T.axis.spatial(1024, ax2_0_0 * 2 + ax2_0_1 + ax0_0)
                                    v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 4 * 256 + ax0_0_1_ax1_0_1_fused % 64 * 4 + ax1_0)
                                    T.reads(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    A_1 = T.match_buffer(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="shared.dyn", offset_factor=16)
                                    C_1 = T.match_buffer(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.matrix_b", offset_factor=16)
                                    T.tvm_load_matrix_sync(C_1.data, 16, 16, 16, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), A_1.data, A_1.elem_offset, A_1.strides[0] * 16, 1), A_1.strides[0], "row_major")
                            for ax0_0_3, ax1_0_3, ax2_0_2, ax0_0_4, ax1_0_4 in T.grid(1, 2, 1, 1, 2):
                                with T.block("B_o_update"):
                                    v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 4 * 8 + ax0_0_1_ax1_0_1_fused // 64 * 2 + ax0_0_2_ax1_0_2_fused + ax0_0_3 + ax0_0_4)
                                    v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 4 * 256 + ax0_0_1_ax1_0_1_fused % 64 * 4 + ax1_0_3 * 2 + ax1_0_4)
                                    v2_o = T.axis.reduce(1024, ax2_0_0 * 2 + ax2_0_1 + ax2_0_2)
                                    T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 4, 0, v1_o % 4, 0:16, 0:16], A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], B_decompress_reindex_shared_dyn_wmma_matrix_b[v2_o * 16:v2_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                    T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 4, 0, v1_o % 4, 0:16, 0:16])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                                    A_1 = T.match_buffer(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="wmma.matrix_a", offset_factor=16)
                                    B_1 = T.match_buffer(B_decompress_reindex_shared_dyn_wmma_matrix_b[v2_o * 16:v2_o * 16 + 16, v1_o * 16:v1_o * 16 + 16], (16, 16), "float16", strides=("B_s0", "B_s1"), scope="wmma.matrix_b", offset_factor=16)
                                    C_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0_o, v1_o // 4, 0, v1_o % 4, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="wmma.accumulator", offset_factor=16)
                                    T.tvm_mma_sync(C_1.data, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16, A_1.data, A_1.elem_offset // A_1.strides[0] // 16 * (A_1.strides[0] // 16) + A_1.elem_offset % A_1.strides[0] // 16, B_1.data, B_1.elem_offset // B_1.strides[0] // 16 * (B_1.strides[0] // 16) + B_1.elem_offset % B_1.strides[0] // 16, C_1.data, C_1.elem_offset // C_1.strides[0] // 16 * (C_1.strides[0] // 16) + C_1.elem_offset % C_1.strides[0] // 16)
                for ax2 in range(1):
                    for ax0_ax1_fused in T.thread_binding(2, thread="threadIdx.y"):
                        for ax2_1, ax3 in T.grid(1, 4):
                            with T.block("C_reindex_shared.dyn_wmma.accumulator_o"):
                                v0 = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 4 * 8 + ax0_0_1_ax1_0_1_fused // 64 * 2 + ax0_ax1_fused)
                                v1 = T.axis.spatial(256, ax0_0_0_ax1_0_0_fused % 4 * 64 + ax0_0_1_ax1_0_1_fused % 64)
                                v2, v3 = T.axis.remap("SS", [ax2_1, ax3])
                                v4_o = T.axis.spatial(1, 0)
                                v5_o = T.axis.spatial(1, 0)
                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16])
                                T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16])
                                A_1 = T.match_buffer(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16], (16, 16), "float16", strides=("A_s0", "A_s1"), scope="wmma.accumulator", offset_factor=16)
                                C_1 = T.match_buffer(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16], (16, 16), "float16", strides=("C_s0", "C_s1"), scope="shared.dyn", offset_factor=16)
                                T.tvm_store_matrix_sync(A_1.data, 16, 16, 16, A_1.elem_offset // A_1.strides[0] // 16 * (A_1.strides[0] // 16) + A_1.elem_offset % A_1.strides[0] // 16, T.tvm_access_ptr(T.type_annotation("float16"), C_1.data, C_1.elem_offset, C_1.strides[0] * 16, 2), C_1.strides[0], "row_major")
                    for ax0_ax1_ax3_ax4_ax5_fused_0 in range(4):
                        for ax0_ax1_ax3_ax4_ax5_fused_1 in T.thread_binding(2, thread="threadIdx.y"):
                            for ax0_ax1_ax3_ax4_ax5_fused_2 in T.thread_binding(32, thread="threadIdx.x"):
                                for ax0_ax1_ax3_ax4_ax5_fused_3 in T.vectorized(8):
                                    with T.block("C_reindex_shared.dyn"):
                                        v0 = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 4 * 8 + ax0_0_1_ax1_0_1_fused // 64 * 2 + (ax0_ax1_ax3_ax4_ax5_fused_0 * 512 + ax0_ax1_ax3_ax4_ax5_fused_1 * 256 + ax0_ax1_ax3_ax4_ax5_fused_2 * 8 + ax0_ax1_ax3_ax4_ax5_fused_3) // 1024)
                                        v1 = T.axis.spatial(256, ax0_0_0_ax1_0_0_fused % 4 * 64 + ax0_0_1_ax1_0_1_fused % 64)
                                        v2 = T.axis.spatial(1, ax2)
                                        v3 = T.axis.spatial(4, (ax0_ax1_ax3_ax4_ax5_fused_0 * 512 + ax0_ax1_ax3_ax4_ax5_fused_1 * 256 + ax0_ax1_ax3_ax4_ax5_fused_2 * 8 + ax0_ax1_ax3_ax4_ax5_fused_3) % 1024 // 256)
                                        v4 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 512 + ax0_ax1_ax3_ax4_ax5_fused_1 * 256 + ax0_ax1_ax3_ax4_ax5_fused_2 * 8 + ax0_ax1_ax3_ax4_ax5_fused_3) % 256 // 16)
                                        v5 = T.axis.spatial(16, (ax0_ax1_ax3_ax4_ax5_fused_0 * 512 + ax0_ax1_ax3_ax4_ax5_fused_1 * 256 + ax0_ax1_ax3_ax4_ax5_fused_2 * 8 + ax0_ax1_ax3_ax4_ax5_fused_3) % 16)
                                        T.reads(C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5])
                                        T.writes(C[v4 + v0 * 16, v5 + v3 * 16 + v1 * 64])
                                        C[v4 + v0 * 16, v5 + v3 * 16 + v1 * 64] = C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5]
b0 = sch.get_block(name="B_decompress", func_name="main")
b1 = sch.get_block(name="B", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
b3 = sch.reindex(block=b1, buffer=("write", 0))
b4 = sch.reindex(block=b1, buffer=("read", 0))
b5 = sch.reindex(block=b1, buffer=("read", 1))
sch.transform_layout(block=b1, buffer=("read", 0), index_map=lambda vi, vk: (vi, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("read", 1), index_map=lambda vj, vk: (vk, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("write", 0), index_map=lambda vi, vj: (vi, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_block_layout(block=b3, index_map=lambda vi, vj: (vi, vj,))
sch.transform_block_layout(block=b4, index_map=lambda vi, vk: (vi, vk,))
sch.transform_block_layout(block=b5, index_map=lambda vj, vk: (vk, vj,))
sch.transform_block_layout(block=b1, index_map=lambda vi, vj, vk: (vi, vj, vk,))
l6, l7, l8 = sch.get_loops(block=b1)
l9, l10 = sch.split(loop=l8, factors=[None, 16], preserve_unit_iters=True)
l11, l12 = sch.split(loop=l7, factors=[None, 16], preserve_unit_iters=True)
l13, l14 = sch.split(loop=l6, factors=[None, 16], preserve_unit_iters=True)
l15, l16, l17, l18, l19, l20 = sch.get_loops(block=b1)
sch.reorder(l17, l19, l14, l12, l10)
b21 = sch.blockize(loop=l14, preserve_unit_iters=True)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_sync_16x16x16_f16f16f16")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize_init", ann_val="wmma_fill_16x16x16_f16")
sch.annotate(block_or_loop=b21, ann_key="warp_execution", ann_val=1)
l22, l23, l24 = sch.get_loops(block=b21)
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l22, n=5, max_innermost_factor=4, decision=[128, 4, 2, 1, 1])
l30, l31, l32, l33, l34 = sch.split(loop=l22, factors=[v25, v26, v27, v28, v29], preserve_unit_iters=True)
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l23, n=5, max_innermost_factor=4, decision=[4, 64, 1, 2, 2])
l40, l41, l42, l43, l44 = sch.split(loop=l23, factors=[v35, v36, v37, v38, v39], preserve_unit_iters=True)
v45, v46, v47 = sch.sample_perfect_tile(loop=l24, n=3, max_innermost_factor=4, decision=[512, 2, 1])
l48, l49, l50 = sch.split(loop=l24, factors=[v45, v46, v47], preserve_unit_iters=True)
sch.reorder(l30, l40, l31, l41, l32, l42, l48, l49, l33, l43, l50, l34, l44)
l51 = sch.fuse(l30, l40, preserve_unit_iters=True)
sch.bind(loop=l51, thread_axis="blockIdx.y")
l52 = sch.fuse(l31, l41, preserve_unit_iters=True)
sch.bind(loop=l52, thread_axis="blockIdx.x")
l53 = sch.fuse(l32, l42, preserve_unit_iters=True)
sch.bind(loop=l53, thread_axis="threadIdx.y")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
sch.transform_layout(block=b21, buffer=("write", 0), index_map=lambda i0, i1: (i0 // 16 // (v28 * v29), i1 // 16 // (v38 * v39), i0 // 16 % (v28 * v29), i1 // 16 % (v38 * v39), i0 % 16, i1 % 16,), pad_value=None, assume_injective_transform=True)
b54 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="shared.dyn")
sch.reverse_compute_at(block=b54, loop=l52, preserve_unit_loops=True, index=-1)
b55 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="wmma.accumulator")
l56, l57, l58, l59, l60, l61, l62, l63 = sch.get_loops(block=b54)
sch.reorder(l60, l58, l59, l61)
sch.compute_at(block=b55, loop=l60, preserve_unit_loops=True, index=-1)
l64, l65, l66, l67, l68, l69, l70, l71, l72 = sch.get_loops(block=b55)
l73 = sch.fuse(l67, l68, preserve_unit_iters=True)
sch.bind(loop=l73, thread_axis="threadIdx.y")
sch.reverse_compute_inline(block=b3)
l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b55)
b82 = sch.blockize(loop=l80, preserve_unit_iters=True)
sch.annotate(block_or_loop=b82, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_store_16x16x16_f16_shared_dyn")
l83, l84, l85, l86, l87, l88, l89, l90 = sch.get_loops(block=b54)
l91 = sch.fuse(l86, l87, l88, l89, l90, preserve_unit_iters=True)
v92 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch", ann_val=v92)
b93 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b93, loop=l48, preserve_unit_loops=True, index=-1)
l94, l95, l96, l97, l98, l99 = sch.get_loops(block=b93)
l100 = sch.fuse(l98, l99, preserve_unit_iters=True)
v101 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch", ann_val=v101)
b102 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b102, loop=l48, preserve_unit_loops=True, index=-1)
l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b102)
l109 = sch.fuse(l107, l108, preserve_unit_iters=True)
v110 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch", ann_val=v110)
b111 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="wmma.matrix_a")
sch.compute_at(block=b111, loop=l49, preserve_unit_loops=True, index=-1)
l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b111)
l119, l120 = sch.split(loop=l118, factors=[None, 16], preserve_unit_iters=True)
l121, l122 = sch.split(loop=l117, factors=[None, 16], preserve_unit_iters=True)
l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b111)
sch.reorder(l130, l122, l120)
b132 = sch.blockize(loop=l122, preserve_unit_iters=True)
sch.annotate(block_or_loop=b132, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_a_shared_dyn")
b133 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="wmma.matrix_b")
sch.compute_at(block=b133, loop=l49, preserve_unit_loops=True, index=-1)
l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b133)
l141, l142 = sch.split(loop=l140, factors=[None, 16], preserve_unit_iters=True)
l143, l144 = sch.split(loop=l139, factors=[None, 16], preserve_unit_iters=True)
l145, l146, l147, l148, l149, l150, l151, l152, l153 = sch.get_loops(block=b133)
sch.reorder(l152, l144, l142)
b154 = sch.blockize(loop=l144, preserve_unit_iters=True)
sch.annotate(block_or_loop=b154, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_b_shared_dyn")
sch.compute_inline(block=b4)
sch.compute_inline(block=b5)
sch.storage_align(block=b93, buffer_index=0, axis=-2, factor=32, offset=8)
sch.storage_align(block=b102, buffer_index=0, axis=-2, factor=32, offset=8)
sch.compute_inline(block=b0)
v155 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v155)
sch.enter_postproc()
sch.unannotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch")
l156, l157, l158, l159 = sch.get_loops(block=b54)
l160, l161, l162, l163 = sch.split(loop=l159, factors=[None, 2, 32, 8], preserve_unit_iters=True)
sch.vectorize(loop=l163)
sch.bind(loop=l162, thread_axis="threadIdx.x")
sch.bind(loop=l161, thread_axis="threadIdx.y")
sch.unannotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch")
l164, l165, l166, l167, l168 = sch.get_loops(block=b93)
l169, l170, l171, l172 = sch.split(loop=l168, factors=[None, 2, 32, 8], preserve_unit_iters=True)
sch.vectorize(loop=l172)
sch.bind(loop=l171, thread_axis="threadIdx.x")
sch.bind(loop=l170, thread_axis="threadIdx.y")
sch.unannotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch")
l173, l174, l175, l176, l177 = sch.get_loops(block=b102)
l178, l179, l180, l181 = sch.split(loop=l177, factors=[None, 2, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l181)
sch.bind(loop=l180, thread_axis="threadIdx.x")
sch.bind(loop=l179, thread_axis="threadIdx.y")
b182 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b182, ann_key="meta_schedule.unroll_explicit")
b183, b184, b185, b186, b187, b188, b189 = sch.get_child_blocks(b182)
l190, l191, l192, l193, l194, l195, l196, l197 = sch.get_loops(block=b183)
sch.annotate(block_or_loop=l190, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l190, ann_key="pragma_unroll_explicit", ann_val=1)
l198, l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b184)
sch.annotate(block_or_loop=l198, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l198, ann_key="pragma_unroll_explicit", ann_val=1)
l206, l207, l208, l209, l210, l211, l212 = sch.get_loops(block=b185)
sch.annotate(block_or_loop=l206, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l206, ann_key="pragma_unroll_explicit", ann_val=1)
l213, l214, l215, l216, l217, l218, l219 = sch.get_loops(block=b186)
sch.annotate(block_or_loop=l213, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l213, ann_key="pragma_unroll_explicit", ann_val=1)
l220, l221, l222, l223, l224, l225, l226, l227, l228, l229 = sch.get_loops(block=b187)
sch.annotate(block_or_loop=l220, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l220, ann_key="pragma_unroll_explicit", ann_val=1)
l230, l231, l232, l233, l234, l235 = sch.get_loops(block=b188)
sch.annotate(block_or_loop=l230, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l230, ann_key="pragma_unroll_explicit", ann_val=1)
l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b189)
sch.annotate(block_or_loop=l236, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l236, ann_key="pragma_unroll_explicit", ann_val=1)
b243 = sch.get_block(name="B_o", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b243)
b254 = sch.decompose_reduction(block=b243, loop=l247)
sch.unannotate(block_or_loop=b254, ann_key="meta_schedule.auto_tensorize")
sch.annotate(block_or_loop=b254, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_fill_16x16x16_f16")
sch.unannotate(block_or_loop=b243, ann_key="meta_schedule.auto_tensorize_init")
sch.unannotate(block_or_loop=b254, ann_key="meta_schedule.auto_tensorize_init")
b255 = sch.get_block(name="B_o_init", func_name="main")
sch.unannotate(block_or_loop=b255, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b255, tensor_intrin="wmma_fill_16x16x16_f16", preserve_unit_iters=True)
b256 = sch.get_block(name="A_reindex_shared.dyn_wmma.matrix_a_o", func_name="main")
sch.unannotate(block_or_loop=b256, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b256, tensor_intrin="wmma_load_16x16x16_f16_a_shared_dyn", preserve_unit_iters=True)
b257 = sch.get_block(name="B_decompress_reindex_shared.dyn_wmma.matrix_b_o", func_name="main")
sch.unannotate(block_or_loop=b257, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b257, tensor_intrin="wmma_load_16x16x16_f16_b_shared_dyn", preserve_unit_iters=True)
b258 = sch.get_block(name="B_o_update", func_name="main")
sch.unannotate(block_or_loop=b258, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b258, tensor_intrin="wmma_sync_16x16x16_f16f16f16", preserve_unit_iters=True)
b259 = sch.get_block(name="C_reindex_shared.dyn_wmma.accumulator_o", func_name="main")
sch.unannotate(block_or_loop=b259, ann_key="meta_schedule.auto_tensorize")
sch.tensorize(block_or_loop=b259, tensor_intrin="wmma_store_16x16x16_f16_shared_dyn", preserve_unit_iters=True)
2023-05-02 06:29:02 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #63: GFLOPs: 95048.1714. Time: 92588.7143 us. Best GFLOPs: 125543.5987
2023-05-02 06:29:02 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #64: GFLOPs: 119118.0476. Time: 73879.5520 us. Best GFLOPs: 125543.5987
2023-05-02 06:29:02 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-02 06:29:04 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-02 06:29:07 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 398 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:29:11 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 799 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:29:14 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 1201 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:29:18 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 1606 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:29:21 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 2004 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:29:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 2405 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:29:25 [INFO] [evolutionary_search.cc:723] Sampled 55 candidate(s)
2023-05-02 06:29:32 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 133 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:29:38 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 93 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:29:45 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 120 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:29:51 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 95 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:29:52 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9997  0.9993  0.9993  0.9977  0.9972  0.9969  0.9962  0.9951  0.9946  0.9943  0.9940  0.9940  0.9934  0.9934  0.9921  0.9919
2023-05-02 06:29:52 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-02 06:29:52 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-02 06:36:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #65: GFLOPs: 93917.7233. Time: 93703.1657 us. Best GFLOPs: 125543.5987
2023-05-02 06:36:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #66: GFLOPs: 26994.4083. Time: 326007.8123 us. Best GFLOPs: 125543.5987
2023-05-02 06:36:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #67: GFLOPs: 9339.5316. Time: 942272.9490 us. Best GFLOPs: 125543.5987
2023-05-02 06:36:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #68: GFLOPs: 112568.1620. Time: 78178.3040 us. Best GFLOPs: 125543.5987
2023-05-02 06:36:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #69: GFLOPs: 81579.2487. Time: 107875.3253 us. Best GFLOPs: 125543.5987
2023-05-02 06:36:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #70: GFLOPs: 111955.6885. Time: 78605.9923 us. Best GFLOPs: 125543.5987
2023-05-02 06:36:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #71: GFLOPs: 71806.6351. Time: 122556.7523 us. Best GFLOPs: 125543.5987
2023-05-02 06:36:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #72: GFLOPs: 8910.9518. Time: 987592.3663 us. Best GFLOPs: 125543.5987
2023-05-02 06:36:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #73: GFLOPs: 44864.5409. Time: 196154.6427 us. Best GFLOPs: 125543.5987
2023-05-02 06:36:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #74: GFLOPs: 50622.4838. Time: 173843.4650 us. Best GFLOPs: 125543.5987
2023-05-02 06:36:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #75: GFLOPs: 87235.8719. Time: 100880.3810 us. Best GFLOPs: 125543.5987
2023-05-02 06:36:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #76: GFLOPs: 85091.2632. Time: 103422.9327 us. Best GFLOPs: 125543.5987
2023-05-02 06:36:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #77: GFLOPs: 52206.1789. Time: 168569.8547 us. Best GFLOPs: 125543.5987
2023-05-02 06:36:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #78: GFLOPs: 92705.3791. Time: 94928.5583 us. Best GFLOPs: 125543.5987
2023-05-02 06:36:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #79: GFLOPs: 93510.7140. Time: 94111.0127 us. Best GFLOPs: 125543.5987
2023-05-02 06:36:41 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #80: GFLOPs: 27177.1458. Time: 323815.7550 us. Best GFLOPs: 125543.5987
2023-05-02 06:36:41 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-02 06:36:42 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-02 06:36:46 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 401 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:36:49 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 806 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:36:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 1207 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:36:56 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 1608 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:37:00 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 2006 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:37:04 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 2403 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:37:04 [INFO] [evolutionary_search.cc:723] Sampled 57 candidate(s)
2023-05-02 06:37:10 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 103 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:37:17 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 95 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:37:23 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 118 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:37:30 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 97 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:37:30 [INFO] [evolutionary_search.cc:649] Scores of the best 16 candidates:
[1 : 16]:	0.9996  0.9993  0.9985  0.9978  0.9972  0.9969  0.9965  0.9960  0.9949  0.9947  0.9944  0.9940  0.9937  0.9937  0.9932  0.9925
2023-05-02 06:37:30 [INFO] [evolutionary_search.cc:727] Got 16 candidate(s) with evolutionary search
2023-05-02 06:37:30 [INFO] [evolutionary_search.cc:730] Sending 16 candidates(s) for measurement
2023-05-02 06:44:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #81: GFLOPs: 113969.9110. Time: 77216.7663 us. Best GFLOPs: 125543.5987
2023-05-02 06:44:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #82: GFLOPs: 42933.9374. Time: 204975.0973 us. Best GFLOPs: 125543.5987
2023-05-02 06:44:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #83: GFLOPs: 13247.7366. Time: 664293.7010 us. Best GFLOPs: 125543.5987
2023-05-02 06:44:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #84: GFLOPs: 102009.4818. Time: 86270.2940 us. Best GFLOPs: 125543.5987
2023-05-02 06:44:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #85: GFLOPs: 22258.0662. Time: 395379.7200 us. Best GFLOPs: 125543.5987
2023-05-02 06:44:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #86: GFLOPs: 40587.2997. Time: 216826.1513 us. Best GFLOPs: 125543.5987
2023-05-02 06:44:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #87: GFLOPs: 37386.8027. Time: 235387.5527 us. Best GFLOPs: 125543.5987
2023-05-02 06:44:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #88: GFLOPs: 50136.7797. Time: 175527.5877 us. Best GFLOPs: 125543.5987
2023-05-02 06:44:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #89: GFLOPs: 41894.1654. Time: 210062.3777 us. Best GFLOPs: 125543.5987
2023-05-02 06:44:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #90: GFLOPs: 52513.2678. Time: 167584.0860 us. Best GFLOPs: 125543.5987
2023-05-02 06:44:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #91: GFLOPs: 113009.7615. Time: 77872.8127 us. Best GFLOPs: 125543.5987
2023-05-02 06:44:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #92: GFLOPs: 89384.3715. Time: 98455.5560 us. Best GFLOPs: 125543.5987
2023-05-02 06:44:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #93: GFLOPs: 63928.0905. Time: 137660.7360 us. Best GFLOPs: 125543.5987
2023-05-02 06:44:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #94: GFLOPs: 122390.3630. Time: 71904.2560 us. Best GFLOPs: 125543.5987
2023-05-02 06:44:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #95: GFLOPs: 7602.6293. Time: 1157545.3287 us. Best GFLOPs: 125543.5987
2023-05-02 06:44:22 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #96: GFLOPs: 50112.8023. Time: 175611.5720 us. Best GFLOPs: 125543.5987
2023-05-02 06:44:22 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-05-02 06:44:23 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-05-02 06:44:27 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 401 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:44:30 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 798 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:44:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 1199 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:44:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 1598 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:44:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 2000 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:44:41 [INFO] [evolutionary_search.cc:723] Sampled 50 candidate(s)
2023-05-02 06:44:48 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 128 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:44:54 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 111 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:45:01 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 118 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:45:07 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x2327e08)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x25a8178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x2642478)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x2527678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x260be88)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x261fd08)]: 103 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x25acbc8)]: 0 failure(s)
2023-05-02 06:45:08 [INFO] [evolutionary_search.cc:649] Scores of the best 4 candidates:
[1 : 4]:	1.0000  0.9998  0.9982  0.9981
2023-05-02 06:45:08 [INFO] [evolutionary_search.cc:727] Got 4 candidate(s) with evolutionary search
2023-05-02 06:45:08 [INFO] [evolutionary_search.cc:730] Sending 4 candidates(s) for measurement
2023-05-02 06:46:49 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #97: GFLOPs: 106253.8332. Time: 82824.1930 us. Best GFLOPs: 125543.5987
2023-05-02 06:46:49 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #98: GFLOPs: 112200.7509. Time: 78434.3057 us. Best GFLOPs: 125543.5987
2023-05-02 06:46:49 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #99: GFLOPs: 63042.5846. Time: 139594.3400 us. Best GFLOPs: 125543.5987
2023-05-02 06:46:49 [INFO] [task_scheduler.cc:131] [Task #0: main] Trial #100: GFLOPs: 111975.6208. Time: 78592.0000 us. Best GFLOPs: 125543.5987
2023-05-02 14:13:12 [INFO] [task_scheduler.cc:160] Initializing Task #0: "main"
2023-05-02 14:13:12 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 8192), "int8"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        # with T.block("root"):
        B_decompress = T.alloc_buffer((16384, 16384), "float16")
        for i, j in T.grid(16384, 16384):
            with T.block("B_decompress"):
                vi, vj = T.axis.remap("SS", [i, j])
                T.reads(B[vi, vj // 2:vj // 2 + 2])
                T.writes(B_decompress[vi, vj])
                B_decompress[vi, vj] = T.Select(vj % 32 * 4 % 8 <= 5, T.Cast("float16", T.bitwise_and(T.shift_right(T.Cast("int32", B[vi, vj // 32 * 16 + vj % 32 * 4 // 8]), vj % 32 * 4 % 8), 15)), T.Cast("float16", T.bitwise_or(T.Cast("int8", T.bitwise_and(T.shift_right(T.Cast("int32", B[vi, vj // 32 * 16 + vj % 32 * 4 // 8]), vj % 32 * 4 % 8), T.shift_left(1, 8 - vj % 32 * 4 % 8) - 1)), T.Cast("int8", T.bitwise_and(T.bitwise_and(T.shift_left(T.Cast("int32", B[vi, vj // 32 * 16 + vj % 32 * 4 // 8 + 1]), 8 - vj % 32 * 4 % 8), T.shift_left(15, 8 - vj % 32 * 4 % 8)), 15)))))
        for i, j, k in T.grid(16384, 16384, 16384):
            with T.block("B"):
                vi, vj, vk = T.axis.remap("SSR", [i, j, k])
                T.reads(A[vi, vk], B_decompress[vj, vk])
                T.writes(C[vi, vj])
                with T.init():
                    C[vi, vj] = T.float16(0)
                C[vi, vj] = C[vi, vj] + A[vi, vk] * B_decompress[vj, vk]
2023-05-02 14:13:12 [INFO] [multi_level_tiling_tensor_core.cc:216] Sketch 0: tensorizing with wmma_sync_16x16x16_f16f16f16_trans
2023-05-02 14:13:12 [INFO] [multi_level_tiling_tensor_core.cc:216] Sketch 1: tensorizing with wmma_sync_16x16x16_f16f16f16
2023-05-02 14:13:12 [INFO] [task_scheduler.cc:164] Total 2 design space(s) generated
2023-05-02 14:13:12 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 8192), "int8"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 64})
            C_reindex_shared_dyn = T.alloc_buffer((512, 16, 2, 64, 16, 16), "float16", scope="shared.dyn")
            C_reindex_shared_dyn_wmma_accumulator = T.alloc_buffer((512, 16, 2, 64, 16, 16), "float16", scope="wmma.accumulator")
            A_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            B_decompress_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            A_reindex_shared_dyn_wmma_matrix_a = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_a")
            B_decompress_reindex_shared_dyn_wmma_matrix_b = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_b")
            for ax0_0_0_ax1_0_0_fused in T.thread_binding(64, thread="blockIdx.y"):
                for ax0_0_1_ax1_0_1_fused in T.thread_binding(32, thread="blockIdx.x"):
                    for ax0_0_2_ax1_0_2_fused in T.thread_binding(4, thread="threadIdx.y"):
                        for ax2_0_0 in range(4):
                            for ax0_ax1_fused in range(262144):
                                with T.block("A_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused // 8 * 2048 + ax0_0_1_ax1_0_1_fused * 64 + ax0_ax1_fused // 4096)
                                    v1 = T.axis.spatial(16384, ax2_0_0 * 4096 + ax0_ax1_fused % 4096)
                                    T.reads(A[v0, v1])
                                    T.writes(A_reindex_shared_dyn[v0, v1])
                                    T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]], "meta_schedule.cooperative_fetch": 8})
                                    A_reindex_shared_dyn[v0, v1] = A[v0, v1]
                            for ax0_ax1_fused in range(8388608):
                                with T.block("B_decompress_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(16384, ax2_0_0 * 4096 + ax0_ax1_fused // 2048)
                                    v1 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused % 8 * 2048 + ax0_ax1_fused % 2048)
                                    T.reads(B[v1, v0 // 2:v0 // 2 + 2])
                                    T.writes(B_decompress_reindex_shared_dyn[v0, v1])
                                    T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]], "meta_schedule.cooperative_fetch": 1})
                                    B_decompress_reindex_shared_dyn[v0, v1] = T.Select(v0 % 32 * 4 % 8 <= 5, T.Cast("float16", T.bitwise_and(T.shift_right(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8]), v0 % 32 * 4 % 8), 15)), T.Cast("float16", T.bitwise_or(T.Cast("int8", T.bitwise_and(T.shift_right(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8]), v0 % 32 * 4 % 8), T.shift_left(1, 8 - v0 % 32 * 4 % 8) - 1)), T.Cast("int8", T.bitwise_and(T.bitwise_and(T.shift_left(T.Cast("int32", B[v1, v0 // 32 * 16 + v0 % 32 * 4 // 8 + 1]), 8 - v0 % 32 * 4 % 8), T.shift_left(15, 8 - v0 % 32 * 4 % 8)), 15)))))
                            for ax2_0_1 in range(64):
                                for ax0_0, ax1_0 in T.grid(2, 4):
                                    with T.block("A_reindex_shared.dyn_wmma.matrix_a_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 8 * 128 + ax0_0_1_ax1_0_1_fused * 4 + ax0_0_2_ax1_0_2_fused // 2 * 2 + ax0_0)
                                        v1_o = T.axis.spatial(1024, ax2_0_0 * 256 + ax2_0_1 * 4 + ax1_0)
                                        T.reads(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_load_16x16x16_f16_a_shared_dyn"})
                                        for ax0_1, ax1_1 in T.grid(16, 16):
                                            with T.block("A_reindex_shared.dyn_wmma.matrix_a"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(A_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = A_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                                for ax0_0, ax1_0 in T.grid(4, 64):
                                    with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b_o"):
                                        v0_o = T.axis.spatial(1024, ax2_0_0 * 256 + ax2_0_1 * 4 + ax0_0)
                                        v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 8 * 128 + ax0_0_2_ax1_0_2_fused % 2 * 64 + ax1_0)
                                        T.reads(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_load_16x16x16_f16_b_shared_dyn"})
                                        for ax0_1, ax1_1 in T.grid(16, 16):
                                            with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(B_decompress_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = B_decompress_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                                for ax0_0_3, ax1_0_3, ax2_0_2, ax0_0_4, ax1_0_4 in T.grid(1, 64, 4, 2, 1):
                                    with T.block("B_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 8 * 128 + ax0_0_1_ax1_0_1_fused * 4 + ax0_0_2_ax1_0_2_fused // 2 * 2 + ax0_0_3 * 2 + ax0_0_4)
                                        v1_o = T.axis.spatial(1024, ax1_0_4 + ax0_0_0_ax1_0_0_fused % 8 * 128 + ax0_0_2_ax1_0_2_fused % 2 * 64 + ax1_0_3)
                                        v2_o = T.axis.reduce(1024, ax2_0_0 * 256 + ax2_0_1 * 4 + ax2_0_2)
                                        T.reads(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], B_decompress_reindex_shared_dyn_wmma_matrix_b[v2_o * 16:v2_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 2, v1_o // 64, v0_o % 2, v1_o % 64, 0:16, 0:16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_sync_16x16x16_f16f16f16", "meta_schedule.auto_tensorize_init": "wmma_fill_16x16x16_f16", "meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                                        with T.init():
                                            for ax0_1, ax1_1 in T.grid(16, 16):
                                                with T.block("B_init"):
                                                    v0_i_init, v1_i_init = T.axis.remap("SS", [ax0_1, ax1_1])
                                                    T.reads()
                                                    T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 2, v1_o // 64, v0_o % 2, v1_o % 64, v0_i_init, v1_i_init])
                                                    C_reindex_shared_dyn_wmma_accumulator[v0_o // 2, v1_o // 64, v0_o % 2, v1_o % 64, v0_i_init, v1_i_init] = T.float16(0)
                                        for ax0_1, ax1_1, ax2_1 in T.grid(16, 16, 16):
                                            with T.block("B"):
                                                v0_i, v1_i, v2_i = T.axis.remap("SSR", [ax0_1, ax1_1, ax2_1])
                                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o // 2, v1_o // 64, v0_o % 2, v1_o % 64, v0_i, v1_i], A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v2_o * 16 + v2_i], B_decompress_reindex_shared_dyn_wmma_matrix_b[v2_o * 16 + v2_i, v1_o * 16 + v1_i])
                                                T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 2, v1_o // 64, v0_o % 2, v1_o % 64, v0_i, v1_i])
                                                T.block_attr({"meta_schedule.tiling_structure": "SSSRRSRS"})
                                                C_reindex_shared_dyn_wmma_accumulator[v0_o // 2, v1_o // 64, v0_o % 2, v1_o % 64, v0_i, v1_i] = C_reindex_shared_dyn_wmma_accumulator[v0_o // 2, v1_o // 64, v0_o % 2, v1_o % 64, v0_i, v1_i] + A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v2_o * 16 + v2_i] * B_decompress_reindex_shared_dyn_wmma_matrix_b[v2_o * 16 + v2_i, v1_o * 16 + v1_i]
                    for ax2 in range(2):
                        for ax0_ax1_fused in T.thread_binding(4, thread="threadIdx.y"):
                            for ax2_1, ax3 in T.grid(1, 64):
                                with T.block("C_reindex_shared.dyn_wmma.accumulator_o"):
                                    v0 = T.axis.spatial(512, ax0_0_0_ax1_0_0_fused // 8 * 64 + ax0_0_1_ax1_0_1_fused * 2 + ax0_ax1_fused // 2)
                                    v1 = T.axis.spatial(16, ax0_0_0_ax1_0_0_fused % 8 * 2 + ax0_ax1_fused % 2)
                                    v2 = T.axis.spatial(2, ax2 + ax2_1)
                                    v3 = T.axis.spatial(64, ax3)
                                    v4_o = T.axis.spatial(1, 0)
                                    v5_o = T.axis.spatial(1, 0)
                                    T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16])
                                    T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16])
                                    T.block_attr({"meta_schedule.auto_tensorize": "wmma_store_16x16x16_f16_shared_dyn"})
                                    for ax4, ax5 in T.grid(16, 16):
                                        with T.block("C_reindex_shared.dyn_wmma.accumulator"):
                                            v4_i, v5_i = T.axis.remap("SS", [ax4, ax5])
                                            T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, v4_i, v5_i])
                                            T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, v4_i, v5_i])
                                            C_reindex_shared_dyn[v0, v1, v2, v3, v4_i, v5_i] = C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, v4_i, v5_i]
                        for ax0_ax1_ax3_ax4_ax5_fused in range(65536):
                            with T.block("C_reindex_shared.dyn"):
                                v0 = T.axis.spatial(512, ax0_0_0_ax1_0_0_fused // 8 * 64 + ax0_0_1_ax1_0_1_fused * 2 + ax0_ax1_ax3_ax4_ax5_fused // 32768)
                                v1 = T.axis.spatial(16, ax0_0_0_ax1_0_0_fused % 8 * 2 + ax0_ax1_ax3_ax4_ax5_fused % 32768 // 16384)
                                v2 = T.axis.spatial(2, ax2)
                                v3 = T.axis.spatial(64, ax0_ax1_ax3_ax4_ax5_fused % 16384 // 256)
                                v4 = T.axis.spatial(16, ax0_ax1_ax3_ax4_ax5_fused % 256 // 16)
                                v5 = T.axis.spatial(16, ax0_ax1_ax3_ax4_ax5_fused % 16)
                                T.reads(C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5])
                                T.writes(C[v4 + v2 * 16 + v0 * 32, v5 + v3 * 16 + v1 * 1024])
                                T.block_attr({"meta_schedule.cooperative_fetch": 4})
                                C[v4 + v2 * 16 + v0 * 32, v5 + v3 * 16 + v1 * 1024] = C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5]
b0 = sch.get_block(name="B_decompress", func_name="main")
b1 = sch.get_block(name="B", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
b3 = sch.reindex(block=b1, buffer=("write", 0))
b4 = sch.reindex(block=b1, buffer=("read", 0))
b5 = sch.reindex(block=b1, buffer=("read", 1))
sch.transform_layout(block=b1, buffer=("read", 0), index_map=lambda vi, vk: (vi, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("read", 1), index_map=lambda vj, vk: (vk, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("write", 0), index_map=lambda vi, vj: (vi, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_block_layout(block=b3, index_map=lambda vi, vj: (vi, vj,))
sch.transform_block_layout(block=b4, index_map=lambda vi, vk: (vi, vk,))
sch.transform_block_layout(block=b5, index_map=lambda vj, vk: (vk, vj,))
sch.transform_block_layout(block=b1, index_map=lambda vi, vj, vk: (vi, vj, vk,))
l6, l7, l8 = sch.get_loops(block=b1)
l9, l10 = sch.split(loop=l8, factors=[None, 16], preserve_unit_iters=True)
l11, l12 = sch.split(loop=l7, factors=[None, 16], preserve_unit_iters=True)
l13, l14 = sch.split(loop=l6, factors=[None, 16], preserve_unit_iters=True)
l15, l16, l17, l18, l19, l20 = sch.get_loops(block=b1)
sch.reorder(l17, l19, l14, l12, l10)
b21 = sch.blockize(loop=l14, preserve_unit_iters=True)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_sync_16x16x16_f16f16f16")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize_init", ann_val="wmma_fill_16x16x16_f16")
sch.annotate(block_or_loop=b21, ann_key="warp_execution", ann_val=1)
l22, l23, l24 = sch.get_loops(block=b21)
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l22, n=5, max_innermost_factor=4, decision=[8, 32, 2, 1, 2])
l30, l31, l32, l33, l34 = sch.split(loop=l22, factors=[v25, v26, v27, v28, v29], preserve_unit_iters=True)
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l23, n=5, max_innermost_factor=4, decision=[8, 1, 2, 64, 1])
l40, l41, l42, l43, l44 = sch.split(loop=l23, factors=[v35, v36, v37, v38, v39], preserve_unit_iters=True)
v45, v46, v47 = sch.sample_perfect_tile(loop=l24, n=3, max_innermost_factor=4, decision=[4, 64, 4])
l48, l49, l50 = sch.split(loop=l24, factors=[v45, v46, v47], preserve_unit_iters=True)
sch.reorder(l30, l40, l31, l41, l32, l42, l48, l49, l33, l43, l50, l34, l44)
l51 = sch.fuse(l30, l40, preserve_unit_iters=True)
sch.bind(loop=l51, thread_axis="blockIdx.y")
l52 = sch.fuse(l31, l41, preserve_unit_iters=True)
sch.bind(loop=l52, thread_axis="blockIdx.x")
l53 = sch.fuse(l32, l42, preserve_unit_iters=True)
sch.bind(loop=l53, thread_axis="threadIdx.y")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
sch.transform_layout(block=b21, buffer=("write", 0), index_map=lambda i0, i1: (i0 // 16 // (v28 * v29), i1 // 16 // (v38 * v39), i0 // 16 % (v28 * v29), i1 // 16 % (v38 * v39), i0 % 16, i1 % 16,), pad_value=None, assume_injective_transform=True)
b54 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="shared.dyn")
sch.reverse_compute_at(block=b54, loop=l52, preserve_unit_loops=True, index=-1)
b55 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="wmma.accumulator")
l56, l57, l58, l59, l60, l61, l62, l63 = sch.get_loops(block=b54)
sch.reorder(l60, l58, l59, l61)
sch.compute_at(block=b55, loop=l60, preserve_unit_loops=True, index=-1)
l64, l65, l66, l67, l68, l69, l70, l71, l72 = sch.get_loops(block=b55)
l73 = sch.fuse(l67, l68, preserve_unit_iters=True)
sch.bind(loop=l73, thread_axis="threadIdx.y")
sch.reverse_compute_inline(block=b3)
l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b55)
b82 = sch.blockize(loop=l80, preserve_unit_iters=True)
sch.annotate(block_or_loop=b82, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_store_16x16x16_f16_shared_dyn")
l83, l84, l85, l86, l87, l88, l89, l90 = sch.get_loops(block=b54)
l91 = sch.fuse(l86, l87, l88, l89, l90, preserve_unit_iters=True)
v92 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch", ann_val=v92)
b93 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b93, loop=l48, preserve_unit_loops=True, index=-1)
l94, l95, l96, l97, l98, l99 = sch.get_loops(block=b93)
l100 = sch.fuse(l98, l99, preserve_unit_iters=True)
v101 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch", ann_val=v101)
b102 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b102, loop=l48, preserve_unit_loops=True, index=-1)
l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b102)
l109 = sch.fuse(l107, l108, preserve_unit_iters=True)
v110 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch", ann_val=v110)
b111 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="wmma.matrix_a")
sch.compute_at(block=b111, loop=l49, preserve_unit_loops=True, index=-1)
l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b111)
l119, l120 = sch.split(loop=l118, factors=[None, 16], preserve_unit_iters=True)
l121, l122 = sch.split(loop=l117, factors=[None, 16], preserve_unit_iters=True)
l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b111)
sch.reorder(l130, l122, l120)
b132 = sch.blockize(loop=l122, preserve_unit_iters=True)
sch.annotate(block_or_loop=b132, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_a_shared_dyn")
b133 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="wmma.matrix_b")
sch.compute_at(block=b133, loop=l49, preserve_unit_loops=True, index=-1)
l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b133)
l141, l142 = sch.split(loop=l140, factors=[None, 16], preserve_unit_iters=True)
l143, l144 = sch.split(loop=l139, factors=[None, 16], preserve_unit_iters=True)
l145, l146, l147, l148, l149, l150, l151, l152, l153 = sch.get_loops(block=b133)
sch.reorder(l152, l144, l142)
b154 = sch.blockize(loop=l144, preserve_unit_iters=True)
sch.annotate(block_or_loop=b154, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_b_shared_dyn")
sch.compute_inline(block=b4)
sch.compute_inline(block=b5)
sch.storage_align(block=b93, buffer_index=0, axis=-2, factor=32, offset=8)
sch.storage_align(block=b102, buffer_index=0, axis=-2, factor=32, offset=8)
sch.compute_inline(block=b0)
v155 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v155)
2023-05-02 14:13:12 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(A: T.Buffer((16384, 16384), "float16"), B: T.Buffer((16384, 8192), "int8"), C: T.Buffer((16384, 16384), "float16")):
        T.func_attr({"global_symbol": "main", "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 0})
            C_reindex_shared_dyn = T.alloc_buffer((16, 512, 64, 2, 16, 16), "float16", scope="shared.dyn")
            C_reindex_shared_dyn_wmma_accumulator = T.alloc_buffer((16, 512, 64, 2, 16, 16), "float16", scope="wmma.accumulator")
            A_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            B_decompress_reindex_shared_dyn = T.alloc_buffer((16384, 16384), "float16", scope="shared.dyn")
            A_reindex_shared_dyn_wmma_matrix_a = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_a")
            B_decompress_reindex_shared_dyn_wmma_matrix_b = T.alloc_buffer((16384, 16384), "float16", scope="wmma.matrix_b")
            for ax0_0_0_ax1_0_0_fused in T.thread_binding(256, thread="blockIdx.y"):
                for ax0_0_1_ax1_0_1_fused in T.thread_binding(16, thread="blockIdx.x"):
                    for ax0_0_2_ax1_0_2_fused in T.thread_binding(2, thread="threadIdx.y"):
                        for ax2_0_0 in range(4):
                            for ax0_ax1_fused in range(4194304):
                                with T.block("A_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused // 128 * 8192 + ax0_0_1_ax1_0_1_fused // 2 * 1024 + ax0_ax1_fused // 4096)
                                    v1 = T.axis.spatial(16384, ax2_0_0 * 4096 + ax0_ax1_fused % 4096)
                                    T.reads(A[v0, v1])
                                    T.writes(A_reindex_shared_dyn[v0, v1])
                                    T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]], "meta_schedule.cooperative_fetch": 4})
                                    A_reindex_shared_dyn[v0, v1] = A[v0, v1]
                            for ax0_ax1_fused in range(262144):
                                with T.block("B_decompress_reindex_shared.dyn"):
                                    v0 = T.axis.spatial(16384, ax0_0_0_ax1_0_0_fused % 128 * 128 + ax0_0_1_ax1_0_1_fused % 2 * 64 + ax0_ax1_fused // 4096)
                                    v1 = T.axis.spatial(16384, ax2_0_0 * 4096 + ax0_ax1_fused % 4096)
                                    T.reads(B[v0, v1 // 2:v1 // 2 + 2])
                                    T.writes(B_decompress_reindex_shared_dyn[v0, v1])
                                    T.block_attr({"buffer_dim_align": [[0, 0, 32, 8]], "meta_schedule.cooperative_fetch": 8})
                                    B_decompress_reindex_shared_dyn[v0, v1] = T.Select(v1 % 32 * 4 % 8 <= 5, T.Cast("float16", T.bitwise_and(T.shift_right(T.Cast("int32", B[v0, v1 // 32 * 16 + v1 % 32 * 4 // 8]), v1 % 32 * 4 % 8), 15)), T.Cast("float16", T.bitwise_or(T.Cast("int8", T.bitwise_and(T.shift_right(T.Cast("int32", B[v0, v1 // 32 * 16 + v1 % 32 * 4 // 8]), v1 % 32 * 4 % 8), T.shift_left(1, 8 - v1 % 32 * 4 % 8) - 1)), T.Cast("int8", T.bitwise_and(T.bitwise_and(T.shift_left(T.Cast("int32", B[v0, v1 // 32 * 16 + v1 % 32 * 4 // 8 + 1]), 8 - v1 % 32 * 4 % 8), T.shift_left(15, 8 - v1 % 32 * 4 % 8)), 15)))))
                            for ax2_0_1 in range(128):
                                for ax0_0, ax1_0 in T.grid(64, 2):
                                    with T.block("A_reindex_shared.dyn_wmma.matrix_a_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 128 * 512 + ax0_0_1_ax1_0_1_fused // 2 * 64 + ax0_0)
                                        v1_o = T.axis.spatial(1024, ax2_0_0 * 256 + ax2_0_1 * 2 + ax1_0)
                                        T.reads(A_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_load_16x16x16_f16_a_shared_dyn"})
                                        for ax0_1, ax1_1 in T.grid(16, 16):
                                            with T.block("A_reindex_shared.dyn_wmma.matrix_a"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(A_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.writes(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = A_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                                for ax0_0, ax1_0 in T.grid(2, 2):
                                    with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 128 * 8 + ax0_0_1_ax1_0_1_fused % 2 * 4 + ax0_0_2_ax1_0_2_fused * 2 + ax0_0)
                                        v1_o = T.axis.spatial(1024, ax2_0_0 * 256 + ax2_0_1 * 2 + ax1_0)
                                        T.reads(B_decompress_reindex_shared_dyn[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16:v0_o * 16 + 16, v1_o * 16:v1_o * 16 + 16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_load_16x16x16_f16_b_trans_shared_dyn"})
                                        for ax0_1, ax1_1 in T.grid(16, 16):
                                            with T.block("B_decompress_reindex_shared.dyn_wmma.matrix_b"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(B_decompress_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                T.writes(B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16 + v0_i, v1_o * 16 + v1_i])
                                                B_decompress_reindex_shared_dyn_wmma_matrix_b[v0_o * 16 + v0_i, v1_o * 16 + v1_i] = B_decompress_reindex_shared_dyn[v0_o * 16 + v0_i, v1_o * 16 + v1_i]
                                for ax0_0_3, ax1_0_3, ax2_0_2, ax0_0_4, ax1_0_4 in T.grid(32, 1, 2, 2, 2):
                                    with T.block("B_o"):
                                        v0_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused // 128 * 512 + ax0_0_1_ax1_0_1_fused // 2 * 64 + ax0_0_3 * 2 + ax0_0_4)
                                        v1_o = T.axis.spatial(1024, ax0_0_0_ax1_0_0_fused % 128 * 8 + ax0_0_1_ax1_0_1_fused % 2 * 4 + ax0_0_2_ax1_0_2_fused * 2 + ax1_0_3 * 2 + ax1_0_4)
                                        v2_o = T.axis.reduce(1024, ax2_0_0 * 256 + ax2_0_1 * 2 + ax2_0_2)
                                        T.reads(A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16:v0_o * 16 + 16, v2_o * 16:v2_o * 16 + 16], B_decompress_reindex_shared_dyn_wmma_matrix_b[v1_o * 16:v1_o * 16 + 16, v2_o * 16:v2_o * 16 + 16])
                                        T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 64, v1_o // 2, v0_o % 64, v1_o % 2, 0:16, 0:16])
                                        T.block_attr({"meta_schedule.auto_tensorize": "wmma_sync_16x16x16_f16f16f16_trans", "meta_schedule.auto_tensorize_init": "wmma_fill_16x16x16_f16", "meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "warp_execution": 1})
                                        with T.init():
                                            for ax0_1, ax1_1 in T.grid(16, 16):
                                                with T.block("B_init"):
                                                    v0_i_init, v1_i_init = T.axis.remap("SS", [ax0_1, ax1_1])
                                                    T.reads()
                                                    T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 64, v1_o // 2, v0_o % 64, v1_o % 2, v0_i_init, v1_i_init])
                                                    C_reindex_shared_dyn_wmma_accumulator[v0_o // 64, v1_o // 2, v0_o % 64, v1_o % 2, v0_i_init, v1_i_init] = T.float16(0)
                                        for ax0_1, ax1_1, ax2_1 in T.grid(16, 16, 16):
                                            with T.block("B"):
                                                v0_i, v1_i, v2_i = T.axis.remap("SSR", [ax0_1, ax1_1, ax2_1])
                                                T.reads(C_reindex_shared_dyn_wmma_accumulator[v0_o // 64, v1_o // 2, v0_o % 64, v1_o % 2, v0_i, v1_i], A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v2_o * 16 + v2_i], B_decompress_reindex_shared_dyn_wmma_matrix_b[v1_o * 16 + v1_i, v2_o * 16 + v2_i])
                                                T.writes(C_reindex_shared_dyn_wmma_accumulator[v0_o // 64, v1_o // 2, v0_o % 64, v1_o % 2, v0_i, v1_i])
                                                T.block_attr({"meta_schedule.tiling_structure": "SSSRRSRS"})
                                                C_reindex_shared_dyn_wmma_accumulator[v0_o // 64, v1_o // 2, v0_o % 64, v1_o % 2, v0_i, v1_i] = C_reindex_shared_dyn_wmma_accumulator[v0_o // 64, v1_o // 2, v0_o % 64, v1_o % 2, v0_i, v1_i] + A_reindex_shared_dyn_wmma_matrix_a[v0_o * 16 + v0_i, v2_o * 16 + v2_i] * B_decompress_reindex_shared_dyn_wmma_matrix_b[v1_o * 16 + v1_i, v2_o * 16 + v2_i]
                    for ax2 in range(64):
                        for ax0_ax1_fused in T.thread_binding(2, thread="threadIdx.y"):
                            for ax2_1, ax3 in T.grid(1, 2):
                                with T.block("C_reindex_shared.dyn_wmma.accumulator_o"):
                                    v0 = T.axis.spatial(16, ax0_0_0_ax1_0_0_fused // 128 * 8 + ax0_0_1_ax1_0_1_fused // 2)
                                    v1 = T.axis.spatial(512, ax0_0_0_ax1_0_0_fused % 128 * 4 + ax0_0_1_ax1_0_1_fused % 2 * 2 + ax0_ax1_fused)
                                    v2 = T.axis.spatial(64, ax2 + ax2_1)
                                    v3 = T.axis.spatial(2, ax3)
                                    v4_o = T.axis.spatial(1, 0)
                                    v5_o = T.axis.spatial(1, 0)
                                    T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, 0:16, 0:16])
                                    T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, 0:16, 0:16])
                                    T.block_attr({"meta_schedule.auto_tensorize": "wmma_store_16x16x16_f16_shared_dyn"})
                                    for ax4, ax5 in T.grid(16, 16):
                                        with T.block("C_reindex_shared.dyn_wmma.accumulator"):
                                            v4_i, v5_i = T.axis.remap("SS", [ax4, ax5])
                                            T.reads(C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, v4_i, v5_i])
                                            T.writes(C_reindex_shared_dyn[v0, v1, v2, v3, v4_i, v5_i])
                                            C_reindex_shared_dyn[v0, v1, v2, v3, v4_i, v5_i] = C_reindex_shared_dyn_wmma_accumulator[v0, v1, v2, v3, v4_i, v5_i]
                        for ax0_ax1_ax3_ax4_ax5_fused in range(1024):
                            with T.block("C_reindex_shared.dyn"):
                                v0 = T.axis.spatial(16, ax0_0_0_ax1_0_0_fused // 128 * 8 + ax0_0_1_ax1_0_1_fused // 2)
                                v1 = T.axis.spatial(512, ax0_0_0_ax1_0_0_fused % 128 * 4 + ax0_0_1_ax1_0_1_fused % 2 * 2 + ax0_ax1_ax3_ax4_ax5_fused // 512)
                                v2 = T.axis.spatial(64, ax2)
                                v3 = T.axis.spatial(2, ax0_ax1_ax3_ax4_ax5_fused % 512 // 256)
                                v4 = T.axis.spatial(16, ax0_ax1_ax3_ax4_ax5_fused % 256 // 16)
                                v5 = T.axis.spatial(16, ax0_ax1_ax3_ax4_ax5_fused % 16)
                                T.reads(C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5])
                                T.writes(C[v4 + v2 * 16 + v0 * 1024, v5 + v3 * 16 + v1 * 32])
                                T.block_attr({"meta_schedule.cooperative_fetch": 2})
                                C[v4 + v2 * 16 + v0 * 1024, v5 + v3 * 16 + v1 * 32] = C_reindex_shared_dyn[v0, v1, v2, v3, v4, v5]
b0 = sch.get_block(name="B_decompress", func_name="main")
b1 = sch.get_block(name="B", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
b3 = sch.reindex(block=b1, buffer=("write", 0))
b4 = sch.reindex(block=b1, buffer=("read", 0))
b5 = sch.reindex(block=b1, buffer=("read", 1))
sch.transform_layout(block=b1, buffer=("read", 0), index_map=lambda vi, vk: (vi, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("read", 1), index_map=lambda vj, vk: (vj, vk,), pad_value=None, assume_injective_transform=True)
sch.transform_layout(block=b1, buffer=("write", 0), index_map=lambda vi, vj: (vi, vj,), pad_value=None, assume_injective_transform=True)
sch.transform_block_layout(block=b3, index_map=lambda vi, vj: (vi, vj,))
sch.transform_block_layout(block=b4, index_map=lambda vi, vk: (vi, vk,))
sch.transform_block_layout(block=b5, index_map=lambda vj, vk: (vj, vk,))
sch.transform_block_layout(block=b1, index_map=lambda vi, vj, vk: (vi, vj, vk,))
l6, l7, l8 = sch.get_loops(block=b1)
l9, l10 = sch.split(loop=l8, factors=[None, 16], preserve_unit_iters=True)
l11, l12 = sch.split(loop=l7, factors=[None, 16], preserve_unit_iters=True)
l13, l14 = sch.split(loop=l6, factors=[None, 16], preserve_unit_iters=True)
l15, l16, l17, l18, l19, l20 = sch.get_loops(block=b1)
sch.reorder(l17, l19, l14, l12, l10)
b21 = sch.blockize(loop=l14, preserve_unit_iters=True)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_sync_16x16x16_f16f16f16_trans")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.auto_tensorize_init", ann_val="wmma_fill_16x16x16_f16")
sch.annotate(block_or_loop=b21, ann_key="warp_execution", ann_val=1)
l22, l23, l24 = sch.get_loops(block=b21)
v25, v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l22, n=5, max_innermost_factor=4, decision=[2, 8, 1, 32, 2])
l30, l31, l32, l33, l34 = sch.split(loop=l22, factors=[v25, v26, v27, v28, v29], preserve_unit_iters=True)
v35, v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l23, n=5, max_innermost_factor=4, decision=[128, 2, 2, 1, 2])
l40, l41, l42, l43, l44 = sch.split(loop=l23, factors=[v35, v36, v37, v38, v39], preserve_unit_iters=True)
v45, v46, v47 = sch.sample_perfect_tile(loop=l24, n=3, max_innermost_factor=4, decision=[4, 128, 2])
l48, l49, l50 = sch.split(loop=l24, factors=[v45, v46, v47], preserve_unit_iters=True)
sch.reorder(l30, l40, l31, l41, l32, l42, l48, l49, l33, l43, l50, l34, l44)
l51 = sch.fuse(l30, l40, preserve_unit_iters=True)
sch.bind(loop=l51, thread_axis="blockIdx.y")
l52 = sch.fuse(l31, l41, preserve_unit_iters=True)
sch.bind(loop=l52, thread_axis="blockIdx.x")
l53 = sch.fuse(l32, l42, preserve_unit_iters=True)
sch.bind(loop=l53, thread_axis="threadIdx.y")
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b21, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
sch.transform_layout(block=b21, buffer=("write", 0), index_map=lambda i0, i1: (i0 // 16 // (v28 * v29), i1 // 16 // (v38 * v39), i0 // 16 % (v28 * v29), i1 // 16 % (v38 * v39), i0 % 16, i1 % 16,), pad_value=None, assume_injective_transform=True)
b54 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="shared.dyn")
sch.reverse_compute_at(block=b54, loop=l52, preserve_unit_loops=True, index=-1)
b55 = sch.cache_write(block=b21, write_buffer_index=0, storage_scope="wmma.accumulator")
l56, l57, l58, l59, l60, l61, l62, l63 = sch.get_loops(block=b54)
sch.reorder(l60, l58, l59, l61)
sch.compute_at(block=b55, loop=l60, preserve_unit_loops=True, index=-1)
l64, l65, l66, l67, l68, l69, l70, l71, l72 = sch.get_loops(block=b55)
l73 = sch.fuse(l67, l68, preserve_unit_iters=True)
sch.bind(loop=l73, thread_axis="threadIdx.y")
sch.reverse_compute_inline(block=b3)
l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b55)
b82 = sch.blockize(loop=l80, preserve_unit_iters=True)
sch.annotate(block_or_loop=b82, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_store_16x16x16_f16_shared_dyn")
l83, l84, l85, l86, l87, l88, l89, l90 = sch.get_loops(block=b54)
l91 = sch.fuse(l86, l87, l88, l89, l90, preserve_unit_iters=True)
v92 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b54, ann_key="meta_schedule.cooperative_fetch", ann_val=v92)
b93 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b93, loop=l48, preserve_unit_loops=True, index=-1)
l94, l95, l96, l97, l98, l99 = sch.get_loops(block=b93)
l100 = sch.fuse(l98, l99, preserve_unit_iters=True)
v101 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b93, ann_key="meta_schedule.cooperative_fetch", ann_val=v101)
b102 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="shared.dyn", consumer_blocks=[b21])
sch.compute_at(block=b102, loop=l48, preserve_unit_loops=True, index=-1)
l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b102)
l109 = sch.fuse(l107, l108, preserve_unit_iters=True)
v110 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b102, ann_key="meta_schedule.cooperative_fetch", ann_val=v110)
b111 = sch.cache_read(block=b21, read_buffer_index=0, storage_scope="wmma.matrix_a")
sch.compute_at(block=b111, loop=l49, preserve_unit_loops=True, index=-1)
l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b111)
l119, l120 = sch.split(loop=l118, factors=[None, 16], preserve_unit_iters=True)
l121, l122 = sch.split(loop=l117, factors=[None, 16], preserve_unit_iters=True)
l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b111)
sch.reorder(l130, l122, l120)
b132 = sch.blockize(loop=l122, preserve_unit_iters=True)
sch.annotate(block_or_loop=b132, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_a_shared_dyn")
b133 = sch.cache_read(block=b21, read_buffer_index=1, storage_scope="wmma.matrix_b")
sch.compute_at(block=b133, loop=l49, preserve_unit_loops=True, index=-1)
l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b133)
l141, l142 = sch.split(loop=l140, factors=[None, 16], preserve_unit_iters=True)
l143, l144 = sch.split(loop=l139, factors=[None, 16], preserve_unit_iters=True)
l145, l146, l147, l148, l149, l150, l151, l152, l153 = sch.get_loops(block=b133)
sch.reorder(l152, l144, l142)
b154 = sch.blockize(loop=l144, preserve_unit_iters=True)
sch.annotate(block_or_loop=b154, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_b_trans_shared_dyn")
sch.compute_inline(block=b4)
sch.compute_inline(block=b5)
sch.storage_align(block=b93, buffer_index=0, axis=-2, factor=32, offset=8)
sch.storage_align(block=b102, buffer_index=0, axis=-2, factor=32, offset=8)
sch.compute_inline(block=b0)
v155 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v155)
